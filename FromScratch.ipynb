{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FromScratch.ipynb","provenance":[{"file_id":"1pScoRZMfQznBX3l1Im9-2R8u_zFsSkqm","timestamp":1586986531238}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"TXuMbF1W9zce","colab_type":"code","outputId":"e0cdb67a-352b-4777-d86a-5d381b1ec013","executionInfo":{"status":"ok","timestamp":1587317368865,"user_tz":-120,"elapsed":2535,"user":{"displayName":"marco sala","photoUrl":"","userId":"07284782352463012974"}},"colab":{"base_uri":"https://localhost:8080/","height":454}},"source":["# Taken from https://github.com/seyrankhademi/ResNet_CIFAR10\n","import os\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","# Here specify the path to your directory\n","!ls \"/content/gdrive/My Drive/DeepLearning\" \n","root_path = 'gdrive/My Drive/DeepLearning' \n","path ='/content/gdrive/My Drive/DeepLearning'\n","os.chdir(path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"," BatchNormalisation.ipynb\n"," clip_figure1.PNG\n"," cnn_accuracies.png\n"," Comparison_activations.png\n"," Comparison_lrs.png\n"," data\n","'ffn_BN_accuracy_97.55_lr=0.005_20200419'\n","'ffn_NO_BN_accuracy_96.71_lr=0.005_20200419'\n","'ffn_NO_BN_accuracy_97.99_lr=0.005_20200419'\n"," figure1.PNG\n"," FromScratch.ipynb\n"," MNIST\n"," percentile_cnn_BN.png\n"," percentile_cnn_NO_BN.png\n"," percentile_ffn_BN.png\n"," percentile_ffn_NO_BN.png\n"," random_neuron_percentile_BN.png\n"," random_neuron_percentile_NO_BN.png\n"," Scratch_Accuracy_LR0-1_init1.png\n"," Scratch_Accuracy_LR0-1.png\n"," Scratch_ActivationsBN_LR0-1_init1.png\n"," Scratch_ActivationsBN_LR0-1.png\n"," Scratch_ActivationsNoBN_LR0-1_init1.png\n"," Scratch_ActivationsNoBN_LR0-1.png\n"," Trained_Models\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uj-BLyhL33F_","colab_type":"code","colab":{}},"source":["import torch \n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch.nn.functional as F\n","import numpy as np\n","torch.manual_seed(1)\n","\n","#Adapted from https://deepnotes.io/softmax-crossentropy\n","def stable_softmax(X):\n","    maximums = torch.max(X, 1)[0]\n","    exps = torch.exp(X - maximums.reshape(maximums.shape[0],1))\n","    sums = torch.sum(exps, 1) \n","    return exps / sums.reshape(sums.shape[0],1)\n","\n","def cross_entropy(X,y):\n","    \"\"\"\n","    X is the output from fully connected layer (num_examples x num_classes)\n","    y is labels (num_examples x 1)\n","    \tNote that y is not one-hot encoded vector. \n","    \tIt can be computed as y.argmax(axis=1) from one-hot encoded vectors of labels if required.\n","    \"\"\"\n","\n","    m = y.shape[0]\n","    p = stable_softmax(X)\n","    oneHot = torch.zeros((N, D_out), device=device, dtype=dtype)\n","    oneHot.zero_()\n","    oneHot.scatter_(1, y, 1)\n","    new_log_likelihood = - oneHot * torch.log(p)\n","    loss = torch.sum(new_log_likelihood) / m\n","    return loss\n","\n","dtype = torch.float\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","transform = transforms.Compose( [transforms.ToTensor()] )                          \n","trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=60,     \n","                                          shuffle=True, num_workers=1)\n","testset = torchvision.datasets.MNIST(root='./data', train=False,\n","                                     download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=60,\n","                                         shuffle=False, num_workers=1)\n","\n","# Whole training set to compute statistics to use during testing\n","wholeBatch = torch.empty(60_000, 28*28, device=device, dtype=dtype)\n","\n","for i, batch in enumerate(trainloader):\n","  wholeBatch[i*60:(i+1)*60, :] = batch[0].view(60, 28*28)\n","\n","classes = ('0', '1', '2', '3',\n","           '4', '5', '6', '7', '8', '9')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iy72twmUYLDz","colab_type":"code","outputId":"14205dda-c4fa-4997-c7c7-d2bb84052120","executionInfo":{"status":"ok","timestamp":1587317886206,"user_tz":-120,"elapsed":519491,"user":{"displayName":"marco sala","photoUrl":"","userId":"07284782352463012974"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Adapted from https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n","# N is batch size; D_in is input dimension;\n","# H is hidden dimension; D_out is output dimension.\n","N, D_in, H, D_out = 60, 28*28, 100, 10\n","\n","# Create random Tensors to hold input and outputs.\n","\n","# One hot vector with the target labels for testing\n","y_onehot = torch.zeros(N, D_out, dtype=dtype, device=device)\n","\n","# weigths and biases\n","w0 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=False) #* 0.1\n","w1 = torch.randn(H, H, device=device, dtype=dtype, requires_grad=False)    #* 0.1\n","w2 = torch.randn(H, H, device=device, dtype=dtype, requires_grad=False)    #* 0.1\n","wy = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=False)#* 0.1\n","b0 = torch.randn(1, H, device=device, dtype=dtype, requires_grad=False)    #* 0.1\n","b1 = torch.randn(1, H, device=device, dtype=dtype, requires_grad=False)    #* 0.1\n","b2 = torch.randn(1, H, device=device, dtype=dtype, requires_grad=False)    #* 0.1\n","by = torch.randn(1, D_out, device=device, dtype=dtype, requires_grad=False)#* 0.1\n","\n","# vectors to create matrices with repeating rows. Used for bias, gamma and beta\n","ones = torch.ones(N, 1)\n","# vector to stabilize dividing by sqrt(var)\n","eps = torch.zeros((1, H), device=device)+1e-8\n","\n","## bb = beta, gg = gamma from the BN in the different layers\n","gg0 = torch.randn(1, H, device=device, dtype=dtype, requires_grad=False)   #* 0.1\n","bb0 = torch.randn(1, H, device=device, dtype=dtype, requires_grad=False)   #* 0.1\n","gg1 = torch.randn(1, H, device=device, dtype=dtype, requires_grad=False)   #* 0.1\n","bb1 = torch.randn(1, H, device=device, dtype=dtype, requires_grad=False)   #* 0.1\n","gg2 = torch.randn(1, H, device=device, dtype=dtype, requires_grad=False)   #* 0.1\n","bb2 = torch.randn(1, H, device=device, dtype=dtype, requires_grad=False)   #* 0.1\n","\n","#variables for momentum\n","momentum = 0.9\n","\n","vwy  = 0\n","vby  = 0\n","vgg2 = 0\n","vbb2 = 0\n","vw2  = 0\n","vb2  = 0\n","vgg1 = 0\n","vbb1 = 0\n","vw1  = 0\n","vb1  = 0\n","vgg0 = 0\n","vbb0 = 0\n","vw0  = 0\n","vb0  = 0\n","\n","# to save the sigmoid activations\n","sigmoidActivation15Percentile = []\n","sigmoidActivation50Percentile = []\n","sigmoidActivation85Percentile = []\n","\n","# to save test accuracy along training\n","testAccuracyPerTrainingStep = []\n","\n","#training\n","learningRate = 0.1\n","for i in range(50):\n","  for j, batch in enumerate(trainloader):\n","    # x = mini-batch, y = target labels\n","    x = batch[0].view(N, D_in).to(device)\n","    y = batch[1].view(N, 1).to(device)\n","    ones = torch.ones((N, 1), device=device)\n","\n","    #first hidden layer\n","    h0_lin = x.mm(w0) + ones.mm(b0) #N*h\n","    mean0 = h0_lin.mean(0).reshape(1,H)\n","    var0 = h0_lin.var(0).reshape(1,H)\n","    h0_hat = (h0_lin - ones.mm(mean0))/torch.sqrt(ones.mm(var0) + ones.mm(eps))\n","    h0_bn = h0_hat*(ones.mm(gg0)) + ones.mm(bb0)\n","    h0 = h0_bn.sigmoid()\n","\n","    #second hidden layer\n","    h1_lin = h0.mm(w1) + ones.mm(b1)\n","    mean1 = h1_lin.mean(0).reshape(1,H)\n","    var1 = h1_lin.var(0).reshape(1,H)\n","    h1_hat = (h1_lin - ones.mm(mean1))/torch.sqrt(ones.mm(var1) + ones.mm(eps))\n","    h1_bn = h1_hat*(ones.mm(gg2)) + ones.mm(bb1)\n","    h1 = h1_bn.sigmoid()\n","\n","    #third hidden layer\n","    h2_lin = h1.mm(w2) + ones.mm(b2)\n","    mean2 = h2_lin.mean(0).reshape(1,H)\n","    var2 = h2_lin.var(0).reshape(1,H)\n","    h2_hat = (h2_lin - ones.mm(mean2))/torch.sqrt(ones.mm(var2) + ones.mm(eps))\n","    h2_bn = h2_hat*(ones.mm(gg2)) + ones.mm(bb2)\n","    h2 = h2_bn.sigmoid()\n","    \n","    #output layer\n","    y_pred = h2.mm(wy) + ones.mm(by) # ypred = \"alin\" in the derivations\n","\n","    #loss function\n","    loss = cross_entropy(y_pred, y)\n","    \n","    if j % 50 == 0:\n","      print(\"Loss function at epoch\", i, \"and at batch\", j, \" is \", loss.cpu().detach().numpy() )\n","    \n","    # backward pass \n","    # dL omitted so dh = dL/dh\n","\n","    #creates a matrix of N onehot vectors with the target labels\n","    y_onehot.zero_()\n","    y_onehot.scatter_(1, y, 1)\n","    dy_pred = (stable_softmax(y_pred) - y_onehot) / N\n","\n","    dwy = h2.T.mm(dy_pred)\n","    dby = ones.T.mm(dy_pred)\n","    \n","    dh2 = dy_pred.mm(wy.T)\n","    dh2_bn = dh2 * (h2 * (1 - h2))\n","    dgg2 = ones.T.mm(dh2_bn * h2_hat)\n","    dbb2 = ones.T.mm(dh2_bn)\n","    \n","    dh2_hat = dh2_bn * (ones.mm(gg2))\n","    dvar2 = ones.T.mm((dh2_hat * (h2_lin - ones.mm(mean2))) * (-1/2) * (ones.mm(var2) + ones.mm(eps))**(-3/2))\n","    dmean2 = ones.T.mm(dh2_hat * (-1)/torch.sqrt(ones.mm(var2) + ones.mm(eps))) + dvar2 * ones.T.mm(-2/N*(h2_lin - ones.mm(mean2)))\n","    dh2_lin = dh2_hat * 1/torch.sqrt(ones.mm(var2) + ones.mm(eps)) + ones.mm(dvar2) * 2/N*(h2_lin - ones.mm(mean2)) + ones.mm(dmean2)/N\n","    dw2 = h1.T.mm(dh2_lin)\n","    db2 = ones.T.mm(dh2_lin)\n","    \n","    dh1 = dh2_lin.mm(w2.T)\n","    dh1_bn = dh1 * (h1 * (1 - h1))\n","    dgg1 = ones.T.mm(dh1_bn * h1_hat)\n","    dbb1 = ones.T.mm(dh1_bn)\n","    \n","    dh1_hat = dh1_bn * (ones.mm(gg1))\n","    dvar1 = ones.T.mm((dh1_hat * (h1_lin - ones.mm(mean1))) * (-1/2) * (ones.mm(var1) + ones.mm(eps))**(-3/2))\n","    dmean1 = ones.T.mm(dh1_hat * (-1)/torch.sqrt(ones.mm(var1) + ones.mm(eps))) + dvar1 * ones.T.mm(-2/N*(h1_lin - ones.mm(mean1)))\n","    dh1_lin = dh1_hat * 1/torch.sqrt(ones.mm(var1) + ones.mm(eps)) + ones.mm(dvar1) * 2/N*(h1_lin - ones.mm(mean1)) + ones.mm(dmean1)/N\n","    dw1 = h0.T.mm(dh1_lin)\n","    db1 = ones.T.mm(dh1_lin)\n","    \n","    dh0 = dh1_lin.mm(w1.T)\n","    dh0_bn = dh0 * (h0 * (1 - h0))\n","    dgg0 = ones.T.mm(dh0_bn * h0_hat)\n","    dbb0 = ones.T.mm(dh0_bn)\n","    \n","    dh0_hat = dh0_bn * (ones.mm(gg0))\n","    dvar0 = ones.T.mm((dh0_hat * (h0_lin - ones.mm(mean0))) * (-1/2) * (ones.mm(var0) + ones.mm(eps))**(-3/2))\n","    dmean0 = ones.T.mm(dh0_hat * (-1)/torch.sqrt(ones.mm(var0) + ones.mm(eps))) + dvar0 * ones.T.mm(-2/N*(h0_lin - ones.mm(mean0)))\n","    dh0_lin = dh0_hat * 1/torch.sqrt(ones.mm(var0) + ones.mm(eps)) + ones.mm(dvar0) * 2/N*(h0_lin - ones.mm(mean0)) + ones.mm(dmean0)/N\n","    dw0 = x.T.mm(dh0_lin)\n","    db0 = ones.T.mm(dh0_lin)\n","    \n","    #momentum\n","    vwy  = momentum * vwy  + (1 - momentum) * dwy \n","    vby  = momentum * vby  + (1 - momentum) * dby \n","    vgg2 = momentum * vgg2 + (1 - momentum) * dgg2\n","    vbb2 = momentum * vbb2 + (1 - momentum) * dbb2\n","    vw2  = momentum * vw2  + (1 - momentum) * dw2 \n","    vb2  = momentum * vb2  + (1 - momentum) * db2 \n","    vgg1 = momentum * vgg1 + (1 - momentum) * dgg1\n","    vbb1 = momentum * vbb1 + (1 - momentum) * dbb1\n","    vw1  = momentum * vw1  + (1 - momentum) * dw1 \n","    vb1  = momentum * vb1  + (1 - momentum) * db1 \n","    vgg0 = momentum * vgg0 + (1 - momentum) * dgg0\n","    vbb0 = momentum * vbb0 + (1 - momentum) * dbb0\n","    vw0  = momentum * vw0  + (1 - momentum) * dw0 \n","    vb0  = momentum * vb0  + (1 - momentum) * db0 \n","\n","    # update\n","    wy -= learningRate* vwy \n","    by -= learningRate* vby \n","    gg2 -= learningRate*vgg2\n","    bb2 -= learningRate*vbb2\n","    w2 -= learningRate* vw2 \n","    b2 -= learningRate* vb2 \n","    gg1 -= learningRate*vgg1\n","    bb1 -= learningRate*vbb1\n","    w1 -= learningRate* vw1 \n","    b1 -= learningRate* vb1 \n","    gg0 -= learningRate*vgg0\n","    bb0 -= learningRate*vbb0\n","    w0 -= learningRate* vw0 \n","    b0 -= learningRate* vb0 \n","\n","    # add sigmoid activations every 50 training steps\n","    if j % 50 == 0:\n","      sigmoidActivation15Percentile.append(np.percentile(h2_bn.cpu().detach().numpy(), 15))\n","      sigmoidActivation50Percentile.append(np.percentile(h2_bn.cpu().detach().numpy(), 50))\n","      sigmoidActivation85Percentile.append(np.percentile(h2_bn.cpu().detach().numpy(), 85))\n","      #print(\"15 Percentiles: \", sigmoidActivation15Percentile)\n","      #print(\"50 Percentiles: \", sigmoidActivation50Percentile)\n","      #print(\"85 Percentiles: \", sigmoidActivation85Percentile)\n","\n","    # test accuracy\n","    if j == 0:\n","      #computing statistics for the full training set mean and var 0,1,2\n","      accuracyOfTrainingStep = []\n","\n","      ones = torch.ones(wholeBatch.shape[0], 1).to(device)\n","\n","      h0_lin = wholeBatch.mm(w0) + ones.mm(b0) \n","      mean0 = h0_lin.mean(0).reshape(1,H).to(device)\n","      var0 = h0_lin.var(0).reshape(1,H).to(device)\n","      h0_hat = (h0_lin - ones.mm(mean0))/torch.sqrt(ones.mm(var0) + ones.mm(eps))\n","      h0_bn = h0_hat*(ones.mm(gg0)) + ones.mm(bb0)\n","      h0 = h0_bn.sigmoid()\n","\n","      h1_lin = h0.mm(w1) + ones.mm(b1)\n","      mean1 = h1_lin.mean(0).reshape(1,H).to(device)\n","      var1 = h1_lin.var(0).reshape(1,H).to(device)\n","      h1_hat = (h1_lin - ones.mm(mean1))/torch.sqrt(ones.mm(var1) + ones.mm(eps))\n","      h1_bn = h1_hat*(ones.mm(gg2)) + ones.mm(bb1)\n","      h1 = h1_bn.sigmoid()\n","\n","      h2_lin = h1.mm(w2) + ones.mm(b2)\n","      mean2 = h2_lin.mean(0).reshape(1,H).to(device)\n","      var2 = h2_lin.var(0).reshape(1,H).to(device)\n","\n","      #computes test accuracy\n","      for k, testbatch in enumerate(testloader):\n","        x_test = testbatch[0].view(testbatch[0].shape[0], D_in).to(device)\n","        y_test = testbatch[1].view(testbatch[0].shape[0], 1).to(device)\n","        ones = torch.ones(testbatch[0].shape[0], 1).to(device)\n","\n","        h0_lin = x_test.mm(w0) + ones.mm(b0) \n","        h0_hat = (h0_lin - ones.mm(mean0))/torch.sqrt(ones.mm(var0) + ones.mm(eps))\n","        h0_bn = h0_hat*(ones.mm(gg0)) + ones.mm(bb0)\n","        h0 = h0_bn.sigmoid()\n","\n","        h1_lin = h0.mm(w1) + ones.mm(b1)\n","        h1_hat = (h1_lin - ones.mm(mean1))/torch.sqrt(ones.mm(var1) + ones.mm(eps))\n","        h1_bn = h1_hat*(ones.mm(gg2)) + ones.mm(bb1)\n","        h1 = h1_bn.sigmoid()\n","\n","        h2_lin = h1.mm(w2) + ones.mm(b2)\n","        h2_hat = (h2_lin - ones.mm(mean2))/torch.sqrt(ones.mm(var2) + ones.mm(eps))\n","        h2_bn = h2_hat*(ones.mm(gg2)) + ones.mm(bb2)\n","        h2 = h2_bn.sigmoid()\n","        \n","        y_pred = h2.mm(wy) + ones.mm(by)\n","        y_prediction = stable_softmax(y_pred)\n","        y_pred_labels = y_prediction.argmax(axis=1).reshape(testbatch[0].shape[0], 1)\n","\n","        if k == 0:\n","          print(\"Testing test minibatch at training step \", j, \" of epoch \", i)\n","        accuracyOfTrainingStep.append(np.sum(y_pred_labels.cpu().numpy() == y_test.cpu().numpy()))\n","\n","      accuracyOfTrainingStep = np.sum(np.array(accuracyOfTrainingStep)) / 10000\n","      testAccuracyPerTrainingStep.append(accuracyOfTrainingStep)\n","\n","      print(\"Accuracy of training step\", i*(j+1)*1000,\" = \", accuracyOfTrainingStep )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loss function at epoch 0 and at batch 0  is  9.535363\n","Testing test minibatch at training step  0  of epoch  0\n","Accuracy of training step 0  =  0.0998\n","Loss function at epoch 0 and at batch 50  is  2.4558218\n","Loss function at epoch 0 and at batch 100  is  2.2649214\n","Loss function at epoch 0 and at batch 150  is  1.7294964\n","Loss function at epoch 0 and at batch 200  is  1.5008574\n","Loss function at epoch 0 and at batch 250  is  1.6975602\n","Loss function at epoch 0 and at batch 300  is  1.2844291\n","Loss function at epoch 0 and at batch 350  is  1.3819141\n","Loss function at epoch 0 and at batch 400  is  1.4305749\n","Loss function at epoch 0 and at batch 450  is  1.090813\n","Loss function at epoch 0 and at batch 500  is  1.0422156\n","Loss function at epoch 0 and at batch 550  is  1.106627\n","Loss function at epoch 0 and at batch 600  is  1.0092398\n","Loss function at epoch 0 and at batch 650  is  0.9689409\n","Loss function at epoch 0 and at batch 700  is  0.905061\n","Loss function at epoch 0 and at batch 750  is  1.0402151\n","Loss function at epoch 0 and at batch 800  is  0.9079154\n","Loss function at epoch 0 and at batch 850  is  0.8816647\n","Loss function at epoch 0 and at batch 900  is  0.8724706\n","Loss function at epoch 0 and at batch 950  is  0.69057906\n","Loss function at epoch 1 and at batch 0  is  0.9886038\n","Testing test minibatch at training step  0  of epoch  1\n","Accuracy of training step 1000  =  0.78\n","Loss function at epoch 1 and at batch 50  is  0.9311927\n","Loss function at epoch 1 and at batch 100  is  0.85173583\n","Loss function at epoch 1 and at batch 150  is  0.9573314\n","Loss function at epoch 1 and at batch 200  is  0.59626937\n","Loss function at epoch 1 and at batch 250  is  0.5597443\n","Loss function at epoch 1 and at batch 300  is  0.8971637\n","Loss function at epoch 1 and at batch 350  is  0.6430699\n","Loss function at epoch 1 and at batch 400  is  0.6027999\n","Loss function at epoch 1 and at batch 450  is  0.43627405\n","Loss function at epoch 1 and at batch 500  is  0.6549913\n","Loss function at epoch 1 and at batch 550  is  0.6746953\n","Loss function at epoch 1 and at batch 600  is  0.7593022\n","Loss function at epoch 1 and at batch 650  is  0.69324255\n","Loss function at epoch 1 and at batch 700  is  0.5367317\n","Loss function at epoch 1 and at batch 750  is  0.4797124\n","Loss function at epoch 1 and at batch 800  is  0.56826085\n","Loss function at epoch 1 and at batch 850  is  0.6740967\n","Loss function at epoch 1 and at batch 900  is  0.47044927\n","Loss function at epoch 1 and at batch 950  is  0.59668005\n","Loss function at epoch 2 and at batch 0  is  0.48260927\n","Testing test minibatch at training step  0  of epoch  2\n","Accuracy of training step 2000  =  0.8608\n","Loss function at epoch 2 and at batch 50  is  0.6526416\n","Loss function at epoch 2 and at batch 100  is  0.38690722\n","Loss function at epoch 2 and at batch 150  is  0.6752968\n","Loss function at epoch 2 and at batch 200  is  0.34603205\n","Loss function at epoch 2 and at batch 250  is  0.47736475\n","Loss function at epoch 2 and at batch 300  is  0.5862249\n","Loss function at epoch 2 and at batch 350  is  0.2858458\n","Loss function at epoch 2 and at batch 400  is  0.5492906\n","Loss function at epoch 2 and at batch 450  is  0.39811283\n","Loss function at epoch 2 and at batch 500  is  0.692746\n","Loss function at epoch 2 and at batch 550  is  0.3599446\n","Loss function at epoch 2 and at batch 600  is  0.49855816\n","Loss function at epoch 2 and at batch 650  is  0.60279644\n","Loss function at epoch 2 and at batch 700  is  0.60194653\n","Loss function at epoch 2 and at batch 750  is  0.42583233\n","Loss function at epoch 2 and at batch 800  is  0.40053332\n","Loss function at epoch 2 and at batch 850  is  0.63642675\n","Loss function at epoch 2 and at batch 900  is  0.6185199\n","Loss function at epoch 2 and at batch 950  is  0.4673641\n","Loss function at epoch 3 and at batch 0  is  0.4800683\n","Testing test minibatch at training step  0  of epoch  3\n","Accuracy of training step 3000  =  0.8844\n","Loss function at epoch 3 and at batch 50  is  0.5575211\n","Loss function at epoch 3 and at batch 100  is  0.6683041\n","Loss function at epoch 3 and at batch 150  is  0.55986094\n","Loss function at epoch 3 and at batch 200  is  0.30848175\n","Loss function at epoch 3 and at batch 250  is  0.3869699\n","Loss function at epoch 3 and at batch 300  is  0.34248433\n","Loss function at epoch 3 and at batch 350  is  0.38839108\n","Loss function at epoch 3 and at batch 400  is  0.44373304\n","Loss function at epoch 3 and at batch 450  is  0.4168455\n","Loss function at epoch 3 and at batch 500  is  0.25368106\n","Loss function at epoch 3 and at batch 550  is  0.3335542\n","Loss function at epoch 3 and at batch 600  is  0.32260096\n","Loss function at epoch 3 and at batch 650  is  0.31783283\n","Loss function at epoch 3 and at batch 700  is  0.20621635\n","Loss function at epoch 3 and at batch 750  is  0.46148056\n","Loss function at epoch 3 and at batch 800  is  0.5446618\n","Loss function at epoch 3 and at batch 850  is  0.3601308\n","Loss function at epoch 3 and at batch 900  is  0.56941974\n","Loss function at epoch 3 and at batch 950  is  0.25832805\n","Loss function at epoch 4 and at batch 0  is  0.26474652\n","Testing test minibatch at training step  0  of epoch  4\n","Accuracy of training step 4000  =  0.8967\n","Loss function at epoch 4 and at batch 50  is  0.2523962\n","Loss function at epoch 4 and at batch 100  is  0.44474813\n","Loss function at epoch 4 and at batch 150  is  0.39016902\n","Loss function at epoch 4 and at batch 200  is  0.2049229\n","Loss function at epoch 4 and at batch 250  is  0.16201179\n","Loss function at epoch 4 and at batch 300  is  0.41978806\n","Loss function at epoch 4 and at batch 350  is  0.40791595\n","Loss function at epoch 4 and at batch 400  is  0.47678104\n","Loss function at epoch 4 and at batch 450  is  0.39419878\n","Loss function at epoch 4 and at batch 500  is  0.59104556\n","Loss function at epoch 4 and at batch 550  is  0.74394935\n","Loss function at epoch 4 and at batch 600  is  0.21240821\n","Loss function at epoch 4 and at batch 650  is  0.5932866\n","Loss function at epoch 4 and at batch 700  is  0.4384592\n","Loss function at epoch 4 and at batch 750  is  0.279248\n","Loss function at epoch 4 and at batch 800  is  0.39957857\n","Loss function at epoch 4 and at batch 850  is  0.33280283\n","Loss function at epoch 4 and at batch 900  is  0.5206079\n","Loss function at epoch 4 and at batch 950  is  0.40155745\n","Loss function at epoch 5 and at batch 0  is  0.30840054\n","Testing test minibatch at training step  0  of epoch  5\n","Accuracy of training step 5000  =  0.9048\n","Loss function at epoch 5 and at batch 50  is  0.34318224\n","Loss function at epoch 5 and at batch 100  is  0.3798105\n","Loss function at epoch 5 and at batch 150  is  0.4093699\n","Loss function at epoch 5 and at batch 200  is  0.1806903\n","Loss function at epoch 5 and at batch 250  is  0.5260166\n","Loss function at epoch 5 and at batch 300  is  0.36138982\n","Loss function at epoch 5 and at batch 350  is  0.22353575\n","Loss function at epoch 5 and at batch 400  is  0.17952722\n","Loss function at epoch 5 and at batch 450  is  0.29983586\n","Loss function at epoch 5 and at batch 500  is  0.26214468\n","Loss function at epoch 5 and at batch 550  is  0.44214055\n","Loss function at epoch 5 and at batch 600  is  0.23591222\n","Loss function at epoch 5 and at batch 650  is  0.3185255\n","Loss function at epoch 5 and at batch 700  is  0.21764754\n","Loss function at epoch 5 and at batch 750  is  0.47950613\n","Loss function at epoch 5 and at batch 800  is  0.43269154\n","Loss function at epoch 5 and at batch 850  is  0.16676897\n","Loss function at epoch 5 and at batch 900  is  0.18162109\n","Loss function at epoch 5 and at batch 950  is  0.24736209\n","Loss function at epoch 6 and at batch 0  is  0.28717312\n","Testing test minibatch at training step  0  of epoch  6\n","Accuracy of training step 6000  =  0.9154\n","Loss function at epoch 6 and at batch 50  is  0.31552613\n","Loss function at epoch 6 and at batch 100  is  0.2520631\n","Loss function at epoch 6 and at batch 150  is  0.5006665\n","Loss function at epoch 6 and at batch 200  is  0.44857663\n","Loss function at epoch 6 and at batch 250  is  0.3227037\n","Loss function at epoch 6 and at batch 300  is  0.33012232\n","Loss function at epoch 6 and at batch 350  is  0.26646164\n","Loss function at epoch 6 and at batch 400  is  0.25831023\n","Loss function at epoch 6 and at batch 450  is  0.4190307\n","Loss function at epoch 6 and at batch 500  is  0.34992614\n","Loss function at epoch 6 and at batch 550  is  0.23986296\n","Loss function at epoch 6 and at batch 600  is  0.46608594\n","Loss function at epoch 6 and at batch 650  is  0.36565223\n","Loss function at epoch 6 and at batch 700  is  0.18515803\n","Loss function at epoch 6 and at batch 750  is  0.40009192\n","Loss function at epoch 6 and at batch 800  is  0.11683579\n","Loss function at epoch 6 and at batch 850  is  0.30542243\n","Loss function at epoch 6 and at batch 900  is  0.11038401\n","Loss function at epoch 6 and at batch 950  is  0.15860893\n","Loss function at epoch 7 and at batch 0  is  0.31403917\n","Testing test minibatch at training step  0  of epoch  7\n","Accuracy of training step 7000  =  0.9228\n","Loss function at epoch 7 and at batch 50  is  0.7012219\n","Loss function at epoch 7 and at batch 100  is  0.16938461\n","Loss function at epoch 7 and at batch 150  is  0.17158839\n","Loss function at epoch 7 and at batch 200  is  0.28784525\n","Loss function at epoch 7 and at batch 250  is  0.40362298\n","Loss function at epoch 7 and at batch 300  is  0.55451137\n","Loss function at epoch 7 and at batch 350  is  0.24892107\n","Loss function at epoch 7 and at batch 400  is  0.23136476\n","Loss function at epoch 7 and at batch 450  is  0.34066543\n","Loss function at epoch 7 and at batch 500  is  0.30867103\n","Loss function at epoch 7 and at batch 550  is  0.46993437\n","Loss function at epoch 7 and at batch 600  is  0.2108337\n","Loss function at epoch 7 and at batch 650  is  0.1932316\n","Loss function at epoch 7 and at batch 700  is  0.25107703\n","Loss function at epoch 7 and at batch 750  is  0.52349246\n","Loss function at epoch 7 and at batch 800  is  0.3816339\n","Loss function at epoch 7 and at batch 850  is  0.3519055\n","Loss function at epoch 7 and at batch 900  is  0.3039827\n","Loss function at epoch 7 and at batch 950  is  0.3559366\n","Loss function at epoch 8 and at batch 0  is  0.19291139\n","Testing test minibatch at training step  0  of epoch  8\n","Accuracy of training step 8000  =  0.9307\n","Loss function at epoch 8 and at batch 50  is  0.10118632\n","Loss function at epoch 8 and at batch 100  is  0.42885277\n","Loss function at epoch 8 and at batch 150  is  0.20580178\n","Loss function at epoch 8 and at batch 200  is  0.3750435\n","Loss function at epoch 8 and at batch 250  is  0.25393072\n","Loss function at epoch 8 and at batch 300  is  0.26240647\n","Loss function at epoch 8 and at batch 350  is  0.2882264\n","Loss function at epoch 8 and at batch 400  is  0.38775334\n","Loss function at epoch 8 and at batch 450  is  0.4350593\n","Loss function at epoch 8 and at batch 500  is  0.21991515\n","Loss function at epoch 8 and at batch 550  is  0.31791344\n","Loss function at epoch 8 and at batch 600  is  0.16891824\n","Loss function at epoch 8 and at batch 650  is  0.40288183\n","Loss function at epoch 8 and at batch 700  is  0.26523006\n","Loss function at epoch 8 and at batch 750  is  0.30510396\n","Loss function at epoch 8 and at batch 800  is  0.42125857\n","Loss function at epoch 8 and at batch 850  is  0.24798858\n","Loss function at epoch 8 and at batch 900  is  0.25686246\n","Loss function at epoch 8 and at batch 950  is  0.23894444\n","Loss function at epoch 9 and at batch 0  is  0.33376792\n","Testing test minibatch at training step  0  of epoch  9\n","Accuracy of training step 9000  =  0.9351\n","Loss function at epoch 9 and at batch 50  is  0.31225887\n","Loss function at epoch 9 and at batch 100  is  0.22116898\n","Loss function at epoch 9 and at batch 150  is  0.14581607\n","Loss function at epoch 9 and at batch 200  is  0.28167483\n","Loss function at epoch 9 and at batch 250  is  0.19815548\n","Loss function at epoch 9 and at batch 300  is  0.21152385\n","Loss function at epoch 9 and at batch 350  is  0.08561667\n","Loss function at epoch 9 and at batch 400  is  0.525293\n","Loss function at epoch 9 and at batch 450  is  0.5106086\n","Loss function at epoch 9 and at batch 500  is  0.16850053\n","Loss function at epoch 9 and at batch 550  is  0.18190798\n","Loss function at epoch 9 and at batch 600  is  0.20514992\n","Loss function at epoch 9 and at batch 650  is  0.43094057\n","Loss function at epoch 9 and at batch 700  is  0.15925209\n","Loss function at epoch 9 and at batch 750  is  0.22225948\n","Loss function at epoch 9 and at batch 800  is  0.10735989\n","Loss function at epoch 9 and at batch 850  is  0.22794433\n","Loss function at epoch 9 and at batch 900  is  0.35061434\n","Loss function at epoch 9 and at batch 950  is  0.13375701\n","Loss function at epoch 10 and at batch 0  is  0.2747206\n","Testing test minibatch at training step  0  of epoch  10\n","Accuracy of training step 10000  =  0.9374\n","Loss function at epoch 10 and at batch 50  is  0.29239818\n","Loss function at epoch 10 and at batch 100  is  0.1758913\n","Loss function at epoch 10 and at batch 150  is  0.34917736\n","Loss function at epoch 10 and at batch 200  is  0.19725324\n","Loss function at epoch 10 and at batch 250  is  0.23267171\n","Loss function at epoch 10 and at batch 300  is  0.11020712\n","Loss function at epoch 10 and at batch 350  is  0.23469083\n","Loss function at epoch 10 and at batch 400  is  0.21221486\n","Loss function at epoch 10 and at batch 450  is  0.19318064\n","Loss function at epoch 10 and at batch 500  is  0.09847716\n","Loss function at epoch 10 and at batch 550  is  0.20563902\n","Loss function at epoch 10 and at batch 600  is  0.20026904\n","Loss function at epoch 10 and at batch 650  is  0.34287888\n","Loss function at epoch 10 and at batch 700  is  0.40024167\n","Loss function at epoch 10 and at batch 750  is  0.22747658\n","Loss function at epoch 10 and at batch 800  is  0.47765797\n","Loss function at epoch 10 and at batch 850  is  0.10553482\n","Loss function at epoch 10 and at batch 900  is  0.16514549\n","Loss function at epoch 10 and at batch 950  is  0.401377\n","Loss function at epoch 11 and at batch 0  is  0.18829384\n","Testing test minibatch at training step  0  of epoch  11\n","Accuracy of training step 11000  =  0.9426\n","Loss function at epoch 11 and at batch 50  is  0.25541046\n","Loss function at epoch 11 and at batch 100  is  0.37347543\n","Loss function at epoch 11 and at batch 150  is  0.18590565\n","Loss function at epoch 11 and at batch 200  is  0.08114482\n","Loss function at epoch 11 and at batch 250  is  0.1335154\n","Loss function at epoch 11 and at batch 300  is  0.19666213\n","Loss function at epoch 11 and at batch 350  is  0.25063753\n","Loss function at epoch 11 and at batch 400  is  0.13258348\n","Loss function at epoch 11 and at batch 450  is  0.14640304\n","Loss function at epoch 11 and at batch 500  is  0.3227843\n","Loss function at epoch 11 and at batch 550  is  0.13024382\n","Loss function at epoch 11 and at batch 600  is  0.18284309\n","Loss function at epoch 11 and at batch 650  is  0.14480652\n","Loss function at epoch 11 and at batch 700  is  0.130788\n","Loss function at epoch 11 and at batch 750  is  0.28723678\n","Loss function at epoch 11 and at batch 800  is  0.36273915\n","Loss function at epoch 11 and at batch 850  is  0.06965921\n","Loss function at epoch 11 and at batch 900  is  0.13813777\n","Loss function at epoch 11 and at batch 950  is  0.10957521\n","Loss function at epoch 12 and at batch 0  is  0.14339346\n","Testing test minibatch at training step  0  of epoch  12\n","Accuracy of training step 12000  =  0.9464\n","Loss function at epoch 12 and at batch 50  is  0.22932988\n","Loss function at epoch 12 and at batch 100  is  0.22595859\n","Loss function at epoch 12 and at batch 150  is  0.21928956\n","Loss function at epoch 12 and at batch 200  is  0.18192528\n","Loss function at epoch 12 and at batch 250  is  0.23170248\n","Loss function at epoch 12 and at batch 300  is  0.21569641\n","Loss function at epoch 12 and at batch 350  is  0.17190906\n","Loss function at epoch 12 and at batch 400  is  0.11839329\n","Loss function at epoch 12 and at batch 450  is  0.111163415\n","Loss function at epoch 12 and at batch 500  is  0.22408652\n","Loss function at epoch 12 and at batch 550  is  0.15430507\n","Loss function at epoch 12 and at batch 600  is  0.25156742\n","Loss function at epoch 12 and at batch 650  is  0.18966727\n","Loss function at epoch 12 and at batch 700  is  0.21045083\n","Loss function at epoch 12 and at batch 750  is  0.14453018\n","Loss function at epoch 12 and at batch 800  is  0.12730427\n","Loss function at epoch 12 and at batch 850  is  0.117494285\n","Loss function at epoch 12 and at batch 900  is  0.107962385\n","Loss function at epoch 12 and at batch 950  is  0.18617421\n","Loss function at epoch 13 and at batch 0  is  0.2108262\n","Testing test minibatch at training step  0  of epoch  13\n","Accuracy of training step 13000  =  0.9482\n","Loss function at epoch 13 and at batch 50  is  0.06547949\n","Loss function at epoch 13 and at batch 100  is  0.19066395\n","Loss function at epoch 13 and at batch 150  is  0.30093563\n","Loss function at epoch 13 and at batch 200  is  0.2774697\n","Loss function at epoch 13 and at batch 250  is  0.16890398\n","Loss function at epoch 13 and at batch 300  is  0.12101171\n","Loss function at epoch 13 and at batch 350  is  0.22764072\n","Loss function at epoch 13 and at batch 400  is  0.15107368\n","Loss function at epoch 13 and at batch 450  is  0.08522218\n","Loss function at epoch 13 and at batch 500  is  0.3739324\n","Loss function at epoch 13 and at batch 550  is  0.11151852\n","Loss function at epoch 13 and at batch 600  is  0.40641615\n","Loss function at epoch 13 and at batch 650  is  0.15568478\n","Loss function at epoch 13 and at batch 700  is  0.13051346\n","Loss function at epoch 13 and at batch 750  is  0.2804504\n","Loss function at epoch 13 and at batch 800  is  0.12614487\n","Loss function at epoch 13 and at batch 850  is  0.1886038\n","Loss function at epoch 13 and at batch 900  is  0.21541545\n","Loss function at epoch 13 and at batch 950  is  0.28501946\n","Loss function at epoch 14 and at batch 0  is  0.17732853\n","Testing test minibatch at training step  0  of epoch  14\n","Accuracy of training step 14000  =  0.9505\n","Loss function at epoch 14 and at batch 50  is  0.18080005\n","Loss function at epoch 14 and at batch 100  is  0.17049377\n","Loss function at epoch 14 and at batch 150  is  0.113395676\n","Loss function at epoch 14 and at batch 200  is  0.21022286\n","Loss function at epoch 14 and at batch 250  is  0.122916795\n","Loss function at epoch 14 and at batch 300  is  0.06602522\n","Loss function at epoch 14 and at batch 350  is  0.23678842\n","Loss function at epoch 14 and at batch 400  is  0.30238828\n","Loss function at epoch 14 and at batch 450  is  0.19492096\n","Loss function at epoch 14 and at batch 500  is  0.07563463\n","Loss function at epoch 14 and at batch 550  is  0.12933457\n","Loss function at epoch 14 and at batch 600  is  0.098028064\n","Loss function at epoch 14 and at batch 650  is  0.13863982\n","Loss function at epoch 14 and at batch 700  is  0.25316495\n","Loss function at epoch 14 and at batch 750  is  0.22774841\n","Loss function at epoch 14 and at batch 800  is  0.09894068\n","Loss function at epoch 14 and at batch 850  is  0.12138641\n","Loss function at epoch 14 and at batch 900  is  0.106322765\n","Loss function at epoch 14 and at batch 950  is  0.3084268\n","Loss function at epoch 15 and at batch 0  is  0.31343424\n","Testing test minibatch at training step  0  of epoch  15\n","Accuracy of training step 15000  =  0.953\n","Loss function at epoch 15 and at batch 50  is  0.28222036\n","Loss function at epoch 15 and at batch 100  is  0.09934586\n","Loss function at epoch 15 and at batch 150  is  0.14979462\n","Loss function at epoch 15 and at batch 200  is  0.1922931\n","Loss function at epoch 15 and at batch 250  is  0.13804275\n","Loss function at epoch 15 and at batch 300  is  0.34618336\n","Loss function at epoch 15 and at batch 350  is  0.14661115\n","Loss function at epoch 15 and at batch 400  is  0.108070634\n","Loss function at epoch 15 and at batch 450  is  0.1601776\n","Loss function at epoch 15 and at batch 500  is  0.20372246\n","Loss function at epoch 15 and at batch 550  is  0.18381561\n","Loss function at epoch 15 and at batch 600  is  0.22874425\n","Loss function at epoch 15 and at batch 650  is  0.09776353\n","Loss function at epoch 15 and at batch 700  is  0.040997896\n","Loss function at epoch 15 and at batch 750  is  0.07790509\n","Loss function at epoch 15 and at batch 800  is  0.17096956\n","Loss function at epoch 15 and at batch 850  is  0.219378\n","Loss function at epoch 15 and at batch 900  is  0.21438089\n","Loss function at epoch 15 and at batch 950  is  0.18490055\n","Loss function at epoch 16 and at batch 0  is  0.19881941\n","Testing test minibatch at training step  0  of epoch  16\n","Accuracy of training step 16000  =  0.9549\n","Loss function at epoch 16 and at batch 50  is  0.08614472\n","Loss function at epoch 16 and at batch 100  is  0.039890356\n","Loss function at epoch 16 and at batch 150  is  0.22212517\n","Loss function at epoch 16 and at batch 200  is  0.106878646\n","Loss function at epoch 16 and at batch 250  is  0.1068396\n","Loss function at epoch 16 and at batch 300  is  0.12423834\n","Loss function at epoch 16 and at batch 350  is  0.14783037\n","Loss function at epoch 16 and at batch 400  is  0.17823349\n","Loss function at epoch 16 and at batch 450  is  0.10228586\n","Loss function at epoch 16 and at batch 500  is  0.20384443\n","Loss function at epoch 16 and at batch 550  is  0.30586836\n","Loss function at epoch 16 and at batch 600  is  0.25887167\n","Loss function at epoch 16 and at batch 650  is  0.20429711\n","Loss function at epoch 16 and at batch 700  is  0.14543045\n","Loss function at epoch 16 and at batch 750  is  0.11943486\n","Loss function at epoch 16 and at batch 800  is  0.04005784\n","Loss function at epoch 16 and at batch 850  is  0.051036447\n","Loss function at epoch 16 and at batch 900  is  0.091226\n","Loss function at epoch 16 and at batch 950  is  0.16699076\n","Loss function at epoch 17 and at batch 0  is  0.24575241\n","Testing test minibatch at training step  0  of epoch  17\n","Accuracy of training step 17000  =  0.9564\n","Loss function at epoch 17 and at batch 50  is  0.17242381\n","Loss function at epoch 17 and at batch 100  is  0.38451406\n","Loss function at epoch 17 and at batch 150  is  0.10404129\n","Loss function at epoch 17 and at batch 200  is  0.10141495\n","Loss function at epoch 17 and at batch 250  is  0.15300335\n","Loss function at epoch 17 and at batch 300  is  0.09828918\n","Loss function at epoch 17 and at batch 350  is  0.16098112\n","Loss function at epoch 17 and at batch 400  is  0.067866586\n","Loss function at epoch 17 and at batch 450  is  0.23068693\n","Loss function at epoch 17 and at batch 500  is  0.17322199\n","Loss function at epoch 17 and at batch 550  is  0.14985493\n","Loss function at epoch 17 and at batch 600  is  0.16994335\n","Loss function at epoch 17 and at batch 650  is  0.047349382\n","Loss function at epoch 17 and at batch 700  is  0.05065526\n","Loss function at epoch 17 and at batch 750  is  0.089068204\n","Loss function at epoch 17 and at batch 800  is  0.13733178\n","Loss function at epoch 17 and at batch 850  is  0.096366264\n","Loss function at epoch 17 and at batch 900  is  0.045712456\n","Loss function at epoch 17 and at batch 950  is  0.092185915\n","Loss function at epoch 18 and at batch 0  is  0.09588906\n","Testing test minibatch at training step  0  of epoch  18\n","Accuracy of training step 18000  =  0.9566\n","Loss function at epoch 18 and at batch 50  is  0.11316312\n","Loss function at epoch 18 and at batch 100  is  0.11349893\n","Loss function at epoch 18 and at batch 150  is  0.06872196\n","Loss function at epoch 18 and at batch 200  is  0.2157451\n","Loss function at epoch 18 and at batch 250  is  0.096579306\n","Loss function at epoch 18 and at batch 300  is  0.17641976\n","Loss function at epoch 18 and at batch 350  is  0.08102678\n","Loss function at epoch 18 and at batch 400  is  0.1445481\n","Loss function at epoch 18 and at batch 450  is  0.27050948\n","Loss function at epoch 18 and at batch 500  is  0.13604927\n","Loss function at epoch 18 and at batch 550  is  0.072714046\n","Loss function at epoch 18 and at batch 600  is  0.16368636\n","Loss function at epoch 18 and at batch 650  is  0.07530642\n","Loss function at epoch 18 and at batch 700  is  0.2914159\n","Loss function at epoch 18 and at batch 750  is  0.20253336\n","Loss function at epoch 18 and at batch 800  is  0.2458906\n","Loss function at epoch 18 and at batch 850  is  0.04286886\n","Loss function at epoch 18 and at batch 900  is  0.07575183\n","Loss function at epoch 18 and at batch 950  is  0.16270527\n","Loss function at epoch 19 and at batch 0  is  0.18999116\n","Testing test minibatch at training step  0  of epoch  19\n","Accuracy of training step 19000  =  0.9591\n","Loss function at epoch 19 and at batch 50  is  0.1945018\n","Loss function at epoch 19 and at batch 100  is  0.104537055\n","Loss function at epoch 19 and at batch 150  is  0.17042765\n","Loss function at epoch 19 and at batch 200  is  0.4873091\n","Loss function at epoch 19 and at batch 250  is  0.18451072\n","Loss function at epoch 19 and at batch 300  is  0.10130135\n","Loss function at epoch 19 and at batch 350  is  0.2957548\n","Loss function at epoch 19 and at batch 400  is  0.1307172\n","Loss function at epoch 19 and at batch 450  is  0.094861865\n","Loss function at epoch 19 and at batch 500  is  0.09619184\n","Loss function at epoch 19 and at batch 550  is  0.14962612\n","Loss function at epoch 19 and at batch 600  is  0.05678239\n","Loss function at epoch 19 and at batch 650  is  0.24871808\n","Loss function at epoch 19 and at batch 700  is  0.094233446\n","Loss function at epoch 19 and at batch 750  is  0.11881658\n","Loss function at epoch 19 and at batch 800  is  0.023402808\n","Loss function at epoch 19 and at batch 850  is  0.23796938\n","Loss function at epoch 19 and at batch 900  is  0.055000935\n","Loss function at epoch 19 and at batch 950  is  0.18918633\n","Loss function at epoch 20 and at batch 0  is  0.062134244\n","Testing test minibatch at training step  0  of epoch  20\n","Accuracy of training step 20000  =  0.9596\n","Loss function at epoch 20 and at batch 50  is  0.20912327\n","Loss function at epoch 20 and at batch 100  is  0.19927312\n","Loss function at epoch 20 and at batch 150  is  0.06310996\n","Loss function at epoch 20 and at batch 200  is  0.109807126\n","Loss function at epoch 20 and at batch 250  is  0.21301179\n","Loss function at epoch 20 and at batch 300  is  0.1037032\n","Loss function at epoch 20 and at batch 350  is  0.13072926\n","Loss function at epoch 20 and at batch 400  is  0.08197518\n","Loss function at epoch 20 and at batch 450  is  0.17739764\n","Loss function at epoch 20 and at batch 500  is  0.18962824\n","Loss function at epoch 20 and at batch 550  is  0.07634899\n","Loss function at epoch 20 and at batch 600  is  0.16584463\n","Loss function at epoch 20 and at batch 650  is  0.17268318\n","Loss function at epoch 20 and at batch 700  is  0.07005166\n","Loss function at epoch 20 and at batch 750  is  0.04850456\n","Loss function at epoch 20 and at batch 800  is  0.073257186\n","Loss function at epoch 20 and at batch 850  is  0.09569322\n","Loss function at epoch 20 and at batch 900  is  0.23091234\n","Loss function at epoch 20 and at batch 950  is  0.1276396\n","Loss function at epoch 21 and at batch 0  is  0.12534101\n","Testing test minibatch at training step  0  of epoch  21\n","Accuracy of training step 21000  =  0.9603\n","Loss function at epoch 21 and at batch 50  is  0.14934653\n","Loss function at epoch 21 and at batch 100  is  0.03250526\n","Loss function at epoch 21 and at batch 150  is  0.14601062\n","Loss function at epoch 21 and at batch 200  is  0.1222546\n","Loss function at epoch 21 and at batch 250  is  0.06292531\n","Loss function at epoch 21 and at batch 300  is  0.09707555\n","Loss function at epoch 21 and at batch 350  is  0.22204773\n","Loss function at epoch 21 and at batch 400  is  0.106870845\n","Loss function at epoch 21 and at batch 450  is  0.12717834\n","Loss function at epoch 21 and at batch 500  is  0.07855705\n","Loss function at epoch 21 and at batch 550  is  0.109464\n","Loss function at epoch 21 and at batch 600  is  0.13456285\n","Loss function at epoch 21 and at batch 650  is  0.082204826\n","Loss function at epoch 21 and at batch 700  is  0.13630658\n","Loss function at epoch 21 and at batch 750  is  0.10685015\n","Loss function at epoch 21 and at batch 800  is  0.037664156\n","Loss function at epoch 21 and at batch 850  is  0.08403272\n","Loss function at epoch 21 and at batch 900  is  0.03286793\n","Loss function at epoch 21 and at batch 950  is  0.09574282\n","Loss function at epoch 22 and at batch 0  is  0.033892065\n","Testing test minibatch at training step  0  of epoch  22\n","Accuracy of training step 22000  =  0.9622\n","Loss function at epoch 22 and at batch 50  is  0.19052611\n","Loss function at epoch 22 and at batch 100  is  0.09333753\n","Loss function at epoch 22 and at batch 150  is  0.07516028\n","Loss function at epoch 22 and at batch 200  is  0.08092061\n","Loss function at epoch 22 and at batch 250  is  0.19646643\n","Loss function at epoch 22 and at batch 300  is  0.24651992\n","Loss function at epoch 22 and at batch 350  is  0.11578012\n","Loss function at epoch 22 and at batch 400  is  0.13876104\n","Loss function at epoch 22 and at batch 450  is  0.06084773\n","Loss function at epoch 22 and at batch 500  is  0.07536798\n","Loss function at epoch 22 and at batch 550  is  0.047427453\n","Loss function at epoch 22 and at batch 600  is  0.10848822\n","Loss function at epoch 22 and at batch 650  is  0.09871157\n","Loss function at epoch 22 and at batch 700  is  0.20873469\n","Loss function at epoch 22 and at batch 750  is  0.10794596\n","Loss function at epoch 22 and at batch 800  is  0.10548726\n","Loss function at epoch 22 and at batch 850  is  0.10051303\n","Loss function at epoch 22 and at batch 900  is  0.28577846\n","Loss function at epoch 22 and at batch 950  is  0.20079514\n","Loss function at epoch 23 and at batch 0  is  0.07465302\n","Testing test minibatch at training step  0  of epoch  23\n","Accuracy of training step 23000  =  0.9621\n","Loss function at epoch 23 and at batch 50  is  0.078271024\n","Loss function at epoch 23 and at batch 100  is  0.098943464\n","Loss function at epoch 23 and at batch 150  is  0.12936181\n","Loss function at epoch 23 and at batch 200  is  0.12585528\n","Loss function at epoch 23 and at batch 250  is  0.08348538\n","Loss function at epoch 23 and at batch 300  is  0.21456555\n","Loss function at epoch 23 and at batch 350  is  0.08115018\n","Loss function at epoch 23 and at batch 400  is  0.12976068\n","Loss function at epoch 23 and at batch 450  is  0.12476737\n","Loss function at epoch 23 and at batch 500  is  0.09293862\n","Loss function at epoch 23 and at batch 550  is  0.111604266\n","Loss function at epoch 23 and at batch 600  is  0.13737488\n","Loss function at epoch 23 and at batch 650  is  0.33904245\n","Loss function at epoch 23 and at batch 700  is  0.037990514\n","Loss function at epoch 23 and at batch 750  is  0.20339757\n","Loss function at epoch 23 and at batch 800  is  0.113072224\n","Loss function at epoch 23 and at batch 850  is  0.13795662\n","Loss function at epoch 23 and at batch 900  is  0.14016274\n","Loss function at epoch 23 and at batch 950  is  0.09538406\n","Loss function at epoch 24 and at batch 0  is  0.09020153\n","Testing test minibatch at training step  0  of epoch  24\n","Accuracy of training step 24000  =  0.9639\n","Loss function at epoch 24 and at batch 50  is  0.05750188\n","Loss function at epoch 24 and at batch 100  is  0.2288707\n","Loss function at epoch 24 and at batch 150  is  0.09113512\n","Loss function at epoch 24 and at batch 200  is  0.057791747\n","Loss function at epoch 24 and at batch 250  is  0.09581068\n","Loss function at epoch 24 and at batch 300  is  0.23416355\n","Loss function at epoch 24 and at batch 350  is  0.20497654\n","Loss function at epoch 24 and at batch 400  is  0.042450223\n","Loss function at epoch 24 and at batch 450  is  0.060359046\n","Loss function at epoch 24 and at batch 500  is  0.115966745\n","Loss function at epoch 24 and at batch 550  is  0.07797366\n","Loss function at epoch 24 and at batch 600  is  0.073676296\n","Loss function at epoch 24 and at batch 650  is  0.19789217\n","Loss function at epoch 24 and at batch 700  is  0.097247034\n","Loss function at epoch 24 and at batch 750  is  0.0484996\n","Loss function at epoch 24 and at batch 800  is  0.11057322\n","Loss function at epoch 24 and at batch 850  is  0.13562623\n","Loss function at epoch 24 and at batch 900  is  0.19138044\n","Loss function at epoch 24 and at batch 950  is  0.060437564\n","Loss function at epoch 25 and at batch 0  is  0.1283994\n","Testing test minibatch at training step  0  of epoch  25\n","Accuracy of training step 25000  =  0.9626\n","Loss function at epoch 25 and at batch 50  is  0.04703764\n","Loss function at epoch 25 and at batch 100  is  0.11191426\n","Loss function at epoch 25 and at batch 150  is  0.16807884\n","Loss function at epoch 25 and at batch 200  is  0.09305978\n","Loss function at epoch 25 and at batch 250  is  0.123672664\n","Loss function at epoch 25 and at batch 300  is  0.04862143\n","Loss function at epoch 25 and at batch 350  is  0.16147104\n","Loss function at epoch 25 and at batch 400  is  0.1383622\n","Loss function at epoch 25 and at batch 450  is  0.10434798\n","Loss function at epoch 25 and at batch 500  is  0.123254634\n","Loss function at epoch 25 and at batch 550  is  0.0608052\n","Loss function at epoch 25 and at batch 600  is  0.12919444\n","Loss function at epoch 25 and at batch 650  is  0.03144737\n","Loss function at epoch 25 and at batch 700  is  0.19326358\n","Loss function at epoch 25 and at batch 750  is  0.17628843\n","Loss function at epoch 25 and at batch 800  is  0.16570076\n","Loss function at epoch 25 and at batch 850  is  0.07135131\n","Loss function at epoch 25 and at batch 900  is  0.14810337\n","Loss function at epoch 25 and at batch 950  is  0.13928007\n","Loss function at epoch 26 and at batch 0  is  0.21758062\n","Testing test minibatch at training step  0  of epoch  26\n","Accuracy of training step 26000  =  0.964\n","Loss function at epoch 26 and at batch 50  is  0.10592577\n","Loss function at epoch 26 and at batch 100  is  0.0504613\n","Loss function at epoch 26 and at batch 150  is  0.04402359\n","Loss function at epoch 26 and at batch 200  is  0.022778131\n","Loss function at epoch 26 and at batch 250  is  0.17990847\n","Loss function at epoch 26 and at batch 300  is  0.028064765\n","Loss function at epoch 26 and at batch 350  is  0.083819345\n","Loss function at epoch 26 and at batch 400  is  0.12894887\n","Loss function at epoch 26 and at batch 450  is  0.052410707\n","Loss function at epoch 26 and at batch 500  is  0.15728149\n","Loss function at epoch 26 and at batch 550  is  0.09381943\n","Loss function at epoch 26 and at batch 600  is  0.030745737\n","Loss function at epoch 26 and at batch 650  is  0.12685688\n","Loss function at epoch 26 and at batch 700  is  0.05643841\n","Loss function at epoch 26 and at batch 750  is  0.07180924\n","Loss function at epoch 26 and at batch 800  is  0.06836382\n","Loss function at epoch 26 and at batch 850  is  0.1410318\n","Loss function at epoch 26 and at batch 900  is  0.06479983\n","Loss function at epoch 26 and at batch 950  is  0.11162753\n","Loss function at epoch 27 and at batch 0  is  0.15256292\n","Testing test minibatch at training step  0  of epoch  27\n","Accuracy of training step 27000  =  0.9642\n","Loss function at epoch 27 and at batch 50  is  0.050459225\n","Loss function at epoch 27 and at batch 100  is  0.047193076\n","Loss function at epoch 27 and at batch 150  is  0.04172181\n","Loss function at epoch 27 and at batch 200  is  0.13283385\n","Loss function at epoch 27 and at batch 250  is  0.0117816385\n","Loss function at epoch 27 and at batch 300  is  0.11451779\n","Loss function at epoch 27 and at batch 350  is  0.058199313\n","Loss function at epoch 27 and at batch 400  is  0.14328818\n","Loss function at epoch 27 and at batch 450  is  0.09044898\n","Loss function at epoch 27 and at batch 500  is  0.11837028\n","Loss function at epoch 27 and at batch 550  is  0.02520731\n","Loss function at epoch 27 and at batch 600  is  0.13996994\n","Loss function at epoch 27 and at batch 650  is  0.13737933\n","Loss function at epoch 27 and at batch 700  is  0.18612961\n","Loss function at epoch 27 and at batch 750  is  0.11494084\n","Loss function at epoch 27 and at batch 800  is  0.060539473\n","Loss function at epoch 27 and at batch 850  is  0.08276945\n","Loss function at epoch 27 and at batch 900  is  0.16316815\n","Loss function at epoch 27 and at batch 950  is  0.06524105\n","Loss function at epoch 28 and at batch 0  is  0.112758055\n","Testing test minibatch at training step  0  of epoch  28\n","Accuracy of training step 28000  =  0.965\n","Loss function at epoch 28 and at batch 50  is  0.04774555\n","Loss function at epoch 28 and at batch 100  is  0.030283943\n","Loss function at epoch 28 and at batch 150  is  0.053474106\n","Loss function at epoch 28 and at batch 200  is  0.051029753\n","Loss function at epoch 28 and at batch 250  is  0.033251807\n","Loss function at epoch 28 and at batch 300  is  0.15190455\n","Loss function at epoch 28 and at batch 350  is  0.12008982\n","Loss function at epoch 28 and at batch 400  is  0.11031963\n","Loss function at epoch 28 and at batch 450  is  0.062310297\n","Loss function at epoch 28 and at batch 500  is  0.110912666\n","Loss function at epoch 28 and at batch 550  is  0.06077719\n","Loss function at epoch 28 and at batch 600  is  0.03336116\n","Loss function at epoch 28 and at batch 650  is  0.047043357\n","Loss function at epoch 28 and at batch 700  is  0.088604465\n","Loss function at epoch 28 and at batch 750  is  0.077843815\n","Loss function at epoch 28 and at batch 800  is  0.23368159\n","Loss function at epoch 28 and at batch 850  is  0.035009157\n","Loss function at epoch 28 and at batch 900  is  0.12713449\n","Loss function at epoch 28 and at batch 950  is  0.066398196\n","Loss function at epoch 29 and at batch 0  is  0.06673677\n","Testing test minibatch at training step  0  of epoch  29\n","Accuracy of training step 29000  =  0.9662\n","Loss function at epoch 29 and at batch 50  is  0.13166592\n","Loss function at epoch 29 and at batch 100  is  0.07227607\n","Loss function at epoch 29 and at batch 150  is  0.14146963\n","Loss function at epoch 29 and at batch 200  is  0.0421517\n","Loss function at epoch 29 and at batch 250  is  0.015102455\n","Loss function at epoch 29 and at batch 300  is  0.17575556\n","Loss function at epoch 29 and at batch 350  is  0.03317774\n","Loss function at epoch 29 and at batch 400  is  0.0656447\n","Loss function at epoch 29 and at batch 450  is  0.12892255\n","Loss function at epoch 29 and at batch 500  is  0.1419501\n","Loss function at epoch 29 and at batch 550  is  0.09002999\n","Loss function at epoch 29 and at batch 600  is  0.13798349\n","Loss function at epoch 29 and at batch 650  is  0.07772011\n","Loss function at epoch 29 and at batch 700  is  0.18113367\n","Loss function at epoch 29 and at batch 750  is  0.037014253\n","Loss function at epoch 29 and at batch 800  is  0.09471878\n","Loss function at epoch 29 and at batch 850  is  0.061773177\n","Loss function at epoch 29 and at batch 900  is  0.0966206\n","Loss function at epoch 29 and at batch 950  is  0.06781846\n","Loss function at epoch 30 and at batch 0  is  0.029660875\n","Testing test minibatch at training step  0  of epoch  30\n","Accuracy of training step 30000  =  0.9656\n","Loss function at epoch 30 and at batch 50  is  0.08086405\n","Loss function at epoch 30 and at batch 100  is  0.112987556\n","Loss function at epoch 30 and at batch 150  is  0.11759416\n","Loss function at epoch 30 and at batch 200  is  0.06794294\n","Loss function at epoch 30 and at batch 250  is  0.16755289\n","Loss function at epoch 30 and at batch 300  is  0.06490034\n","Loss function at epoch 30 and at batch 350  is  0.10051802\n","Loss function at epoch 30 and at batch 400  is  0.13196601\n","Loss function at epoch 30 and at batch 450  is  0.07939723\n","Loss function at epoch 30 and at batch 500  is  0.020848382\n","Loss function at epoch 30 and at batch 550  is  0.04937156\n","Loss function at epoch 30 and at batch 600  is  0.10384322\n","Loss function at epoch 30 and at batch 650  is  0.15167376\n","Loss function at epoch 30 and at batch 700  is  0.15472616\n","Loss function at epoch 30 and at batch 750  is  0.10752969\n","Loss function at epoch 30 and at batch 800  is  0.03653784\n","Loss function at epoch 30 and at batch 850  is  0.06865273\n","Loss function at epoch 30 and at batch 900  is  0.105594486\n","Loss function at epoch 30 and at batch 950  is  0.040221535\n","Loss function at epoch 31 and at batch 0  is  0.011648111\n","Testing test minibatch at training step  0  of epoch  31\n","Accuracy of training step 31000  =  0.9659\n","Loss function at epoch 31 and at batch 50  is  0.031245487\n","Loss function at epoch 31 and at batch 100  is  0.10069705\n","Loss function at epoch 31 and at batch 150  is  0.063133076\n","Loss function at epoch 31 and at batch 200  is  0.06086129\n","Loss function at epoch 31 and at batch 250  is  0.04656882\n","Loss function at epoch 31 and at batch 300  is  0.071156316\n","Loss function at epoch 31 and at batch 350  is  0.06921274\n","Loss function at epoch 31 and at batch 400  is  0.032237433\n","Loss function at epoch 31 and at batch 450  is  0.15876195\n","Loss function at epoch 31 and at batch 500  is  0.12682122\n","Loss function at epoch 31 and at batch 550  is  0.057398178\n","Loss function at epoch 31 and at batch 600  is  0.1918906\n","Loss function at epoch 31 and at batch 650  is  0.056324743\n","Loss function at epoch 31 and at batch 700  is  0.10097533\n","Loss function at epoch 31 and at batch 750  is  0.024570322\n","Loss function at epoch 31 and at batch 800  is  0.026586486\n","Loss function at epoch 31 and at batch 850  is  0.08852699\n","Loss function at epoch 31 and at batch 900  is  0.19759971\n","Loss function at epoch 31 and at batch 950  is  0.05813022\n","Loss function at epoch 32 and at batch 0  is  0.044569615\n","Testing test minibatch at training step  0  of epoch  32\n","Accuracy of training step 32000  =  0.9666\n","Loss function at epoch 32 and at batch 50  is  0.07372367\n","Loss function at epoch 32 and at batch 100  is  0.0710756\n","Loss function at epoch 32 and at batch 150  is  0.04852149\n","Loss function at epoch 32 and at batch 200  is  0.10650637\n","Loss function at epoch 32 and at batch 250  is  0.29872003\n","Loss function at epoch 32 and at batch 300  is  0.05374516\n","Loss function at epoch 32 and at batch 350  is  0.045564376\n","Loss function at epoch 32 and at batch 400  is  0.13047776\n","Loss function at epoch 32 and at batch 450  is  0.064730704\n","Loss function at epoch 32 and at batch 500  is  0.09465609\n","Loss function at epoch 32 and at batch 550  is  0.1267923\n","Loss function at epoch 32 and at batch 600  is  0.08039208\n","Loss function at epoch 32 and at batch 650  is  0.12044135\n","Loss function at epoch 32 and at batch 700  is  0.10208512\n","Loss function at epoch 32 and at batch 750  is  0.03479968\n","Loss function at epoch 32 and at batch 800  is  0.04121474\n","Loss function at epoch 32 and at batch 850  is  0.056443628\n","Loss function at epoch 32 and at batch 900  is  0.039973333\n","Loss function at epoch 32 and at batch 950  is  0.10201209\n","Loss function at epoch 33 and at batch 0  is  0.029189782\n","Testing test minibatch at training step  0  of epoch  33\n","Accuracy of training step 33000  =  0.9664\n","Loss function at epoch 33 and at batch 50  is  0.03598634\n","Loss function at epoch 33 and at batch 100  is  0.14604937\n","Loss function at epoch 33 and at batch 150  is  0.02905022\n","Loss function at epoch 33 and at batch 200  is  0.02401802\n","Loss function at epoch 33 and at batch 250  is  0.05160556\n","Loss function at epoch 33 and at batch 300  is  0.032995585\n","Loss function at epoch 33 and at batch 350  is  0.06301208\n","Loss function at epoch 33 and at batch 400  is  0.11215356\n","Loss function at epoch 33 and at batch 450  is  0.07320691\n","Loss function at epoch 33 and at batch 500  is  0.16136323\n","Loss function at epoch 33 and at batch 550  is  0.058900665\n","Loss function at epoch 33 and at batch 600  is  0.052209083\n","Loss function at epoch 33 and at batch 650  is  0.09364529\n","Loss function at epoch 33 and at batch 700  is  0.06360492\n","Loss function at epoch 33 and at batch 750  is  0.10654016\n","Loss function at epoch 33 and at batch 800  is  0.032026067\n","Loss function at epoch 33 and at batch 850  is  0.08644261\n","Loss function at epoch 33 and at batch 900  is  0.023589656\n","Loss function at epoch 33 and at batch 950  is  0.06534542\n","Loss function at epoch 34 and at batch 0  is  0.07897242\n","Testing test minibatch at training step  0  of epoch  34\n","Accuracy of training step 34000  =  0.9675\n","Loss function at epoch 34 and at batch 50  is  0.038924944\n","Loss function at epoch 34 and at batch 100  is  0.019380393\n","Loss function at epoch 34 and at batch 150  is  0.17539108\n","Loss function at epoch 34 and at batch 200  is  0.054320063\n","Loss function at epoch 34 and at batch 250  is  0.105923735\n","Loss function at epoch 34 and at batch 300  is  0.08256247\n","Loss function at epoch 34 and at batch 350  is  0.040491574\n","Loss function at epoch 34 and at batch 400  is  0.060094025\n","Loss function at epoch 34 and at batch 450  is  0.2222526\n","Loss function at epoch 34 and at batch 500  is  0.023252217\n","Loss function at epoch 34 and at batch 550  is  0.05630338\n","Loss function at epoch 34 and at batch 600  is  0.1126648\n","Loss function at epoch 34 and at batch 650  is  0.09453898\n","Loss function at epoch 34 and at batch 700  is  0.09423964\n","Loss function at epoch 34 and at batch 750  is  0.0932724\n","Loss function at epoch 34 and at batch 800  is  0.08283095\n","Loss function at epoch 34 and at batch 850  is  0.055196505\n","Loss function at epoch 34 and at batch 900  is  0.06956123\n","Loss function at epoch 34 and at batch 950  is  0.11599554\n","Loss function at epoch 35 and at batch 0  is  0.036491625\n","Testing test minibatch at training step  0  of epoch  35\n","Accuracy of training step 35000  =  0.9673\n","Loss function at epoch 35 and at batch 50  is  0.050306458\n","Loss function at epoch 35 and at batch 100  is  0.08531903\n","Loss function at epoch 35 and at batch 150  is  0.0622021\n","Loss function at epoch 35 and at batch 200  is  0.034143515\n","Loss function at epoch 35 and at batch 250  is  0.06758204\n","Loss function at epoch 35 and at batch 300  is  0.06675529\n","Loss function at epoch 35 and at batch 350  is  0.134462\n","Loss function at epoch 35 and at batch 400  is  0.06372716\n","Loss function at epoch 35 and at batch 450  is  0.020517975\n","Loss function at epoch 35 and at batch 500  is  0.018416815\n","Loss function at epoch 35 and at batch 550  is  0.03546851\n","Loss function at epoch 35 and at batch 600  is  0.107369155\n","Loss function at epoch 35 and at batch 650  is  0.08468228\n","Loss function at epoch 35 and at batch 700  is  0.03243132\n","Loss function at epoch 35 and at batch 750  is  0.044644415\n","Loss function at epoch 35 and at batch 800  is  0.06163966\n","Loss function at epoch 35 and at batch 850  is  0.049712453\n","Loss function at epoch 35 and at batch 900  is  0.14063685\n","Loss function at epoch 35 and at batch 950  is  0.098095834\n","Loss function at epoch 36 and at batch 0  is  0.113195285\n","Testing test minibatch at training step  0  of epoch  36\n","Accuracy of training step 36000  =  0.9677\n","Loss function at epoch 36 and at batch 50  is  0.08319357\n","Loss function at epoch 36 and at batch 100  is  0.06327924\n","Loss function at epoch 36 and at batch 150  is  0.023211181\n","Loss function at epoch 36 and at batch 200  is  0.017960967\n","Loss function at epoch 36 and at batch 250  is  0.03184855\n","Loss function at epoch 36 and at batch 300  is  0.15309958\n","Loss function at epoch 36 and at batch 350  is  0.08809885\n","Loss function at epoch 36 and at batch 400  is  0.025052404\n","Loss function at epoch 36 and at batch 450  is  0.07401699\n","Loss function at epoch 36 and at batch 500  is  0.10139794\n","Loss function at epoch 36 and at batch 550  is  0.030839503\n","Loss function at epoch 36 and at batch 600  is  0.05504832\n","Loss function at epoch 36 and at batch 650  is  0.0056025987\n","Loss function at epoch 36 and at batch 700  is  0.16000846\n","Loss function at epoch 36 and at batch 750  is  0.06454466\n","Loss function at epoch 36 and at batch 800  is  0.06859844\n","Loss function at epoch 36 and at batch 850  is  0.034036852\n","Loss function at epoch 36 and at batch 900  is  0.034584094\n","Loss function at epoch 36 and at batch 950  is  0.0876198\n","Loss function at epoch 37 and at batch 0  is  0.037326608\n","Testing test minibatch at training step  0  of epoch  37\n","Accuracy of training step 37000  =  0.9675\n","Loss function at epoch 37 and at batch 50  is  0.047770232\n","Loss function at epoch 37 and at batch 100  is  0.1273058\n","Loss function at epoch 37 and at batch 150  is  0.02947274\n","Loss function at epoch 37 and at batch 200  is  0.023105692\n","Loss function at epoch 37 and at batch 250  is  0.064682215\n","Loss function at epoch 37 and at batch 300  is  0.102060124\n","Loss function at epoch 37 and at batch 350  is  0.04833088\n","Loss function at epoch 37 and at batch 400  is  0.020094777\n","Loss function at epoch 37 and at batch 450  is  0.03036202\n","Loss function at epoch 37 and at batch 500  is  0.010025512\n","Loss function at epoch 37 and at batch 550  is  0.04440567\n","Loss function at epoch 37 and at batch 600  is  0.0502098\n","Loss function at epoch 37 and at batch 650  is  0.30899817\n","Loss function at epoch 37 and at batch 700  is  0.13996454\n","Loss function at epoch 37 and at batch 750  is  0.03187414\n","Loss function at epoch 37 and at batch 800  is  0.09582544\n","Loss function at epoch 37 and at batch 850  is  0.045884818\n","Loss function at epoch 37 and at batch 900  is  0.08051154\n","Loss function at epoch 37 and at batch 950  is  0.046962615\n","Loss function at epoch 38 and at batch 0  is  0.056334347\n","Testing test minibatch at training step  0  of epoch  38\n","Accuracy of training step 38000  =  0.9692\n","Loss function at epoch 38 and at batch 50  is  0.029230237\n","Loss function at epoch 38 and at batch 100  is  0.16814466\n","Loss function at epoch 38 and at batch 150  is  0.05115968\n","Loss function at epoch 38 and at batch 200  is  0.027633678\n","Loss function at epoch 38 and at batch 250  is  0.02163927\n","Loss function at epoch 38 and at batch 300  is  0.024794817\n","Loss function at epoch 38 and at batch 350  is  0.11760453\n","Loss function at epoch 38 and at batch 400  is  0.10313512\n","Loss function at epoch 38 and at batch 450  is  0.03312885\n","Loss function at epoch 38 and at batch 500  is  0.054554436\n","Loss function at epoch 38 and at batch 550  is  0.034502707\n","Loss function at epoch 38 and at batch 600  is  0.121589534\n","Loss function at epoch 38 and at batch 650  is  0.019139212\n","Loss function at epoch 38 and at batch 700  is  0.09644329\n","Loss function at epoch 38 and at batch 750  is  0.11313508\n","Loss function at epoch 38 and at batch 800  is  0.047077596\n","Loss function at epoch 38 and at batch 850  is  0.072793536\n","Loss function at epoch 38 and at batch 900  is  0.093375295\n","Loss function at epoch 38 and at batch 950  is  0.049579475\n","Loss function at epoch 39 and at batch 0  is  0.029804366\n","Testing test minibatch at training step  0  of epoch  39\n","Accuracy of training step 39000  =  0.9695\n","Loss function at epoch 39 and at batch 50  is  0.07748995\n","Loss function at epoch 39 and at batch 100  is  0.042988423\n","Loss function at epoch 39 and at batch 150  is  0.07415851\n","Loss function at epoch 39 and at batch 200  is  0.076487504\n","Loss function at epoch 39 and at batch 250  is  0.12944487\n","Loss function at epoch 39 and at batch 300  is  0.031822786\n","Loss function at epoch 39 and at batch 350  is  0.09639622\n","Loss function at epoch 39 and at batch 400  is  0.036403984\n","Loss function at epoch 39 and at batch 450  is  0.07236981\n","Loss function at epoch 39 and at batch 500  is  0.04542198\n","Loss function at epoch 39 and at batch 550  is  0.014236741\n","Loss function at epoch 39 and at batch 600  is  0.088357784\n","Loss function at epoch 39 and at batch 650  is  0.02489582\n","Loss function at epoch 39 and at batch 700  is  0.03574682\n","Loss function at epoch 39 and at batch 750  is  0.1989483\n","Loss function at epoch 39 and at batch 800  is  0.023948496\n","Loss function at epoch 39 and at batch 850  is  0.016112223\n","Loss function at epoch 39 and at batch 900  is  0.064292826\n","Loss function at epoch 39 and at batch 950  is  0.06563952\n","Loss function at epoch 40 and at batch 0  is  0.041916635\n","Testing test minibatch at training step  0  of epoch  40\n","Accuracy of training step 40000  =  0.969\n","Loss function at epoch 40 and at batch 50  is  0.054727938\n","Loss function at epoch 40 and at batch 100  is  0.12694454\n","Loss function at epoch 40 and at batch 150  is  0.14245647\n","Loss function at epoch 40 and at batch 200  is  0.067349136\n","Loss function at epoch 40 and at batch 250  is  0.15507527\n","Loss function at epoch 40 and at batch 300  is  0.008634318\n","Loss function at epoch 40 and at batch 350  is  0.121504396\n","Loss function at epoch 40 and at batch 400  is  0.03381177\n","Loss function at epoch 40 and at batch 450  is  0.019377809\n","Loss function at epoch 40 and at batch 500  is  0.06469375\n","Loss function at epoch 40 and at batch 550  is  0.033012748\n","Loss function at epoch 40 and at batch 600  is  0.06259063\n","Loss function at epoch 40 and at batch 650  is  0.10893058\n","Loss function at epoch 40 and at batch 700  is  0.1285333\n","Loss function at epoch 40 and at batch 750  is  0.031750225\n","Loss function at epoch 40 and at batch 800  is  0.08801416\n","Loss function at epoch 40 and at batch 850  is  0.05280654\n","Loss function at epoch 40 and at batch 900  is  0.087862276\n","Loss function at epoch 40 and at batch 950  is  0.021968637\n","Loss function at epoch 41 and at batch 0  is  0.13375849\n","Testing test minibatch at training step  0  of epoch  41\n","Accuracy of training step 41000  =  0.9697\n","Loss function at epoch 41 and at batch 50  is  0.14020929\n","Loss function at epoch 41 and at batch 100  is  0.03992154\n","Loss function at epoch 41 and at batch 150  is  0.103658475\n","Loss function at epoch 41 and at batch 200  is  0.025140999\n","Loss function at epoch 41 and at batch 250  is  0.03331517\n","Loss function at epoch 41 and at batch 300  is  0.05269317\n","Loss function at epoch 41 and at batch 350  is  0.076552264\n","Loss function at epoch 41 and at batch 400  is  0.049114503\n","Loss function at epoch 41 and at batch 450  is  0.076144464\n","Loss function at epoch 41 and at batch 500  is  0.061079863\n","Loss function at epoch 41 and at batch 550  is  0.05214588\n","Loss function at epoch 41 and at batch 600  is  0.12351738\n","Loss function at epoch 41 and at batch 650  is  0.10499133\n","Loss function at epoch 41 and at batch 700  is  0.17428973\n","Loss function at epoch 41 and at batch 750  is  0.083486505\n","Loss function at epoch 41 and at batch 800  is  0.03714113\n","Loss function at epoch 41 and at batch 850  is  0.042323068\n","Loss function at epoch 41 and at batch 900  is  0.13023548\n","Loss function at epoch 41 and at batch 950  is  0.05722829\n","Loss function at epoch 42 and at batch 0  is  0.021609204\n","Testing test minibatch at training step  0  of epoch  42\n","Accuracy of training step 42000  =  0.9708\n","Loss function at epoch 42 and at batch 50  is  0.013237297\n","Loss function at epoch 42 and at batch 100  is  0.051081073\n","Loss function at epoch 42 and at batch 150  is  0.033245325\n","Loss function at epoch 42 and at batch 200  is  0.08749154\n","Loss function at epoch 42 and at batch 250  is  0.048926476\n","Loss function at epoch 42 and at batch 300  is  0.0673921\n","Loss function at epoch 42 and at batch 350  is  0.109839894\n","Loss function at epoch 42 and at batch 400  is  0.044335376\n","Loss function at epoch 42 and at batch 450  is  0.054408625\n","Loss function at epoch 42 and at batch 500  is  0.055851813\n","Loss function at epoch 42 and at batch 550  is  0.08939079\n","Loss function at epoch 42 and at batch 600  is  0.10563106\n","Loss function at epoch 42 and at batch 650  is  0.06882972\n","Loss function at epoch 42 and at batch 700  is  0.02783517\n","Loss function at epoch 42 and at batch 750  is  0.058581803\n","Loss function at epoch 42 and at batch 800  is  0.009142572\n","Loss function at epoch 42 and at batch 850  is  0.0853974\n","Loss function at epoch 42 and at batch 900  is  0.0903821\n","Loss function at epoch 42 and at batch 950  is  0.031757683\n","Loss function at epoch 43 and at batch 0  is  0.011100644\n","Testing test minibatch at training step  0  of epoch  43\n","Accuracy of training step 43000  =  0.9704\n","Loss function at epoch 43 and at batch 50  is  0.1878964\n","Loss function at epoch 43 and at batch 100  is  0.052805617\n","Loss function at epoch 43 and at batch 150  is  0.038192753\n","Loss function at epoch 43 and at batch 200  is  0.016756177\n","Loss function at epoch 43 and at batch 250  is  0.06470203\n","Loss function at epoch 43 and at batch 300  is  0.035820823\n","Loss function at epoch 43 and at batch 350  is  0.064651966\n","Loss function at epoch 43 and at batch 400  is  0.0100327935\n","Loss function at epoch 43 and at batch 450  is  0.02530677\n","Loss function at epoch 43 and at batch 500  is  0.05712116\n","Loss function at epoch 43 and at batch 550  is  0.10500604\n","Loss function at epoch 43 and at batch 600  is  0.018671032\n","Loss function at epoch 43 and at batch 650  is  0.033503827\n","Loss function at epoch 43 and at batch 700  is  0.07599143\n","Loss function at epoch 43 and at batch 750  is  0.033536535\n","Loss function at epoch 43 and at batch 800  is  0.14180323\n","Loss function at epoch 43 and at batch 850  is  0.029228218\n","Loss function at epoch 43 and at batch 900  is  0.021123968\n","Loss function at epoch 43 and at batch 950  is  0.045659173\n","Loss function at epoch 44 and at batch 0  is  0.03254535\n","Testing test minibatch at training step  0  of epoch  44\n","Accuracy of training step 44000  =  0.9704\n","Loss function at epoch 44 and at batch 50  is  0.11704386\n","Loss function at epoch 44 and at batch 100  is  0.17836985\n","Loss function at epoch 44 and at batch 150  is  0.07795134\n","Loss function at epoch 44 and at batch 200  is  0.011683266\n","Loss function at epoch 44 and at batch 250  is  0.022758469\n","Loss function at epoch 44 and at batch 300  is  0.031558324\n","Loss function at epoch 44 and at batch 350  is  0.028686319\n","Loss function at epoch 44 and at batch 400  is  0.06358786\n","Loss function at epoch 44 and at batch 450  is  0.020186814\n","Loss function at epoch 44 and at batch 500  is  0.06303309\n","Loss function at epoch 44 and at batch 550  is  0.024733847\n","Loss function at epoch 44 and at batch 600  is  0.0044202567\n","Loss function at epoch 44 and at batch 650  is  0.14226493\n","Loss function at epoch 44 and at batch 700  is  0.018018672\n","Loss function at epoch 44 and at batch 750  is  0.054901928\n","Loss function at epoch 44 and at batch 800  is  0.18328774\n","Loss function at epoch 44 and at batch 850  is  0.028746754\n","Loss function at epoch 44 and at batch 900  is  0.046745252\n","Loss function at epoch 44 and at batch 950  is  0.022630483\n","Loss function at epoch 45 and at batch 0  is  0.010280507\n","Testing test minibatch at training step  0  of epoch  45\n","Accuracy of training step 45000  =  0.9695\n","Loss function at epoch 45 and at batch 50  is  0.07269127\n","Loss function at epoch 45 and at batch 100  is  0.060301945\n","Loss function at epoch 45 and at batch 150  is  0.015018034\n","Loss function at epoch 45 and at batch 200  is  0.052117422\n","Loss function at epoch 45 and at batch 250  is  0.023677943\n","Loss function at epoch 45 and at batch 300  is  0.020508116\n","Loss function at epoch 45 and at batch 350  is  0.034026373\n","Loss function at epoch 45 and at batch 400  is  0.027542586\n","Loss function at epoch 45 and at batch 450  is  0.0106868865\n","Loss function at epoch 45 and at batch 500  is  0.06666335\n","Loss function at epoch 45 and at batch 550  is  0.022724817\n","Loss function at epoch 45 and at batch 600  is  0.07406989\n","Loss function at epoch 45 and at batch 650  is  0.035436306\n","Loss function at epoch 45 and at batch 700  is  0.006521431\n","Loss function at epoch 45 and at batch 750  is  0.05215359\n","Loss function at epoch 45 and at batch 800  is  0.026209844\n","Loss function at epoch 45 and at batch 850  is  0.04806322\n","Loss function at epoch 45 and at batch 900  is  0.0885762\n","Loss function at epoch 45 and at batch 950  is  0.029319448\n","Loss function at epoch 46 and at batch 0  is  0.07869943\n","Testing test minibatch at training step  0  of epoch  46\n","Accuracy of training step 46000  =  0.9701\n","Loss function at epoch 46 and at batch 50  is  0.009311032\n","Loss function at epoch 46 and at batch 100  is  0.015372848\n","Loss function at epoch 46 and at batch 150  is  0.06322141\n","Loss function at epoch 46 and at batch 200  is  0.013235518\n","Loss function at epoch 46 and at batch 250  is  0.012062212\n","Loss function at epoch 46 and at batch 300  is  0.009070255\n","Loss function at epoch 46 and at batch 350  is  0.018550402\n","Loss function at epoch 46 and at batch 400  is  0.017776834\n","Loss function at epoch 46 and at batch 450  is  0.015887173\n","Loss function at epoch 46 and at batch 500  is  0.07896001\n","Loss function at epoch 46 and at batch 550  is  0.09127203\n","Loss function at epoch 46 and at batch 600  is  0.024322702\n","Loss function at epoch 46 and at batch 650  is  0.028634185\n","Loss function at epoch 46 and at batch 700  is  0.0772916\n","Loss function at epoch 46 and at batch 750  is  0.10170548\n","Loss function at epoch 46 and at batch 800  is  0.18054333\n","Loss function at epoch 46 and at batch 850  is  0.032710187\n","Loss function at epoch 46 and at batch 900  is  0.07179204\n","Loss function at epoch 46 and at batch 950  is  0.035862323\n","Loss function at epoch 47 and at batch 0  is  0.008437914\n","Testing test minibatch at training step  0  of epoch  47\n","Accuracy of training step 47000  =  0.97\n","Loss function at epoch 47 and at batch 50  is  0.05212243\n","Loss function at epoch 47 and at batch 100  is  0.016027242\n","Loss function at epoch 47 and at batch 150  is  0.024754336\n","Loss function at epoch 47 and at batch 200  is  0.011369308\n","Loss function at epoch 47 and at batch 250  is  0.01472446\n","Loss function at epoch 47 and at batch 300  is  0.046266656\n","Loss function at epoch 47 and at batch 350  is  0.020676842\n","Loss function at epoch 47 and at batch 400  is  0.083907224\n","Loss function at epoch 47 and at batch 450  is  0.034970872\n","Loss function at epoch 47 and at batch 500  is  0.029415002\n","Loss function at epoch 47 and at batch 550  is  0.071961366\n","Loss function at epoch 47 and at batch 600  is  0.10093455\n","Loss function at epoch 47 and at batch 650  is  0.014180472\n","Loss function at epoch 47 and at batch 700  is  0.026939344\n","Loss function at epoch 47 and at batch 750  is  0.03961713\n","Loss function at epoch 47 and at batch 800  is  0.025907414\n","Loss function at epoch 47 and at batch 850  is  0.07072848\n","Loss function at epoch 47 and at batch 900  is  0.06074205\n","Loss function at epoch 47 and at batch 950  is  0.17776948\n","Loss function at epoch 48 and at batch 0  is  0.019823108\n","Testing test minibatch at training step  0  of epoch  48\n","Accuracy of training step 48000  =  0.9694\n","Loss function at epoch 48 and at batch 50  is  0.019291176\n","Loss function at epoch 48 and at batch 100  is  0.10402414\n","Loss function at epoch 48 and at batch 150  is  0.013816206\n","Loss function at epoch 48 and at batch 200  is  0.03857017\n","Loss function at epoch 48 and at batch 250  is  0.03472935\n","Loss function at epoch 48 and at batch 300  is  0.022140207\n","Loss function at epoch 48 and at batch 350  is  0.023159327\n","Loss function at epoch 48 and at batch 400  is  0.02227967\n","Loss function at epoch 48 and at batch 450  is  0.039245464\n","Loss function at epoch 48 and at batch 500  is  0.037222072\n","Loss function at epoch 48 and at batch 550  is  0.22951107\n","Loss function at epoch 48 and at batch 600  is  0.10756841\n","Loss function at epoch 48 and at batch 650  is  0.071448416\n","Loss function at epoch 48 and at batch 700  is  0.03267677\n","Loss function at epoch 48 and at batch 750  is  0.055387605\n","Loss function at epoch 48 and at batch 800  is  0.012228563\n","Loss function at epoch 48 and at batch 850  is  0.015460768\n","Loss function at epoch 48 and at batch 900  is  0.091305435\n","Loss function at epoch 48 and at batch 950  is  0.19535457\n","Loss function at epoch 49 and at batch 0  is  0.04746172\n","Testing test minibatch at training step  0  of epoch  49\n","Accuracy of training step 49000  =  0.9702\n","Loss function at epoch 49 and at batch 50  is  0.052647036\n","Loss function at epoch 49 and at batch 100  is  0.029154409\n","Loss function at epoch 49 and at batch 150  is  0.044286456\n","Loss function at epoch 49 and at batch 200  is  0.03646747\n","Loss function at epoch 49 and at batch 250  is  0.062634096\n","Loss function at epoch 49 and at batch 300  is  0.0337008\n","Loss function at epoch 49 and at batch 350  is  0.023433177\n","Loss function at epoch 49 and at batch 400  is  0.017284537\n","Loss function at epoch 49 and at batch 450  is  0.020229729\n","Loss function at epoch 49 and at batch 500  is  0.008142627\n","Loss function at epoch 49 and at batch 550  is  0.09197625\n","Loss function at epoch 49 and at batch 600  is  0.037197154\n","Loss function at epoch 49 and at batch 650  is  0.029166063\n","Loss function at epoch 49 and at batch 700  is  0.039271444\n","Loss function at epoch 49 and at batch 750  is  0.12860036\n","Loss function at epoch 49 and at batch 800  is  0.04489199\n","Loss function at epoch 49 and at batch 850  is  0.022537261\n","Loss function at epoch 49 and at batch 900  is  0.03323334\n","Loss function at epoch 49 and at batch 950  is  0.06757646\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tLph7EgpqdnW","colab_type":"code","outputId":"b400254d-8602-4aa6-bd60-622631939e5f","executionInfo":{"status":"ok","timestamp":1587318310280,"user_tz":-120,"elapsed":943249,"user":{"displayName":"marco sala","photoUrl":"","userId":"07284782352463012974"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# weigths and biases\n","w0 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=False) #* 0.1\n","w1 = torch.randn(H, H, device=device, dtype=dtype, requires_grad=False)    #* 0.1\n","w2 = torch.randn(H, H, device=device, dtype=dtype, requires_grad=False)    #* 0.1\n","wy = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=False)#* 0.1\n","b0 = torch.randn(1, H, device=device, dtype=dtype, requires_grad=False)    #* 0.1\n","b1 = torch.randn(1, H, device=device, dtype=dtype, requires_grad=False)    #* 0.1\n","b2 = torch.randn(1, H, device=device, dtype=dtype, requires_grad=False)    #* 0.1\n","by = torch.randn(1, D_out, device=device, dtype=dtype, requires_grad=False)#* 0.1\n","\n","# vectors to create matrices with repeating rows. Used for bias\n","ones = torch.ones(N, 1).to(device)\n","\n","#resetting variables for momentum\n","vwy  = 0\n","vby  = 0\n","vgg2 = 0\n","vbb2 = 0\n","vw2  = 0\n","vb2  = 0\n","vgg1 = 0\n","vbb1 = 0\n","vw1  = 0\n","vb1  = 0\n","vgg0 = 0\n","vbb0 = 0\n","vw0  = 0\n","vb0  = 0\n","\n","# to save the sigmoid activations\n","sigmoidActivation15PercentileNoBN = []\n","sigmoidActivation50PercentileNoBN = []\n","sigmoidActivation85PercentileNoBN = []\n","\n","# to save test accuracy along training\n","testAccuracyPerTrainingStepNoBN = []\n","\n","#training\n","learningRate = 0.1\n","for i in range(50):\n","  for j, batch in enumerate(trainloader):\n","    x = batch[0].view(N, D_in).to(device)\n","    y = batch[1].view(N, 1).to(device)\n","    ones = torch.ones(N, 1).to(device)\n","\n","    #first hidden layer\n","    h0_lin = x.mm(w0) + ones.mm(b0) \n","    h0 = h0_lin.sigmoid()\n","\n","    #second hidden layer\n","    h1_lin = h0.mm(w1) + ones.mm(b1)\n","    h1 = h1_lin.sigmoid()\n","\n","    #third hidden layer\n","    h2_lin = h1.mm(w2) + ones.mm(b2)\n","    h2 = h2_lin.sigmoid()\n","\n","    #output layer\n","    y_pred = h2.mm(wy) + ones.mm(by) \n","    \n","    loss = cross_entropy(y_pred, y)\n","    \n","    if j % 50 == 0:\n","      print(\"No BN: Loss function at epoch\", i, \"and at batch\", j, \" is \", loss.cpu().detach().numpy() )\n","    \n","    # backward pass \n","    # dL omitted so dh = dL/dh\n","\n","    #creates a matrix of N onehot vectors with the target labels\n","    y_onehot.zero_()\n","    y_onehot.scatter_(1, y, 1)\n","    dy_pred = (stable_softmax(y_pred) - y_onehot) / N \n","    dwy = h2.T.mm(dy_pred)\n","    dby = ones.T.mm(dy_pred)\n","    \n","    dh2 = dy_pred.mm(wy.T)\n","    dh2_lin = dh2 * (h2 * (1 - h2))\n","    \n","    dw2 = h1.T.mm(dh2_lin)\n","    db2 = ones.T.mm(dh2_lin)\n","    \n","    dh1 = dh2_lin.mm(w2.T)\n","    dh1_lin = dh1 * (h1 * (1 - h1))\n","    \n","    dw1 = h0.T.mm(dh1_lin)\n","    db1 = ones.T.mm(dh1_lin)\n","    \n","    dh0 = dh1_lin.mm(w1.T)\n","    dh0_lin = dh0 * (h0 * (1 - h0))\n","    \n","    dw0 = x.T.mm(dh0_lin)\n","    db0 = ones.T.mm(dh0_lin)\n","    \n","    #momentum\n","    vwy  = momentum * vwy  + (1 - momentum) * dwy \n","    vby  = momentum * vby  + (1 - momentum) * dby \n","    vgg2 = momentum * vgg2 + (1 - momentum) * dgg2\n","    vbb2 = momentum * vbb2 + (1 - momentum) * dbb2\n","    vw2  = momentum * vw2  + (1 - momentum) * dw2 \n","    vb2  = momentum * vb2  + (1 - momentum) * db2 \n","    vgg1 = momentum * vgg1 + (1 - momentum) * dgg1\n","    vbb1 = momentum * vbb1 + (1 - momentum) * dbb1\n","    vw1  = momentum * vw1  + (1 - momentum) * dw1 \n","    vb1  = momentum * vb1  + (1 - momentum) * db1 \n","    vgg0 = momentum * vgg0 + (1 - momentum) * dgg0\n","    vbb0 = momentum * vbb0 + (1 - momentum) * dbb0\n","    vw0  = momentum * vw0  + (1 - momentum) * dw0 \n","    vb0  = momentum * vb0  + (1 - momentum) * db0 \n","\n","    # update\n","    wy -= learningRate* vwy \n","    by -= learningRate* vby \n","    gg2 -= learningRate*vgg2\n","    bb2 -= learningRate*vbb2\n","    w2 -= learningRate* vw2 \n","    b2 -= learningRate* vb2 \n","    gg1 -= learningRate*vgg1\n","    bb1 -= learningRate*vbb1\n","    w1 -= learningRate* vw1 \n","    b1 -= learningRate* vb1 \n","    gg0 -= learningRate*vgg0\n","    bb0 -= learningRate*vbb0\n","    w0 -= learningRate* vw0 \n","    b0 -= learningRate* vb0 \n","\n","    # saving activations\n","    if j % 50 == 0:\n","      sigmoidActivation15PercentileNoBN.append(np.percentile(h2_lin.cpu().detach().numpy(), 15))\n","      sigmoidActivation50PercentileNoBN.append(np.percentile(h2_lin.cpu().detach().numpy(), 50))\n","      sigmoidActivation85PercentileNoBN.append(np.percentile(h2_lin.cpu().detach().numpy(), 85))\n","\n","    # test accuracy\n","    if j == 0:\n","      accuracyOfTrainingStepNoBN = []\n","\n","      #computes the test accuracy\n","      for k, testbatch in enumerate(testloader):\n","        x_test = testbatch[0].view(testbatch[0].shape[0], D_in).to(device)\n","        y_test = testbatch[1].view(testbatch[0].shape[0], 1).to(device)\n","        ones = torch.ones(testbatch[0].shape[0], 1).to(device)\n","\n","        h0_lin = x_test.mm(w0) + ones.mm(b0) #N*h\n","        h0 = h0_lin.sigmoid()\n","\n","        h1_lin = h0.mm(w1) + ones.mm(b1)\n","        h1 = h1_lin.sigmoid()\n","\n","        h2_lin = h1.mm(w2) + ones.mm(b2)\n","        h2 = h2_lin.sigmoid()\n","\n","        y_pred = h2.mm(wy) + ones.mm(by)\n","        y_prediction = stable_softmax(y_pred)\n","        y_pred_labels = y_prediction.argmax(axis=1).reshape(testbatch[0].shape[0], 1)\n","\n","        if k == 0:\n","          print(\"Testing test minibatch at training step \", j, \" of epoch \", i)\n","        accuracyOfTrainingStepNoBN.append(np.sum(y_pred_labels.cpu().numpy() == y_test.cpu().numpy()))\n","\n","      accuracyOfTrainingStepNoBN = np.sum(np.array(accuracyOfTrainingStepNoBN)) / 10000\n","      testAccuracyPerTrainingStepNoBN.append(accuracyOfTrainingStepNoBN)\n","\n","      print(\"Accuracy of training step\", i*(j+1)*1000,\" = \", accuracyOfTrainingStepNoBN )\n","      \n","\n","    \n","      \n","\n","      \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["No BN: Loss function at epoch 0 and at batch 0  is  12.852609\n","Testing test minibatch at training step  0  of epoch  0\n","Accuracy of training step 0  =  0.0857\n","No BN: Loss function at epoch 0 and at batch 50  is  2.4281685\n","No BN: Loss function at epoch 0 and at batch 100  is  2.294582\n","No BN: Loss function at epoch 0 and at batch 150  is  1.58249\n","No BN: Loss function at epoch 0 and at batch 200  is  1.6053683\n","No BN: Loss function at epoch 0 and at batch 250  is  1.699218\n","No BN: Loss function at epoch 0 and at batch 300  is  1.3737298\n","No BN: Loss function at epoch 0 and at batch 350  is  0.9381471\n","No BN: Loss function at epoch 0 and at batch 400  is  1.1583775\n","No BN: Loss function at epoch 0 and at batch 450  is  1.2375515\n","No BN: Loss function at epoch 0 and at batch 500  is  1.3124342\n","No BN: Loss function at epoch 0 and at batch 550  is  1.139562\n","No BN: Loss function at epoch 0 and at batch 600  is  1.2639474\n","No BN: Loss function at epoch 0 and at batch 650  is  0.91025317\n","No BN: Loss function at epoch 0 and at batch 700  is  0.82912475\n","No BN: Loss function at epoch 0 and at batch 750  is  0.8666427\n","No BN: Loss function at epoch 0 and at batch 800  is  0.83721936\n","No BN: Loss function at epoch 0 and at batch 850  is  1.1390374\n","No BN: Loss function at epoch 0 and at batch 900  is  0.74234486\n","No BN: Loss function at epoch 0 and at batch 950  is  0.7684575\n","No BN: Loss function at epoch 1 and at batch 0  is  0.7691671\n","Testing test minibatch at training step  0  of epoch  1\n","Accuracy of training step 1000  =  0.7488\n","No BN: Loss function at epoch 1 and at batch 50  is  0.7819277\n","No BN: Loss function at epoch 1 and at batch 100  is  0.8431157\n","No BN: Loss function at epoch 1 and at batch 150  is  0.7594825\n","No BN: Loss function at epoch 1 and at batch 200  is  0.8629377\n","No BN: Loss function at epoch 1 and at batch 250  is  0.744603\n","No BN: Loss function at epoch 1 and at batch 300  is  0.69152015\n","No BN: Loss function at epoch 1 and at batch 350  is  0.79075676\n","No BN: Loss function at epoch 1 and at batch 400  is  0.74756527\n","No BN: Loss function at epoch 1 and at batch 450  is  0.7923958\n","No BN: Loss function at epoch 1 and at batch 500  is  0.67802316\n","No BN: Loss function at epoch 1 and at batch 550  is  0.66556424\n","No BN: Loss function at epoch 1 and at batch 600  is  0.4420367\n","No BN: Loss function at epoch 1 and at batch 650  is  0.69492155\n","No BN: Loss function at epoch 1 and at batch 700  is  0.88643354\n","No BN: Loss function at epoch 1 and at batch 750  is  0.549063\n","No BN: Loss function at epoch 1 and at batch 800  is  0.6463364\n","No BN: Loss function at epoch 1 and at batch 850  is  0.8176567\n","No BN: Loss function at epoch 1 and at batch 900  is  0.53526807\n","No BN: Loss function at epoch 1 and at batch 950  is  0.37056002\n","No BN: Loss function at epoch 2 and at batch 0  is  0.45043597\n","Testing test minibatch at training step  0  of epoch  2\n","Accuracy of training step 2000  =  0.82\n","No BN: Loss function at epoch 2 and at batch 50  is  0.72494376\n","No BN: Loss function at epoch 2 and at batch 100  is  0.7105769\n","No BN: Loss function at epoch 2 and at batch 150  is  0.3453314\n","No BN: Loss function at epoch 2 and at batch 200  is  0.3670973\n","No BN: Loss function at epoch 2 and at batch 250  is  0.71776164\n","No BN: Loss function at epoch 2 and at batch 300  is  0.54100287\n","No BN: Loss function at epoch 2 and at batch 350  is  0.80022776\n","No BN: Loss function at epoch 2 and at batch 400  is  0.5965503\n","No BN: Loss function at epoch 2 and at batch 450  is  0.45512095\n","No BN: Loss function at epoch 2 and at batch 500  is  0.48457554\n","No BN: Loss function at epoch 2 and at batch 550  is  0.39497143\n","No BN: Loss function at epoch 2 and at batch 600  is  0.31240818\n","No BN: Loss function at epoch 2 and at batch 650  is  0.4245685\n","No BN: Loss function at epoch 2 and at batch 700  is  0.4111036\n","No BN: Loss function at epoch 2 and at batch 750  is  0.48921314\n","No BN: Loss function at epoch 2 and at batch 800  is  0.8230998\n","No BN: Loss function at epoch 2 and at batch 850  is  0.3276951\n","No BN: Loss function at epoch 2 and at batch 900  is  0.5582372\n","No BN: Loss function at epoch 2 and at batch 950  is  0.2601509\n","No BN: Loss function at epoch 3 and at batch 0  is  0.41576037\n","Testing test minibatch at training step  0  of epoch  3\n","Accuracy of training step 3000  =  0.8453\n","No BN: Loss function at epoch 3 and at batch 50  is  0.45242757\n","No BN: Loss function at epoch 3 and at batch 100  is  0.6036908\n","No BN: Loss function at epoch 3 and at batch 150  is  0.37991154\n","No BN: Loss function at epoch 3 and at batch 200  is  0.6738236\n","No BN: Loss function at epoch 3 and at batch 250  is  0.5932639\n","No BN: Loss function at epoch 3 and at batch 300  is  0.40236855\n","No BN: Loss function at epoch 3 and at batch 350  is  0.35906032\n","No BN: Loss function at epoch 3 and at batch 400  is  0.4541117\n","No BN: Loss function at epoch 3 and at batch 450  is  0.48951417\n","No BN: Loss function at epoch 3 and at batch 500  is  0.5551296\n","No BN: Loss function at epoch 3 and at batch 550  is  0.4093971\n","No BN: Loss function at epoch 3 and at batch 600  is  0.46179253\n","No BN: Loss function at epoch 3 and at batch 650  is  0.5528026\n","No BN: Loss function at epoch 3 and at batch 700  is  0.3476401\n","No BN: Loss function at epoch 3 and at batch 750  is  0.49517515\n","No BN: Loss function at epoch 3 and at batch 800  is  0.3567887\n","No BN: Loss function at epoch 3 and at batch 850  is  0.5005714\n","No BN: Loss function at epoch 3 and at batch 900  is  0.43741184\n","No BN: Loss function at epoch 3 and at batch 950  is  0.3380046\n","No BN: Loss function at epoch 4 and at batch 0  is  0.7316535\n","Testing test minibatch at training step  0  of epoch  4\n","Accuracy of training step 4000  =  0.8603\n","No BN: Loss function at epoch 4 and at batch 50  is  0.31099162\n","No BN: Loss function at epoch 4 and at batch 100  is  0.34391603\n","No BN: Loss function at epoch 4 and at batch 150  is  0.58867824\n","No BN: Loss function at epoch 4 and at batch 200  is  0.31476063\n","No BN: Loss function at epoch 4 and at batch 250  is  0.5153786\n","No BN: Loss function at epoch 4 and at batch 300  is  0.39149496\n","No BN: Loss function at epoch 4 and at batch 350  is  0.27094167\n","No BN: Loss function at epoch 4 and at batch 400  is  0.41418695\n","No BN: Loss function at epoch 4 and at batch 450  is  0.32108963\n","No BN: Loss function at epoch 4 and at batch 500  is  0.32147697\n","No BN: Loss function at epoch 4 and at batch 550  is  0.3468722\n","No BN: Loss function at epoch 4 and at batch 600  is  0.2768683\n","No BN: Loss function at epoch 4 and at batch 650  is  0.21437764\n","No BN: Loss function at epoch 4 and at batch 700  is  0.23442839\n","No BN: Loss function at epoch 4 and at batch 750  is  0.55841297\n","No BN: Loss function at epoch 4 and at batch 800  is  0.4905485\n","No BN: Loss function at epoch 4 and at batch 850  is  0.450046\n","No BN: Loss function at epoch 4 and at batch 900  is  0.46061745\n","No BN: Loss function at epoch 4 and at batch 950  is  0.34185088\n","No BN: Loss function at epoch 5 and at batch 0  is  0.4264708\n","Testing test minibatch at training step  0  of epoch  5\n","Accuracy of training step 5000  =  0.8714\n","No BN: Loss function at epoch 5 and at batch 50  is  0.52781105\n","No BN: Loss function at epoch 5 and at batch 100  is  0.3864856\n","No BN: Loss function at epoch 5 and at batch 150  is  0.1894524\n","No BN: Loss function at epoch 5 and at batch 200  is  0.47338018\n","No BN: Loss function at epoch 5 and at batch 250  is  0.21731824\n","No BN: Loss function at epoch 5 and at batch 300  is  0.5022428\n","No BN: Loss function at epoch 5 and at batch 350  is  0.3726199\n","No BN: Loss function at epoch 5 and at batch 400  is  0.3260156\n","No BN: Loss function at epoch 5 and at batch 450  is  0.3946979\n","No BN: Loss function at epoch 5 and at batch 500  is  0.319677\n","No BN: Loss function at epoch 5 and at batch 550  is  0.33564118\n","No BN: Loss function at epoch 5 and at batch 600  is  0.37759265\n","No BN: Loss function at epoch 5 and at batch 650  is  0.2636442\n","No BN: Loss function at epoch 5 and at batch 700  is  0.22241642\n","No BN: Loss function at epoch 5 and at batch 750  is  0.2586319\n","No BN: Loss function at epoch 5 and at batch 800  is  0.525857\n","No BN: Loss function at epoch 5 and at batch 850  is  0.2251568\n","No BN: Loss function at epoch 5 and at batch 900  is  0.27462575\n","No BN: Loss function at epoch 5 and at batch 950  is  0.5099989\n","No BN: Loss function at epoch 6 and at batch 0  is  0.44483945\n","Testing test minibatch at training step  0  of epoch  6\n","Accuracy of training step 6000  =  0.8855\n","No BN: Loss function at epoch 6 and at batch 50  is  0.18258499\n","No BN: Loss function at epoch 6 and at batch 100  is  0.21809353\n","No BN: Loss function at epoch 6 and at batch 150  is  0.24584682\n","No BN: Loss function at epoch 6 and at batch 200  is  0.2611525\n","No BN: Loss function at epoch 6 and at batch 250  is  0.41968367\n","No BN: Loss function at epoch 6 and at batch 300  is  0.42747855\n","No BN: Loss function at epoch 6 and at batch 350  is  0.34228662\n","No BN: Loss function at epoch 6 and at batch 400  is  0.47110578\n","No BN: Loss function at epoch 6 and at batch 450  is  0.18508597\n","No BN: Loss function at epoch 6 and at batch 500  is  0.40513122\n","No BN: Loss function at epoch 6 and at batch 550  is  0.28593087\n","No BN: Loss function at epoch 6 and at batch 600  is  0.18017751\n","No BN: Loss function at epoch 6 and at batch 650  is  0.24295376\n","No BN: Loss function at epoch 6 and at batch 700  is  0.38205335\n","No BN: Loss function at epoch 6 and at batch 750  is  0.39187574\n","No BN: Loss function at epoch 6 and at batch 800  is  0.4054859\n","No BN: Loss function at epoch 6 and at batch 850  is  0.37330905\n","No BN: Loss function at epoch 6 and at batch 900  is  0.35961998\n","No BN: Loss function at epoch 6 and at batch 950  is  0.34000278\n","No BN: Loss function at epoch 7 and at batch 0  is  0.16466679\n","Testing test minibatch at training step  0  of epoch  7\n","Accuracy of training step 7000  =  0.8923\n","No BN: Loss function at epoch 7 and at batch 50  is  0.32029477\n","No BN: Loss function at epoch 7 and at batch 100  is  0.23357806\n","No BN: Loss function at epoch 7 and at batch 150  is  0.3217159\n","No BN: Loss function at epoch 7 and at batch 200  is  0.41753265\n","No BN: Loss function at epoch 7 and at batch 250  is  0.5272615\n","No BN: Loss function at epoch 7 and at batch 300  is  0.49035472\n","No BN: Loss function at epoch 7 and at batch 350  is  0.19875968\n","No BN: Loss function at epoch 7 and at batch 400  is  0.39601088\n","No BN: Loss function at epoch 7 and at batch 450  is  0.28164873\n","No BN: Loss function at epoch 7 and at batch 500  is  0.3706946\n","No BN: Loss function at epoch 7 and at batch 550  is  0.25421566\n","No BN: Loss function at epoch 7 and at batch 600  is  0.31698698\n","No BN: Loss function at epoch 7 and at batch 650  is  0.49192542\n","No BN: Loss function at epoch 7 and at batch 700  is  0.12024054\n","No BN: Loss function at epoch 7 and at batch 750  is  0.37650174\n","No BN: Loss function at epoch 7 and at batch 800  is  0.37040105\n","No BN: Loss function at epoch 7 and at batch 850  is  0.42712504\n","No BN: Loss function at epoch 7 and at batch 900  is  0.21519338\n","No BN: Loss function at epoch 7 and at batch 950  is  0.47039375\n","No BN: Loss function at epoch 8 and at batch 0  is  0.32839555\n","Testing test minibatch at training step  0  of epoch  8\n","Accuracy of training step 8000  =  0.8951\n","No BN: Loss function at epoch 8 and at batch 50  is  0.2925543\n","No BN: Loss function at epoch 8 and at batch 100  is  0.24373822\n","No BN: Loss function at epoch 8 and at batch 150  is  0.45027247\n","No BN: Loss function at epoch 8 and at batch 200  is  0.28442803\n","No BN: Loss function at epoch 8 and at batch 250  is  0.24361691\n","No BN: Loss function at epoch 8 and at batch 300  is  0.27569318\n","No BN: Loss function at epoch 8 and at batch 350  is  0.20504951\n","No BN: Loss function at epoch 8 and at batch 400  is  0.52859056\n","No BN: Loss function at epoch 8 and at batch 450  is  0.31083685\n","No BN: Loss function at epoch 8 and at batch 500  is  0.2613649\n","No BN: Loss function at epoch 8 and at batch 550  is  0.3539257\n","No BN: Loss function at epoch 8 and at batch 600  is  0.37689748\n","No BN: Loss function at epoch 8 and at batch 650  is  0.24414517\n","No BN: Loss function at epoch 8 and at batch 700  is  0.26122877\n","No BN: Loss function at epoch 8 and at batch 750  is  0.2675307\n","No BN: Loss function at epoch 8 and at batch 800  is  0.33264303\n","No BN: Loss function at epoch 8 and at batch 850  is  0.21116674\n","No BN: Loss function at epoch 8 and at batch 900  is  0.33898115\n","No BN: Loss function at epoch 8 and at batch 950  is  0.18976925\n","No BN: Loss function at epoch 9 and at batch 0  is  0.33660215\n","Testing test minibatch at training step  0  of epoch  9\n","Accuracy of training step 9000  =  0.898\n","No BN: Loss function at epoch 9 and at batch 50  is  0.19248514\n","No BN: Loss function at epoch 9 and at batch 100  is  0.30096957\n","No BN: Loss function at epoch 9 and at batch 150  is  0.31645527\n","No BN: Loss function at epoch 9 and at batch 200  is  0.26476988\n","No BN: Loss function at epoch 9 and at batch 250  is  0.14704788\n","No BN: Loss function at epoch 9 and at batch 300  is  0.2057534\n","No BN: Loss function at epoch 9 and at batch 350  is  0.16433004\n","No BN: Loss function at epoch 9 and at batch 400  is  0.32178453\n","No BN: Loss function at epoch 9 and at batch 450  is  0.4272269\n","No BN: Loss function at epoch 9 and at batch 500  is  0.23399264\n","No BN: Loss function at epoch 9 and at batch 550  is  0.16518979\n","No BN: Loss function at epoch 9 and at batch 600  is  0.3165499\n","No BN: Loss function at epoch 9 and at batch 650  is  0.45407143\n","No BN: Loss function at epoch 9 and at batch 700  is  0.34680676\n","No BN: Loss function at epoch 9 and at batch 750  is  0.23473683\n","No BN: Loss function at epoch 9 and at batch 800  is  0.14594416\n","No BN: Loss function at epoch 9 and at batch 850  is  0.23675145\n","No BN: Loss function at epoch 9 and at batch 900  is  0.27202588\n","No BN: Loss function at epoch 9 and at batch 950  is  0.33436802\n","No BN: Loss function at epoch 10 and at batch 0  is  0.21697816\n","Testing test minibatch at training step  0  of epoch  10\n","Accuracy of training step 10000  =  0.9034\n","No BN: Loss function at epoch 10 and at batch 50  is  0.29522383\n","No BN: Loss function at epoch 10 and at batch 100  is  0.18080653\n","No BN: Loss function at epoch 10 and at batch 150  is  0.38505307\n","No BN: Loss function at epoch 10 and at batch 200  is  0.2919394\n","No BN: Loss function at epoch 10 and at batch 250  is  0.35673004\n","No BN: Loss function at epoch 10 and at batch 300  is  0.32973236\n","No BN: Loss function at epoch 10 and at batch 350  is  0.2165175\n","No BN: Loss function at epoch 10 and at batch 400  is  0.39124706\n","No BN: Loss function at epoch 10 and at batch 450  is  0.19298568\n","No BN: Loss function at epoch 10 and at batch 500  is  0.5174763\n","No BN: Loss function at epoch 10 and at batch 550  is  0.2788188\n","No BN: Loss function at epoch 10 and at batch 600  is  0.23521464\n","No BN: Loss function at epoch 10 and at batch 650  is  0.24171914\n","No BN: Loss function at epoch 10 and at batch 700  is  0.20092456\n","No BN: Loss function at epoch 10 and at batch 750  is  0.4839603\n","No BN: Loss function at epoch 10 and at batch 800  is  0.34539726\n","No BN: Loss function at epoch 10 and at batch 850  is  0.08892723\n","No BN: Loss function at epoch 10 and at batch 900  is  0.1926866\n","No BN: Loss function at epoch 10 and at batch 950  is  0.36079755\n","No BN: Loss function at epoch 11 and at batch 0  is  0.34283113\n","Testing test minibatch at training step  0  of epoch  11\n","Accuracy of training step 11000  =  0.9068\n","No BN: Loss function at epoch 11 and at batch 50  is  0.30725902\n","No BN: Loss function at epoch 11 and at batch 100  is  0.15449296\n","No BN: Loss function at epoch 11 and at batch 150  is  0.19945896\n","No BN: Loss function at epoch 11 and at batch 200  is  0.21109824\n","No BN: Loss function at epoch 11 and at batch 250  is  0.25487694\n","No BN: Loss function at epoch 11 and at batch 300  is  0.30570564\n","No BN: Loss function at epoch 11 and at batch 350  is  0.36422795\n","No BN: Loss function at epoch 11 and at batch 400  is  0.3522328\n","No BN: Loss function at epoch 11 and at batch 450  is  0.39265832\n","No BN: Loss function at epoch 11 and at batch 500  is  0.19065946\n","No BN: Loss function at epoch 11 and at batch 550  is  0.26613677\n","No BN: Loss function at epoch 11 and at batch 600  is  0.26556367\n","No BN: Loss function at epoch 11 and at batch 650  is  0.18098271\n","No BN: Loss function at epoch 11 and at batch 700  is  0.21782762\n","No BN: Loss function at epoch 11 and at batch 750  is  0.20320013\n","No BN: Loss function at epoch 11 and at batch 800  is  0.3163237\n","No BN: Loss function at epoch 11 and at batch 850  is  0.2715719\n","No BN: Loss function at epoch 11 and at batch 900  is  0.2974328\n","No BN: Loss function at epoch 11 and at batch 950  is  0.29541972\n","No BN: Loss function at epoch 12 and at batch 0  is  0.21416332\n","Testing test minibatch at training step  0  of epoch  12\n","Accuracy of training step 12000  =  0.9099\n","No BN: Loss function at epoch 12 and at batch 50  is  0.2533562\n","No BN: Loss function at epoch 12 and at batch 100  is  0.26531005\n","No BN: Loss function at epoch 12 and at batch 150  is  0.3601339\n","No BN: Loss function at epoch 12 and at batch 200  is  0.22133185\n","No BN: Loss function at epoch 12 and at batch 250  is  0.33897018\n","No BN: Loss function at epoch 12 and at batch 300  is  0.24976236\n","No BN: Loss function at epoch 12 and at batch 350  is  0.27139327\n","No BN: Loss function at epoch 12 and at batch 400  is  0.30296385\n","No BN: Loss function at epoch 12 and at batch 450  is  0.40395898\n","No BN: Loss function at epoch 12 and at batch 500  is  0.24218082\n","No BN: Loss function at epoch 12 and at batch 550  is  0.37429938\n","No BN: Loss function at epoch 12 and at batch 600  is  0.098975174\n","No BN: Loss function at epoch 12 and at batch 650  is  0.21368901\n","No BN: Loss function at epoch 12 and at batch 700  is  0.13001925\n","No BN: Loss function at epoch 12 and at batch 750  is  0.095941074\n","No BN: Loss function at epoch 12 and at batch 800  is  0.36718726\n","No BN: Loss function at epoch 12 and at batch 850  is  0.29870516\n","No BN: Loss function at epoch 12 and at batch 900  is  0.16033024\n","No BN: Loss function at epoch 12 and at batch 950  is  0.18734542\n","No BN: Loss function at epoch 13 and at batch 0  is  0.23791264\n","Testing test minibatch at training step  0  of epoch  13\n","Accuracy of training step 13000  =  0.9093\n","No BN: Loss function at epoch 13 and at batch 50  is  0.29076895\n","No BN: Loss function at epoch 13 and at batch 100  is  0.2070788\n","No BN: Loss function at epoch 13 and at batch 150  is  0.099222854\n","No BN: Loss function at epoch 13 and at batch 200  is  0.20748557\n","No BN: Loss function at epoch 13 and at batch 250  is  0.22052488\n","No BN: Loss function at epoch 13 and at batch 300  is  0.36998686\n","No BN: Loss function at epoch 13 and at batch 350  is  0.21035206\n","No BN: Loss function at epoch 13 and at batch 400  is  0.26516882\n","No BN: Loss function at epoch 13 and at batch 450  is  0.38276938\n","No BN: Loss function at epoch 13 and at batch 500  is  0.22440699\n","No BN: Loss function at epoch 13 and at batch 550  is  0.28548145\n","No BN: Loss function at epoch 13 and at batch 600  is  0.30267406\n","No BN: Loss function at epoch 13 and at batch 650  is  0.23637538\n","No BN: Loss function at epoch 13 and at batch 700  is  0.19675674\n","No BN: Loss function at epoch 13 and at batch 750  is  0.17959249\n","No BN: Loss function at epoch 13 and at batch 800  is  0.17350875\n","No BN: Loss function at epoch 13 and at batch 850  is  0.1695316\n","No BN: Loss function at epoch 13 and at batch 900  is  0.34984154\n","No BN: Loss function at epoch 13 and at batch 950  is  0.24668777\n","No BN: Loss function at epoch 14 and at batch 0  is  0.37234476\n","Testing test minibatch at training step  0  of epoch  14\n","Accuracy of training step 14000  =  0.911\n","No BN: Loss function at epoch 14 and at batch 50  is  0.27986094\n","No BN: Loss function at epoch 14 and at batch 100  is  0.1801595\n","No BN: Loss function at epoch 14 and at batch 150  is  0.3234461\n","No BN: Loss function at epoch 14 and at batch 200  is  0.13089497\n","No BN: Loss function at epoch 14 and at batch 250  is  0.24236397\n","No BN: Loss function at epoch 14 and at batch 300  is  0.23993716\n","No BN: Loss function at epoch 14 and at batch 350  is  0.200659\n","No BN: Loss function at epoch 14 and at batch 400  is  0.19876641\n","No BN: Loss function at epoch 14 and at batch 450  is  0.3227861\n","No BN: Loss function at epoch 14 and at batch 500  is  0.19893491\n","No BN: Loss function at epoch 14 and at batch 550  is  0.2515475\n","No BN: Loss function at epoch 14 and at batch 600  is  0.10812848\n","No BN: Loss function at epoch 14 and at batch 650  is  0.27498615\n","No BN: Loss function at epoch 14 and at batch 700  is  0.39448097\n","No BN: Loss function at epoch 14 and at batch 750  is  0.21114099\n","No BN: Loss function at epoch 14 and at batch 800  is  0.19114156\n","No BN: Loss function at epoch 14 and at batch 850  is  0.23229727\n","No BN: Loss function at epoch 14 and at batch 900  is  0.1610864\n","No BN: Loss function at epoch 14 and at batch 950  is  0.10640375\n","No BN: Loss function at epoch 15 and at batch 0  is  0.099211745\n","Testing test minibatch at training step  0  of epoch  15\n","Accuracy of training step 15000  =  0.9138\n","No BN: Loss function at epoch 15 and at batch 50  is  0.16678922\n","No BN: Loss function at epoch 15 and at batch 100  is  0.06838143\n","No BN: Loss function at epoch 15 and at batch 150  is  0.20476055\n","No BN: Loss function at epoch 15 and at batch 200  is  0.27662477\n","No BN: Loss function at epoch 15 and at batch 250  is  0.17218037\n","No BN: Loss function at epoch 15 and at batch 300  is  0.13977376\n","No BN: Loss function at epoch 15 and at batch 350  is  0.38545948\n","No BN: Loss function at epoch 15 and at batch 400  is  0.09067305\n","No BN: Loss function at epoch 15 and at batch 450  is  0.25989446\n","No BN: Loss function at epoch 15 and at batch 500  is  0.23564568\n","No BN: Loss function at epoch 15 and at batch 550  is  0.3220705\n","No BN: Loss function at epoch 15 and at batch 600  is  0.19347256\n","No BN: Loss function at epoch 15 and at batch 650  is  0.29548958\n","No BN: Loss function at epoch 15 and at batch 700  is  0.15291443\n","No BN: Loss function at epoch 15 and at batch 750  is  0.12602207\n","No BN: Loss function at epoch 15 and at batch 800  is  0.25858575\n","No BN: Loss function at epoch 15 and at batch 850  is  0.25336424\n","No BN: Loss function at epoch 15 and at batch 900  is  0.41748628\n","No BN: Loss function at epoch 15 and at batch 950  is  0.30482772\n","No BN: Loss function at epoch 16 and at batch 0  is  0.25530285\n","Testing test minibatch at training step  0  of epoch  16\n","Accuracy of training step 16000  =  0.9165\n","No BN: Loss function at epoch 16 and at batch 50  is  0.12723\n","No BN: Loss function at epoch 16 and at batch 100  is  0.25901622\n","No BN: Loss function at epoch 16 and at batch 150  is  0.22889808\n","No BN: Loss function at epoch 16 and at batch 200  is  0.16766192\n","No BN: Loss function at epoch 16 and at batch 250  is  0.15297176\n","No BN: Loss function at epoch 16 and at batch 300  is  0.21630305\n","No BN: Loss function at epoch 16 and at batch 350  is  0.13198666\n","No BN: Loss function at epoch 16 and at batch 400  is  0.18855986\n","No BN: Loss function at epoch 16 and at batch 450  is  0.104961924\n","No BN: Loss function at epoch 16 and at batch 500  is  0.04876966\n","No BN: Loss function at epoch 16 and at batch 550  is  0.1266556\n","No BN: Loss function at epoch 16 and at batch 600  is  0.2790414\n","No BN: Loss function at epoch 16 and at batch 650  is  0.2188228\n","No BN: Loss function at epoch 16 and at batch 700  is  0.14643441\n","No BN: Loss function at epoch 16 and at batch 750  is  0.315683\n","No BN: Loss function at epoch 16 and at batch 800  is  0.2022693\n","No BN: Loss function at epoch 16 and at batch 850  is  0.17965114\n","No BN: Loss function at epoch 16 and at batch 900  is  0.078802496\n","No BN: Loss function at epoch 16 and at batch 950  is  0.112503\n","No BN: Loss function at epoch 17 and at batch 0  is  0.2750534\n","Testing test minibatch at training step  0  of epoch  17\n","Accuracy of training step 17000  =  0.9171\n","No BN: Loss function at epoch 17 and at batch 50  is  0.22734098\n","No BN: Loss function at epoch 17 and at batch 100  is  0.17100854\n","No BN: Loss function at epoch 17 and at batch 150  is  0.40363076\n","No BN: Loss function at epoch 17 and at batch 200  is  0.12908562\n","No BN: Loss function at epoch 17 and at batch 250  is  0.2662496\n","No BN: Loss function at epoch 17 and at batch 300  is  0.130097\n","No BN: Loss function at epoch 17 and at batch 350  is  0.24830936\n","No BN: Loss function at epoch 17 and at batch 400  is  0.07133607\n","No BN: Loss function at epoch 17 and at batch 450  is  0.12566386\n","No BN: Loss function at epoch 17 and at batch 500  is  0.22492103\n","No BN: Loss function at epoch 17 and at batch 550  is  0.18599574\n","No BN: Loss function at epoch 17 and at batch 600  is  0.17423023\n","No BN: Loss function at epoch 17 and at batch 650  is  0.18030867\n","No BN: Loss function at epoch 17 and at batch 700  is  0.23849271\n","No BN: Loss function at epoch 17 and at batch 750  is  0.2195891\n","No BN: Loss function at epoch 17 and at batch 800  is  0.23391445\n","No BN: Loss function at epoch 17 and at batch 850  is  0.14515889\n","No BN: Loss function at epoch 17 and at batch 900  is  0.2194934\n","No BN: Loss function at epoch 17 and at batch 950  is  0.15223037\n","No BN: Loss function at epoch 18 and at batch 0  is  0.17639412\n","Testing test minibatch at training step  0  of epoch  18\n","Accuracy of training step 18000  =  0.9159\n","No BN: Loss function at epoch 18 and at batch 50  is  0.38303593\n","No BN: Loss function at epoch 18 and at batch 100  is  0.15962224\n","No BN: Loss function at epoch 18 and at batch 150  is  0.1518212\n","No BN: Loss function at epoch 18 and at batch 200  is  0.16853562\n","No BN: Loss function at epoch 18 and at batch 250  is  0.12640174\n","No BN: Loss function at epoch 18 and at batch 300  is  0.3191238\n","No BN: Loss function at epoch 18 and at batch 350  is  0.1328735\n","No BN: Loss function at epoch 18 and at batch 400  is  0.21483515\n","No BN: Loss function at epoch 18 and at batch 450  is  0.207727\n","No BN: Loss function at epoch 18 and at batch 500  is  0.19155008\n","No BN: Loss function at epoch 18 and at batch 550  is  0.11196281\n","No BN: Loss function at epoch 18 and at batch 600  is  0.14952235\n","No BN: Loss function at epoch 18 and at batch 650  is  0.22273232\n","No BN: Loss function at epoch 18 and at batch 700  is  0.390455\n","No BN: Loss function at epoch 18 and at batch 750  is  0.20091398\n","No BN: Loss function at epoch 18 and at batch 800  is  0.2051196\n","No BN: Loss function at epoch 18 and at batch 850  is  0.07798915\n","No BN: Loss function at epoch 18 and at batch 900  is  0.23310825\n","No BN: Loss function at epoch 18 and at batch 950  is  0.06722429\n","No BN: Loss function at epoch 19 and at batch 0  is  0.108515695\n","Testing test minibatch at training step  0  of epoch  19\n","Accuracy of training step 19000  =  0.919\n","No BN: Loss function at epoch 19 and at batch 50  is  0.10016374\n","No BN: Loss function at epoch 19 and at batch 100  is  0.20874555\n","No BN: Loss function at epoch 19 and at batch 150  is  0.16658036\n","No BN: Loss function at epoch 19 and at batch 200  is  0.31920505\n","No BN: Loss function at epoch 19 and at batch 250  is  0.17760158\n","No BN: Loss function at epoch 19 and at batch 300  is  0.19273148\n","No BN: Loss function at epoch 19 and at batch 350  is  0.16989185\n","No BN: Loss function at epoch 19 and at batch 400  is  0.19544472\n","No BN: Loss function at epoch 19 and at batch 450  is  0.124798335\n","No BN: Loss function at epoch 19 and at batch 500  is  0.20268285\n","No BN: Loss function at epoch 19 and at batch 550  is  0.10951896\n","No BN: Loss function at epoch 19 and at batch 600  is  0.13825606\n","No BN: Loss function at epoch 19 and at batch 650  is  0.11809882\n","No BN: Loss function at epoch 19 and at batch 700  is  0.10844536\n","No BN: Loss function at epoch 19 and at batch 750  is  0.12917517\n","No BN: Loss function at epoch 19 and at batch 800  is  0.18020155\n","No BN: Loss function at epoch 19 and at batch 850  is  0.09319166\n","No BN: Loss function at epoch 19 and at batch 900  is  0.3611981\n","No BN: Loss function at epoch 19 and at batch 950  is  0.20538108\n","No BN: Loss function at epoch 20 and at batch 0  is  0.11011977\n","Testing test minibatch at training step  0  of epoch  20\n","Accuracy of training step 20000  =  0.9186\n","No BN: Loss function at epoch 20 and at batch 50  is  0.15262589\n","No BN: Loss function at epoch 20 and at batch 100  is  0.05801331\n","No BN: Loss function at epoch 20 and at batch 150  is  0.06673811\n","No BN: Loss function at epoch 20 and at batch 200  is  0.31245762\n","No BN: Loss function at epoch 20 and at batch 250  is  0.21375108\n","No BN: Loss function at epoch 20 and at batch 300  is  0.093320124\n","No BN: Loss function at epoch 20 and at batch 350  is  0.13734895\n","No BN: Loss function at epoch 20 and at batch 400  is  0.17318389\n","No BN: Loss function at epoch 20 and at batch 450  is  0.19404168\n","No BN: Loss function at epoch 20 and at batch 500  is  0.24040408\n","No BN: Loss function at epoch 20 and at batch 550  is  0.074798554\n","No BN: Loss function at epoch 20 and at batch 600  is  0.14092067\n","No BN: Loss function at epoch 20 and at batch 650  is  0.06875576\n","No BN: Loss function at epoch 20 and at batch 700  is  0.09720585\n","No BN: Loss function at epoch 20 and at batch 750  is  0.095544845\n","No BN: Loss function at epoch 20 and at batch 800  is  0.23698509\n","No BN: Loss function at epoch 20 and at batch 850  is  0.16928108\n","No BN: Loss function at epoch 20 and at batch 900  is  0.17675863\n","No BN: Loss function at epoch 20 and at batch 950  is  0.21159118\n","No BN: Loss function at epoch 21 and at batch 0  is  0.25196907\n","Testing test minibatch at training step  0  of epoch  21\n","Accuracy of training step 21000  =  0.9206\n","No BN: Loss function at epoch 21 and at batch 50  is  0.15259495\n","No BN: Loss function at epoch 21 and at batch 100  is  0.13807333\n","No BN: Loss function at epoch 21 and at batch 150  is  0.1590171\n","No BN: Loss function at epoch 21 and at batch 200  is  0.20233947\n","No BN: Loss function at epoch 21 and at batch 250  is  0.21116664\n","No BN: Loss function at epoch 21 and at batch 300  is  0.21404976\n","No BN: Loss function at epoch 21 and at batch 350  is  0.10602802\n","No BN: Loss function at epoch 21 and at batch 400  is  0.17887183\n","No BN: Loss function at epoch 21 and at batch 450  is  0.12625967\n","No BN: Loss function at epoch 21 and at batch 500  is  0.11345006\n","No BN: Loss function at epoch 21 and at batch 550  is  0.18417066\n","No BN: Loss function at epoch 21 and at batch 600  is  0.11513478\n","No BN: Loss function at epoch 21 and at batch 650  is  0.111849844\n","No BN: Loss function at epoch 21 and at batch 700  is  0.11567818\n","No BN: Loss function at epoch 21 and at batch 750  is  0.41544533\n","No BN: Loss function at epoch 21 and at batch 800  is  0.24368869\n","No BN: Loss function at epoch 21 and at batch 850  is  0.06362504\n","No BN: Loss function at epoch 21 and at batch 900  is  0.18773684\n","No BN: Loss function at epoch 21 and at batch 950  is  0.30088052\n","No BN: Loss function at epoch 22 and at batch 0  is  0.15900284\n","Testing test minibatch at training step  0  of epoch  22\n","Accuracy of training step 22000  =  0.9203\n","No BN: Loss function at epoch 22 and at batch 50  is  0.26679704\n","No BN: Loss function at epoch 22 and at batch 100  is  0.1041226\n","No BN: Loss function at epoch 22 and at batch 150  is  0.19353004\n","No BN: Loss function at epoch 22 and at batch 200  is  0.11889102\n","No BN: Loss function at epoch 22 and at batch 250  is  0.07997172\n","No BN: Loss function at epoch 22 and at batch 300  is  0.074358486\n","No BN: Loss function at epoch 22 and at batch 350  is  0.23324588\n","No BN: Loss function at epoch 22 and at batch 400  is  0.26396\n","No BN: Loss function at epoch 22 and at batch 450  is  0.091277316\n","No BN: Loss function at epoch 22 and at batch 500  is  0.08595608\n","No BN: Loss function at epoch 22 and at batch 550  is  0.25173324\n","No BN: Loss function at epoch 22 and at batch 600  is  0.14505598\n","No BN: Loss function at epoch 22 and at batch 650  is  0.36083215\n","No BN: Loss function at epoch 22 and at batch 700  is  0.20603877\n","No BN: Loss function at epoch 22 and at batch 750  is  0.19722743\n","No BN: Loss function at epoch 22 and at batch 800  is  0.13637532\n","No BN: Loss function at epoch 22 and at batch 850  is  0.33951718\n","No BN: Loss function at epoch 22 and at batch 900  is  0.057284422\n","No BN: Loss function at epoch 22 and at batch 950  is  0.15829274\n","No BN: Loss function at epoch 23 and at batch 0  is  0.12093823\n","Testing test minibatch at training step  0  of epoch  23\n","Accuracy of training step 23000  =  0.9229\n","No BN: Loss function at epoch 23 and at batch 50  is  0.09252419\n","No BN: Loss function at epoch 23 and at batch 100  is  0.24827108\n","No BN: Loss function at epoch 23 and at batch 150  is  0.17155565\n","No BN: Loss function at epoch 23 and at batch 200  is  0.33442652\n","No BN: Loss function at epoch 23 and at batch 250  is  0.19575872\n","No BN: Loss function at epoch 23 and at batch 300  is  0.2962788\n","No BN: Loss function at epoch 23 and at batch 350  is  0.104144104\n","No BN: Loss function at epoch 23 and at batch 400  is  0.29714325\n","No BN: Loss function at epoch 23 and at batch 450  is  0.23394312\n","No BN: Loss function at epoch 23 and at batch 500  is  0.21569143\n","No BN: Loss function at epoch 23 and at batch 550  is  0.2549381\n","No BN: Loss function at epoch 23 and at batch 600  is  0.18034826\n","No BN: Loss function at epoch 23 and at batch 650  is  0.1949392\n","No BN: Loss function at epoch 23 and at batch 700  is  0.11715559\n","No BN: Loss function at epoch 23 and at batch 750  is  0.22113071\n","No BN: Loss function at epoch 23 and at batch 800  is  0.20904672\n","No BN: Loss function at epoch 23 and at batch 850  is  0.17975014\n","No BN: Loss function at epoch 23 and at batch 900  is  0.11331934\n","No BN: Loss function at epoch 23 and at batch 950  is  0.060296126\n","No BN: Loss function at epoch 24 and at batch 0  is  0.10707143\n","Testing test minibatch at training step  0  of epoch  24\n","Accuracy of training step 24000  =  0.923\n","No BN: Loss function at epoch 24 and at batch 50  is  0.21333429\n","No BN: Loss function at epoch 24 and at batch 100  is  0.1813976\n","No BN: Loss function at epoch 24 and at batch 150  is  0.08891055\n","No BN: Loss function at epoch 24 and at batch 200  is  0.23324949\n","No BN: Loss function at epoch 24 and at batch 250  is  0.37327057\n","No BN: Loss function at epoch 24 and at batch 300  is  0.04992571\n","No BN: Loss function at epoch 24 and at batch 350  is  0.31080234\n","No BN: Loss function at epoch 24 and at batch 400  is  0.3173787\n","No BN: Loss function at epoch 24 and at batch 450  is  0.31882343\n","No BN: Loss function at epoch 24 and at batch 500  is  0.3228837\n","No BN: Loss function at epoch 24 and at batch 550  is  0.40881792\n","No BN: Loss function at epoch 24 and at batch 600  is  0.30196968\n","No BN: Loss function at epoch 24 and at batch 650  is  0.15894742\n","No BN: Loss function at epoch 24 and at batch 700  is  0.10323487\n","No BN: Loss function at epoch 24 and at batch 750  is  0.08987057\n","No BN: Loss function at epoch 24 and at batch 800  is  0.18019035\n","No BN: Loss function at epoch 24 and at batch 850  is  0.24519432\n","No BN: Loss function at epoch 24 and at batch 900  is  0.12770624\n","No BN: Loss function at epoch 24 and at batch 950  is  0.17588893\n","No BN: Loss function at epoch 25 and at batch 0  is  0.03369134\n","Testing test minibatch at training step  0  of epoch  25\n","Accuracy of training step 25000  =  0.924\n","No BN: Loss function at epoch 25 and at batch 50  is  0.20804054\n","No BN: Loss function at epoch 25 and at batch 100  is  0.20762667\n","No BN: Loss function at epoch 25 and at batch 150  is  0.14817816\n","No BN: Loss function at epoch 25 and at batch 200  is  0.09484323\n","No BN: Loss function at epoch 25 and at batch 250  is  0.15586266\n","No BN: Loss function at epoch 25 and at batch 300  is  0.2411394\n","No BN: Loss function at epoch 25 and at batch 350  is  0.17439386\n","No BN: Loss function at epoch 25 and at batch 400  is  0.20934342\n","No BN: Loss function at epoch 25 and at batch 450  is  0.17125742\n","No BN: Loss function at epoch 25 and at batch 500  is  0.14695713\n","No BN: Loss function at epoch 25 and at batch 550  is  0.09609394\n","No BN: Loss function at epoch 25 and at batch 600  is  0.1443461\n","No BN: Loss function at epoch 25 and at batch 650  is  0.22811493\n","No BN: Loss function at epoch 25 and at batch 700  is  0.06952544\n","No BN: Loss function at epoch 25 and at batch 750  is  0.13033298\n","No BN: Loss function at epoch 25 and at batch 800  is  0.3044553\n","No BN: Loss function at epoch 25 and at batch 850  is  0.16209657\n","No BN: Loss function at epoch 25 and at batch 900  is  0.13705738\n","No BN: Loss function at epoch 25 and at batch 950  is  0.2354577\n","No BN: Loss function at epoch 26 and at batch 0  is  0.1608855\n","Testing test minibatch at training step  0  of epoch  26\n","Accuracy of training step 26000  =  0.9245\n","No BN: Loss function at epoch 26 and at batch 50  is  0.22043796\n","No BN: Loss function at epoch 26 and at batch 100  is  0.14403598\n","No BN: Loss function at epoch 26 and at batch 150  is  0.08375153\n","No BN: Loss function at epoch 26 and at batch 200  is  0.1452022\n","No BN: Loss function at epoch 26 and at batch 250  is  0.1227606\n","No BN: Loss function at epoch 26 and at batch 300  is  0.30381283\n","No BN: Loss function at epoch 26 and at batch 350  is  0.1049414\n","No BN: Loss function at epoch 26 and at batch 400  is  0.09020278\n","No BN: Loss function at epoch 26 and at batch 450  is  0.13306218\n","No BN: Loss function at epoch 26 and at batch 500  is  0.18969916\n","No BN: Loss function at epoch 26 and at batch 550  is  0.11360914\n","No BN: Loss function at epoch 26 and at batch 600  is  0.07690005\n","No BN: Loss function at epoch 26 and at batch 650  is  0.14886723\n","No BN: Loss function at epoch 26 and at batch 700  is  0.0982338\n","No BN: Loss function at epoch 26 and at batch 750  is  0.17481619\n","No BN: Loss function at epoch 26 and at batch 800  is  0.11998535\n","No BN: Loss function at epoch 26 and at batch 850  is  0.06302716\n","No BN: Loss function at epoch 26 and at batch 900  is  0.030019706\n","No BN: Loss function at epoch 26 and at batch 950  is  0.13970721\n","No BN: Loss function at epoch 27 and at batch 0  is  0.18987371\n","Testing test minibatch at training step  0  of epoch  27\n","Accuracy of training step 27000  =  0.9272\n","No BN: Loss function at epoch 27 and at batch 50  is  0.06582502\n","No BN: Loss function at epoch 27 and at batch 100  is  0.18325365\n","No BN: Loss function at epoch 27 and at batch 150  is  0.11734168\n","No BN: Loss function at epoch 27 and at batch 200  is  0.19720039\n","No BN: Loss function at epoch 27 and at batch 250  is  0.15881161\n","No BN: Loss function at epoch 27 and at batch 300  is  0.24523716\n","No BN: Loss function at epoch 27 and at batch 350  is  0.13492101\n","No BN: Loss function at epoch 27 and at batch 400  is  0.11505932\n","No BN: Loss function at epoch 27 and at batch 450  is  0.20608582\n","No BN: Loss function at epoch 27 and at batch 500  is  0.21657695\n","No BN: Loss function at epoch 27 and at batch 550  is  0.042771887\n","No BN: Loss function at epoch 27 and at batch 600  is  0.09985\n","No BN: Loss function at epoch 27 and at batch 650  is  0.10531725\n","No BN: Loss function at epoch 27 and at batch 700  is  0.20650055\n","No BN: Loss function at epoch 27 and at batch 750  is  0.11096968\n","No BN: Loss function at epoch 27 and at batch 800  is  0.086290285\n","No BN: Loss function at epoch 27 and at batch 850  is  0.11919159\n","No BN: Loss function at epoch 27 and at batch 900  is  0.15867577\n","No BN: Loss function at epoch 27 and at batch 950  is  0.21450368\n","No BN: Loss function at epoch 28 and at batch 0  is  0.1661424\n","Testing test minibatch at training step  0  of epoch  28\n","Accuracy of training step 28000  =  0.925\n","No BN: Loss function at epoch 28 and at batch 50  is  0.19039237\n","No BN: Loss function at epoch 28 and at batch 100  is  0.11775919\n","No BN: Loss function at epoch 28 and at batch 150  is  0.065779544\n","No BN: Loss function at epoch 28 and at batch 200  is  0.17410535\n","No BN: Loss function at epoch 28 and at batch 250  is  0.110321894\n","No BN: Loss function at epoch 28 and at batch 300  is  0.14946271\n","No BN: Loss function at epoch 28 and at batch 350  is  0.05527693\n","No BN: Loss function at epoch 28 and at batch 400  is  0.048799492\n","No BN: Loss function at epoch 28 and at batch 450  is  0.049891792\n","No BN: Loss function at epoch 28 and at batch 500  is  0.15192837\n","No BN: Loss function at epoch 28 and at batch 550  is  0.20809105\n","No BN: Loss function at epoch 28 and at batch 600  is  0.1256725\n","No BN: Loss function at epoch 28 and at batch 650  is  0.1556862\n","No BN: Loss function at epoch 28 and at batch 700  is  0.09758957\n","No BN: Loss function at epoch 28 and at batch 750  is  0.09321162\n","No BN: Loss function at epoch 28 and at batch 800  is  0.09076777\n","No BN: Loss function at epoch 28 and at batch 850  is  0.23576094\n","No BN: Loss function at epoch 28 and at batch 900  is  0.119035244\n","No BN: Loss function at epoch 28 and at batch 950  is  0.18384641\n","No BN: Loss function at epoch 29 and at batch 0  is  0.10173666\n","Testing test minibatch at training step  0  of epoch  29\n","Accuracy of training step 29000  =  0.9278\n","No BN: Loss function at epoch 29 and at batch 50  is  0.06511734\n","No BN: Loss function at epoch 29 and at batch 100  is  0.07637153\n","No BN: Loss function at epoch 29 and at batch 150  is  0.21367612\n","No BN: Loss function at epoch 29 and at batch 200  is  0.12310169\n","No BN: Loss function at epoch 29 and at batch 250  is  0.24659026\n","No BN: Loss function at epoch 29 and at batch 300  is  0.101517975\n","No BN: Loss function at epoch 29 and at batch 350  is  0.061194804\n","No BN: Loss function at epoch 29 and at batch 400  is  0.22214563\n","No BN: Loss function at epoch 29 and at batch 450  is  0.21133167\n","No BN: Loss function at epoch 29 and at batch 500  is  0.12450711\n","No BN: Loss function at epoch 29 and at batch 550  is  0.16708976\n","No BN: Loss function at epoch 29 and at batch 600  is  0.103035055\n","No BN: Loss function at epoch 29 and at batch 650  is  0.18662131\n","No BN: Loss function at epoch 29 and at batch 700  is  0.07928089\n","No BN: Loss function at epoch 29 and at batch 750  is  0.15723018\n","No BN: Loss function at epoch 29 and at batch 800  is  0.13674049\n","No BN: Loss function at epoch 29 and at batch 850  is  0.04304624\n","No BN: Loss function at epoch 29 and at batch 900  is  0.093511984\n","No BN: Loss function at epoch 29 and at batch 950  is  0.13005854\n","No BN: Loss function at epoch 30 and at batch 0  is  0.04865013\n","Testing test minibatch at training step  0  of epoch  30\n","Accuracy of training step 30000  =  0.9281\n","No BN: Loss function at epoch 30 and at batch 50  is  0.15210964\n","No BN: Loss function at epoch 30 and at batch 100  is  0.14708571\n","No BN: Loss function at epoch 30 and at batch 150  is  0.14560334\n","No BN: Loss function at epoch 30 and at batch 200  is  0.3246675\n","No BN: Loss function at epoch 30 and at batch 250  is  0.08872396\n","No BN: Loss function at epoch 30 and at batch 300  is  0.16010273\n","No BN: Loss function at epoch 30 and at batch 350  is  0.22077377\n","No BN: Loss function at epoch 30 and at batch 400  is  0.28772265\n","No BN: Loss function at epoch 30 and at batch 450  is  0.109934814\n","No BN: Loss function at epoch 30 and at batch 500  is  0.20957607\n","No BN: Loss function at epoch 30 and at batch 550  is  0.39520603\n","No BN: Loss function at epoch 30 and at batch 600  is  0.097746305\n","No BN: Loss function at epoch 30 and at batch 650  is  0.20345539\n","No BN: Loss function at epoch 30 and at batch 700  is  0.11031468\n","No BN: Loss function at epoch 30 and at batch 750  is  0.031984657\n","No BN: Loss function at epoch 30 and at batch 800  is  0.2320663\n","No BN: Loss function at epoch 30 and at batch 850  is  0.38029838\n","No BN: Loss function at epoch 30 and at batch 900  is  0.2024247\n","No BN: Loss function at epoch 30 and at batch 950  is  0.21708634\n","No BN: Loss function at epoch 31 and at batch 0  is  0.074454635\n","Testing test minibatch at training step  0  of epoch  31\n","Accuracy of training step 31000  =  0.9269\n","No BN: Loss function at epoch 31 and at batch 50  is  0.11152214\n","No BN: Loss function at epoch 31 and at batch 100  is  0.12778074\n","No BN: Loss function at epoch 31 and at batch 150  is  0.11320354\n","No BN: Loss function at epoch 31 and at batch 200  is  0.103817485\n","No BN: Loss function at epoch 31 and at batch 250  is  0.15819022\n","No BN: Loss function at epoch 31 and at batch 300  is  0.1926558\n","No BN: Loss function at epoch 31 and at batch 350  is  0.13391888\n","No BN: Loss function at epoch 31 and at batch 400  is  0.060259752\n","No BN: Loss function at epoch 31 and at batch 450  is  0.19613421\n","No BN: Loss function at epoch 31 and at batch 500  is  0.09138554\n","No BN: Loss function at epoch 31 and at batch 550  is  0.13517842\n","No BN: Loss function at epoch 31 and at batch 600  is  0.2574455\n","No BN: Loss function at epoch 31 and at batch 650  is  0.100735374\n","No BN: Loss function at epoch 31 and at batch 700  is  0.17771327\n","No BN: Loss function at epoch 31 and at batch 750  is  0.15300374\n","No BN: Loss function at epoch 31 and at batch 800  is  0.2224401\n","No BN: Loss function at epoch 31 and at batch 850  is  0.16518022\n","No BN: Loss function at epoch 31 and at batch 900  is  0.079741895\n","No BN: Loss function at epoch 31 and at batch 950  is  0.14912383\n","No BN: Loss function at epoch 32 and at batch 0  is  0.12895499\n","Testing test minibatch at training step  0  of epoch  32\n","Accuracy of training step 32000  =  0.9295\n","No BN: Loss function at epoch 32 and at batch 50  is  0.25920224\n","No BN: Loss function at epoch 32 and at batch 100  is  0.050651755\n","No BN: Loss function at epoch 32 and at batch 150  is  0.17144045\n","No BN: Loss function at epoch 32 and at batch 200  is  0.139073\n","No BN: Loss function at epoch 32 and at batch 250  is  0.2236232\n","No BN: Loss function at epoch 32 and at batch 300  is  0.037671402\n","No BN: Loss function at epoch 32 and at batch 350  is  0.09420759\n","No BN: Loss function at epoch 32 and at batch 400  is  0.191768\n","No BN: Loss function at epoch 32 and at batch 450  is  0.23946866\n","No BN: Loss function at epoch 32 and at batch 500  is  0.14552316\n","No BN: Loss function at epoch 32 and at batch 550  is  0.12099096\n","No BN: Loss function at epoch 32 and at batch 600  is  0.21218856\n","No BN: Loss function at epoch 32 and at batch 650  is  0.11992664\n","No BN: Loss function at epoch 32 and at batch 700  is  0.10795045\n","No BN: Loss function at epoch 32 and at batch 750  is  0.19216675\n","No BN: Loss function at epoch 32 and at batch 800  is  0.08419412\n","No BN: Loss function at epoch 32 and at batch 850  is  0.08575375\n","No BN: Loss function at epoch 32 and at batch 900  is  0.18075177\n","No BN: Loss function at epoch 32 and at batch 950  is  0.11915136\n","No BN: Loss function at epoch 33 and at batch 0  is  0.04768939\n","Testing test minibatch at training step  0  of epoch  33\n","Accuracy of training step 33000  =  0.9293\n","No BN: Loss function at epoch 33 and at batch 50  is  0.038096424\n","No BN: Loss function at epoch 33 and at batch 100  is  0.24012418\n","No BN: Loss function at epoch 33 and at batch 150  is  0.06778794\n","No BN: Loss function at epoch 33 and at batch 200  is  0.14273901\n","No BN: Loss function at epoch 33 and at batch 250  is  0.20085154\n","No BN: Loss function at epoch 33 and at batch 300  is  0.090899296\n","No BN: Loss function at epoch 33 and at batch 350  is  0.049095895\n","No BN: Loss function at epoch 33 and at batch 400  is  0.13566221\n","No BN: Loss function at epoch 33 and at batch 450  is  0.23387818\n","No BN: Loss function at epoch 33 and at batch 500  is  0.16912611\n","No BN: Loss function at epoch 33 and at batch 550  is  0.13694438\n","No BN: Loss function at epoch 33 and at batch 600  is  0.08247098\n","No BN: Loss function at epoch 33 and at batch 650  is  0.26850045\n","No BN: Loss function at epoch 33 and at batch 700  is  0.16589814\n","No BN: Loss function at epoch 33 and at batch 750  is  0.04767807\n","No BN: Loss function at epoch 33 and at batch 800  is  0.05062708\n","No BN: Loss function at epoch 33 and at batch 850  is  0.2370062\n","No BN: Loss function at epoch 33 and at batch 900  is  0.1898613\n","No BN: Loss function at epoch 33 and at batch 950  is  0.042137705\n","No BN: Loss function at epoch 34 and at batch 0  is  0.06613158\n","Testing test minibatch at training step  0  of epoch  34\n","Accuracy of training step 34000  =  0.9291\n","No BN: Loss function at epoch 34 and at batch 50  is  0.30039534\n","No BN: Loss function at epoch 34 and at batch 100  is  0.11505675\n","No BN: Loss function at epoch 34 and at batch 150  is  0.0665481\n","No BN: Loss function at epoch 34 and at batch 200  is  0.086413644\n","No BN: Loss function at epoch 34 and at batch 250  is  0.093189165\n","No BN: Loss function at epoch 34 and at batch 300  is  0.26841825\n","No BN: Loss function at epoch 34 and at batch 350  is  0.061241068\n","No BN: Loss function at epoch 34 and at batch 400  is  0.14402315\n","No BN: Loss function at epoch 34 and at batch 450  is  0.06554168\n","No BN: Loss function at epoch 34 and at batch 500  is  0.20364621\n","No BN: Loss function at epoch 34 and at batch 550  is  0.14552553\n","No BN: Loss function at epoch 34 and at batch 600  is  0.16560031\n","No BN: Loss function at epoch 34 and at batch 650  is  0.029551452\n","No BN: Loss function at epoch 34 and at batch 700  is  0.17088124\n","No BN: Loss function at epoch 34 and at batch 750  is  0.116419375\n","No BN: Loss function at epoch 34 and at batch 800  is  0.25596264\n","No BN: Loss function at epoch 34 and at batch 850  is  0.05162886\n","No BN: Loss function at epoch 34 and at batch 900  is  0.24579345\n","No BN: Loss function at epoch 34 and at batch 950  is  0.17889968\n","No BN: Loss function at epoch 35 and at batch 0  is  0.10369353\n","Testing test minibatch at training step  0  of epoch  35\n","Accuracy of training step 35000  =  0.9297\n","No BN: Loss function at epoch 35 and at batch 50  is  0.1216198\n","No BN: Loss function at epoch 35 and at batch 100  is  0.041156676\n","No BN: Loss function at epoch 35 and at batch 150  is  0.123711795\n","No BN: Loss function at epoch 35 and at batch 200  is  0.07252385\n","No BN: Loss function at epoch 35 and at batch 250  is  0.1421407\n","No BN: Loss function at epoch 35 and at batch 300  is  0.084132455\n","No BN: Loss function at epoch 35 and at batch 350  is  0.04595525\n","No BN: Loss function at epoch 35 and at batch 400  is  0.12219221\n","No BN: Loss function at epoch 35 and at batch 450  is  0.054404866\n","No BN: Loss function at epoch 35 and at batch 500  is  0.1542252\n","No BN: Loss function at epoch 35 and at batch 550  is  0.17883424\n","No BN: Loss function at epoch 35 and at batch 600  is  0.048752405\n","No BN: Loss function at epoch 35 and at batch 650  is  0.08058661\n","No BN: Loss function at epoch 35 and at batch 700  is  0.06854172\n","No BN: Loss function at epoch 35 and at batch 750  is  0.03288587\n","No BN: Loss function at epoch 35 and at batch 800  is  0.07528015\n","No BN: Loss function at epoch 35 and at batch 850  is  0.21751368\n","No BN: Loss function at epoch 35 and at batch 900  is  0.07207768\n","No BN: Loss function at epoch 35 and at batch 950  is  0.180477\n","No BN: Loss function at epoch 36 and at batch 0  is  0.15806676\n","Testing test minibatch at training step  0  of epoch  36\n","Accuracy of training step 36000  =  0.9313\n","No BN: Loss function at epoch 36 and at batch 50  is  0.09473843\n","No BN: Loss function at epoch 36 and at batch 100  is  0.1881328\n","No BN: Loss function at epoch 36 and at batch 150  is  0.1509704\n","No BN: Loss function at epoch 36 and at batch 200  is  0.11678046\n","No BN: Loss function at epoch 36 and at batch 250  is  0.08486334\n","No BN: Loss function at epoch 36 and at batch 300  is  0.08450629\n","No BN: Loss function at epoch 36 and at batch 350  is  0.09264\n","No BN: Loss function at epoch 36 and at batch 400  is  0.19949186\n","No BN: Loss function at epoch 36 and at batch 450  is  0.13698189\n","No BN: Loss function at epoch 36 and at batch 500  is  0.18695112\n","No BN: Loss function at epoch 36 and at batch 550  is  0.10539837\n","No BN: Loss function at epoch 36 and at batch 600  is  0.049274683\n","No BN: Loss function at epoch 36 and at batch 650  is  0.3169784\n","No BN: Loss function at epoch 36 and at batch 700  is  0.12775086\n","No BN: Loss function at epoch 36 and at batch 750  is  0.013066163\n","No BN: Loss function at epoch 36 and at batch 800  is  0.08724858\n","No BN: Loss function at epoch 36 and at batch 850  is  0.07592553\n","No BN: Loss function at epoch 36 and at batch 900  is  0.08644829\n","No BN: Loss function at epoch 36 and at batch 950  is  0.10436548\n","No BN: Loss function at epoch 37 and at batch 0  is  0.082692534\n","Testing test minibatch at training step  0  of epoch  37\n","Accuracy of training step 37000  =  0.9304\n","No BN: Loss function at epoch 37 and at batch 50  is  0.09872952\n","No BN: Loss function at epoch 37 and at batch 100  is  0.13194731\n","No BN: Loss function at epoch 37 and at batch 150  is  0.05642207\n","No BN: Loss function at epoch 37 and at batch 200  is  0.083143026\n","No BN: Loss function at epoch 37 and at batch 250  is  0.09826716\n","No BN: Loss function at epoch 37 and at batch 300  is  0.057914976\n","No BN: Loss function at epoch 37 and at batch 350  is  0.029139068\n","No BN: Loss function at epoch 37 and at batch 400  is  0.23131716\n","No BN: Loss function at epoch 37 and at batch 450  is  0.31192616\n","No BN: Loss function at epoch 37 and at batch 500  is  0.084095955\n","No BN: Loss function at epoch 37 and at batch 550  is  0.056531906\n","No BN: Loss function at epoch 37 and at batch 600  is  0.107949294\n","No BN: Loss function at epoch 37 and at batch 650  is  0.03938211\n","No BN: Loss function at epoch 37 and at batch 700  is  0.077454075\n","No BN: Loss function at epoch 37 and at batch 750  is  0.098981045\n","No BN: Loss function at epoch 37 and at batch 800  is  0.1230243\n","No BN: Loss function at epoch 37 and at batch 850  is  0.20349269\n","No BN: Loss function at epoch 37 and at batch 900  is  0.067304544\n","No BN: Loss function at epoch 37 and at batch 950  is  0.03814754\n","No BN: Loss function at epoch 38 and at batch 0  is  0.044181634\n","Testing test minibatch at training step  0  of epoch  38\n","Accuracy of training step 38000  =  0.9317\n","No BN: Loss function at epoch 38 and at batch 50  is  0.031362794\n","No BN: Loss function at epoch 38 and at batch 100  is  0.17858653\n","No BN: Loss function at epoch 38 and at batch 150  is  0.1275317\n","No BN: Loss function at epoch 38 and at batch 200  is  0.12122403\n","No BN: Loss function at epoch 38 and at batch 250  is  0.05467787\n","No BN: Loss function at epoch 38 and at batch 300  is  0.06840025\n","No BN: Loss function at epoch 38 and at batch 350  is  0.0916455\n","No BN: Loss function at epoch 38 and at batch 400  is  0.19530563\n","No BN: Loss function at epoch 38 and at batch 450  is  0.07960008\n","No BN: Loss function at epoch 38 and at batch 500  is  0.09598601\n","No BN: Loss function at epoch 38 and at batch 550  is  0.039208118\n","No BN: Loss function at epoch 38 and at batch 600  is  0.13787359\n","No BN: Loss function at epoch 38 and at batch 650  is  0.17452917\n","No BN: Loss function at epoch 38 and at batch 700  is  0.083140135\n","No BN: Loss function at epoch 38 and at batch 750  is  0.11260778\n","No BN: Loss function at epoch 38 and at batch 800  is  0.09362418\n","No BN: Loss function at epoch 38 and at batch 850  is  0.05144981\n","No BN: Loss function at epoch 38 and at batch 900  is  0.056332007\n","No BN: Loss function at epoch 38 and at batch 950  is  0.033531953\n","No BN: Loss function at epoch 39 and at batch 0  is  0.14678732\n","Testing test minibatch at training step  0  of epoch  39\n","Accuracy of training step 39000  =  0.9318\n","No BN: Loss function at epoch 39 and at batch 50  is  0.18586326\n","No BN: Loss function at epoch 39 and at batch 100  is  0.07470319\n","No BN: Loss function at epoch 39 and at batch 150  is  0.29946044\n","No BN: Loss function at epoch 39 and at batch 200  is  0.10616448\n","No BN: Loss function at epoch 39 and at batch 250  is  0.09209862\n","No BN: Loss function at epoch 39 and at batch 300  is  0.092346616\n","No BN: Loss function at epoch 39 and at batch 350  is  0.06755252\n","No BN: Loss function at epoch 39 and at batch 400  is  0.17537756\n","No BN: Loss function at epoch 39 and at batch 450  is  0.24685477\n","No BN: Loss function at epoch 39 and at batch 500  is  0.25800517\n","No BN: Loss function at epoch 39 and at batch 550  is  0.19259667\n","No BN: Loss function at epoch 39 and at batch 600  is  0.24400634\n","No BN: Loss function at epoch 39 and at batch 650  is  0.17102629\n","No BN: Loss function at epoch 39 and at batch 700  is  0.12975332\n","No BN: Loss function at epoch 39 and at batch 750  is  0.10234181\n","No BN: Loss function at epoch 39 and at batch 800  is  0.16689283\n","No BN: Loss function at epoch 39 and at batch 850  is  0.111456506\n","No BN: Loss function at epoch 39 and at batch 900  is  0.1766097\n","No BN: Loss function at epoch 39 and at batch 950  is  0.1163882\n","No BN: Loss function at epoch 40 and at batch 0  is  0.073250234\n","Testing test minibatch at training step  0  of epoch  40\n","Accuracy of training step 40000  =  0.9311\n","No BN: Loss function at epoch 40 and at batch 50  is  0.0713774\n","No BN: Loss function at epoch 40 and at batch 100  is  0.16926517\n","No BN: Loss function at epoch 40 and at batch 150  is  0.0924516\n","No BN: Loss function at epoch 40 and at batch 200  is  0.07373471\n","No BN: Loss function at epoch 40 and at batch 250  is  0.08682391\n","No BN: Loss function at epoch 40 and at batch 300  is  0.12304199\n","No BN: Loss function at epoch 40 and at batch 350  is  0.03888575\n","No BN: Loss function at epoch 40 and at batch 400  is  0.050730783\n","No BN: Loss function at epoch 40 and at batch 450  is  0.07515981\n","No BN: Loss function at epoch 40 and at batch 500  is  0.18716443\n","No BN: Loss function at epoch 40 and at batch 550  is  0.19629465\n","No BN: Loss function at epoch 40 and at batch 600  is  0.08395412\n","No BN: Loss function at epoch 40 and at batch 650  is  0.1304019\n","No BN: Loss function at epoch 40 and at batch 700  is  0.21922325\n","No BN: Loss function at epoch 40 and at batch 750  is  0.14283866\n","No BN: Loss function at epoch 40 and at batch 800  is  0.19078703\n","No BN: Loss function at epoch 40 and at batch 850  is  0.2004361\n","No BN: Loss function at epoch 40 and at batch 900  is  0.16833273\n","No BN: Loss function at epoch 40 and at batch 950  is  0.15770464\n","No BN: Loss function at epoch 41 and at batch 0  is  0.040998224\n","Testing test minibatch at training step  0  of epoch  41\n","Accuracy of training step 41000  =  0.9332\n","No BN: Loss function at epoch 41 and at batch 50  is  0.05493757\n","No BN: Loss function at epoch 41 and at batch 100  is  0.14310342\n","No BN: Loss function at epoch 41 and at batch 150  is  0.042238247\n","No BN: Loss function at epoch 41 and at batch 200  is  0.058464848\n","No BN: Loss function at epoch 41 and at batch 250  is  0.032663446\n","No BN: Loss function at epoch 41 and at batch 300  is  0.048234362\n","No BN: Loss function at epoch 41 and at batch 350  is  0.042095967\n","No BN: Loss function at epoch 41 and at batch 400  is  0.09308457\n","No BN: Loss function at epoch 41 and at batch 450  is  0.06473007\n","No BN: Loss function at epoch 41 and at batch 500  is  0.10025823\n","No BN: Loss function at epoch 41 and at batch 550  is  0.120784715\n","No BN: Loss function at epoch 41 and at batch 600  is  0.18925531\n","No BN: Loss function at epoch 41 and at batch 650  is  0.27169952\n","No BN: Loss function at epoch 41 and at batch 700  is  0.0711588\n","No BN: Loss function at epoch 41 and at batch 750  is  0.04313096\n","No BN: Loss function at epoch 41 and at batch 800  is  0.08420191\n","No BN: Loss function at epoch 41 and at batch 850  is  0.09174843\n","No BN: Loss function at epoch 41 and at batch 900  is  0.046111505\n","No BN: Loss function at epoch 41 and at batch 950  is  0.1495982\n","No BN: Loss function at epoch 42 and at batch 0  is  0.10496724\n","Testing test minibatch at training step  0  of epoch  42\n","Accuracy of training step 42000  =  0.9339\n","No BN: Loss function at epoch 42 and at batch 50  is  0.05629939\n","No BN: Loss function at epoch 42 and at batch 100  is  0.13237584\n","No BN: Loss function at epoch 42 and at batch 150  is  0.087374076\n","No BN: Loss function at epoch 42 and at batch 200  is  0.030037826\n","No BN: Loss function at epoch 42 and at batch 250  is  0.05857033\n","No BN: Loss function at epoch 42 and at batch 300  is  0.084853575\n","No BN: Loss function at epoch 42 and at batch 350  is  0.08869784\n","No BN: Loss function at epoch 42 and at batch 400  is  0.2491608\n","No BN: Loss function at epoch 42 and at batch 450  is  0.15619947\n","No BN: Loss function at epoch 42 and at batch 500  is  0.28210333\n","No BN: Loss function at epoch 42 and at batch 550  is  0.053307742\n","No BN: Loss function at epoch 42 and at batch 600  is  0.021364301\n","No BN: Loss function at epoch 42 and at batch 650  is  0.19033341\n","No BN: Loss function at epoch 42 and at batch 700  is  0.10407892\n","No BN: Loss function at epoch 42 and at batch 750  is  0.101797\n","No BN: Loss function at epoch 42 and at batch 800  is  0.03394766\n","No BN: Loss function at epoch 42 and at batch 850  is  0.118814275\n","No BN: Loss function at epoch 42 and at batch 900  is  0.2325177\n","No BN: Loss function at epoch 42 and at batch 950  is  0.06634985\n","No BN: Loss function at epoch 43 and at batch 0  is  0.15928473\n","Testing test minibatch at training step  0  of epoch  43\n","Accuracy of training step 43000  =  0.9337\n","No BN: Loss function at epoch 43 and at batch 50  is  0.090880565\n","No BN: Loss function at epoch 43 and at batch 100  is  0.23713832\n","No BN: Loss function at epoch 43 and at batch 150  is  0.18503371\n","No BN: Loss function at epoch 43 and at batch 200  is  0.1343472\n","No BN: Loss function at epoch 43 and at batch 250  is  0.057152115\n","No BN: Loss function at epoch 43 and at batch 300  is  0.064793564\n","No BN: Loss function at epoch 43 and at batch 350  is  0.22129846\n","No BN: Loss function at epoch 43 and at batch 400  is  0.04595395\n","No BN: Loss function at epoch 43 and at batch 450  is  0.105639815\n","No BN: Loss function at epoch 43 and at batch 500  is  0.015035599\n","No BN: Loss function at epoch 43 and at batch 550  is  0.045926787\n","No BN: Loss function at epoch 43 and at batch 600  is  0.10697617\n","No BN: Loss function at epoch 43 and at batch 650  is  0.087365985\n","No BN: Loss function at epoch 43 and at batch 700  is  0.15533493\n","No BN: Loss function at epoch 43 and at batch 750  is  0.054940414\n","No BN: Loss function at epoch 43 and at batch 800  is  0.13505092\n","No BN: Loss function at epoch 43 and at batch 850  is  0.1554455\n","No BN: Loss function at epoch 43 and at batch 900  is  0.16871473\n","No BN: Loss function at epoch 43 and at batch 950  is  0.22444554\n","No BN: Loss function at epoch 44 and at batch 0  is  0.15939558\n","Testing test minibatch at training step  0  of epoch  44\n","Accuracy of training step 44000  =  0.9335\n","No BN: Loss function at epoch 44 and at batch 50  is  0.1514932\n","No BN: Loss function at epoch 44 and at batch 100  is  0.14180814\n","No BN: Loss function at epoch 44 and at batch 150  is  0.04626395\n","No BN: Loss function at epoch 44 and at batch 200  is  0.110846125\n","No BN: Loss function at epoch 44 and at batch 250  is  0.16126822\n","No BN: Loss function at epoch 44 and at batch 300  is  0.13848422\n","No BN: Loss function at epoch 44 and at batch 350  is  0.05034436\n","No BN: Loss function at epoch 44 and at batch 400  is  0.08466771\n","No BN: Loss function at epoch 44 and at batch 450  is  0.08552329\n","No BN: Loss function at epoch 44 and at batch 500  is  0.071048774\n","No BN: Loss function at epoch 44 and at batch 550  is  0.11104644\n","No BN: Loss function at epoch 44 and at batch 600  is  0.24515845\n","No BN: Loss function at epoch 44 and at batch 650  is  0.27543396\n","No BN: Loss function at epoch 44 and at batch 700  is  0.088151604\n","No BN: Loss function at epoch 44 and at batch 750  is  0.19775839\n","No BN: Loss function at epoch 44 and at batch 800  is  0.023921976\n","No BN: Loss function at epoch 44 and at batch 850  is  0.022773018\n","No BN: Loss function at epoch 44 and at batch 900  is  0.07595818\n","No BN: Loss function at epoch 44 and at batch 950  is  0.17326197\n","No BN: Loss function at epoch 45 and at batch 0  is  0.1296503\n","Testing test minibatch at training step  0  of epoch  45\n","Accuracy of training step 45000  =  0.9337\n","No BN: Loss function at epoch 45 and at batch 50  is  0.09328741\n","No BN: Loss function at epoch 45 and at batch 100  is  0.06105978\n","No BN: Loss function at epoch 45 and at batch 150  is  0.10994516\n","No BN: Loss function at epoch 45 and at batch 200  is  0.06653319\n","No BN: Loss function at epoch 45 and at batch 250  is  0.09205115\n","No BN: Loss function at epoch 45 and at batch 300  is  0.09415127\n","No BN: Loss function at epoch 45 and at batch 350  is  0.12155382\n","No BN: Loss function at epoch 45 and at batch 400  is  0.043679655\n","No BN: Loss function at epoch 45 and at batch 450  is  0.07870326\n","No BN: Loss function at epoch 45 and at batch 500  is  0.07534846\n","No BN: Loss function at epoch 45 and at batch 550  is  0.08023055\n","No BN: Loss function at epoch 45 and at batch 600  is  0.053994477\n","No BN: Loss function at epoch 45 and at batch 650  is  0.07471679\n","No BN: Loss function at epoch 45 and at batch 700  is  0.07790018\n","No BN: Loss function at epoch 45 and at batch 750  is  0.13526002\n","No BN: Loss function at epoch 45 and at batch 800  is  0.051837705\n","No BN: Loss function at epoch 45 and at batch 850  is  0.017481089\n","No BN: Loss function at epoch 45 and at batch 900  is  0.040326864\n","No BN: Loss function at epoch 45 and at batch 950  is  0.27103767\n","No BN: Loss function at epoch 46 and at batch 0  is  0.041240472\n","Testing test minibatch at training step  0  of epoch  46\n","Accuracy of training step 46000  =  0.9343\n","No BN: Loss function at epoch 46 and at batch 50  is  0.0781045\n","No BN: Loss function at epoch 46 and at batch 100  is  0.1627307\n","No BN: Loss function at epoch 46 and at batch 150  is  0.089166954\n","No BN: Loss function at epoch 46 and at batch 200  is  0.03435125\n","No BN: Loss function at epoch 46 and at batch 250  is  0.19208655\n","No BN: Loss function at epoch 46 and at batch 300  is  0.0551428\n","No BN: Loss function at epoch 46 and at batch 350  is  0.122428425\n","No BN: Loss function at epoch 46 and at batch 400  is  0.13077784\n","No BN: Loss function at epoch 46 and at batch 450  is  0.07804023\n","No BN: Loss function at epoch 46 and at batch 500  is  0.09250858\n","No BN: Loss function at epoch 46 and at batch 550  is  0.08004373\n","No BN: Loss function at epoch 46 and at batch 600  is  0.11177261\n","No BN: Loss function at epoch 46 and at batch 650  is  0.040416546\n","No BN: Loss function at epoch 46 and at batch 700  is  0.09210483\n","No BN: Loss function at epoch 46 and at batch 750  is  0.049825475\n","No BN: Loss function at epoch 46 and at batch 800  is  0.065993086\n","No BN: Loss function at epoch 46 and at batch 850  is  0.16601287\n","No BN: Loss function at epoch 46 and at batch 900  is  0.06236682\n","No BN: Loss function at epoch 46 and at batch 950  is  0.13730983\n","No BN: Loss function at epoch 47 and at batch 0  is  0.056305673\n","Testing test minibatch at training step  0  of epoch  47\n","Accuracy of training step 47000  =  0.9331\n","No BN: Loss function at epoch 47 and at batch 50  is  0.07054186\n","No BN: Loss function at epoch 47 and at batch 100  is  0.08651362\n","No BN: Loss function at epoch 47 and at batch 150  is  0.08153866\n","No BN: Loss function at epoch 47 and at batch 200  is  0.0534278\n","No BN: Loss function at epoch 47 and at batch 250  is  0.08396753\n","No BN: Loss function at epoch 47 and at batch 300  is  0.07484785\n","No BN: Loss function at epoch 47 and at batch 350  is  0.034583796\n","No BN: Loss function at epoch 47 and at batch 400  is  0.11399317\n","No BN: Loss function at epoch 47 and at batch 450  is  0.20669524\n","No BN: Loss function at epoch 47 and at batch 500  is  0.106484674\n","No BN: Loss function at epoch 47 and at batch 550  is  0.14323641\n","No BN: Loss function at epoch 47 and at batch 600  is  0.040875614\n","No BN: Loss function at epoch 47 and at batch 650  is  0.07407145\n","No BN: Loss function at epoch 47 and at batch 700  is  0.0785313\n","No BN: Loss function at epoch 47 and at batch 750  is  0.14431931\n","No BN: Loss function at epoch 47 and at batch 800  is  0.10455814\n","No BN: Loss function at epoch 47 and at batch 850  is  0.08848355\n","No BN: Loss function at epoch 47 and at batch 900  is  0.033640597\n","No BN: Loss function at epoch 47 and at batch 950  is  0.08395443\n","No BN: Loss function at epoch 48 and at batch 0  is  0.094140336\n","Testing test minibatch at training step  0  of epoch  48\n","Accuracy of training step 48000  =  0.9352\n","No BN: Loss function at epoch 48 and at batch 50  is  0.115334995\n","No BN: Loss function at epoch 48 and at batch 100  is  0.044714104\n","No BN: Loss function at epoch 48 and at batch 150  is  0.10918862\n","No BN: Loss function at epoch 48 and at batch 200  is  0.081741504\n","No BN: Loss function at epoch 48 and at batch 250  is  0.085761905\n","No BN: Loss function at epoch 48 and at batch 300  is  0.063501306\n","No BN: Loss function at epoch 48 and at batch 350  is  0.07148549\n","No BN: Loss function at epoch 48 and at batch 400  is  0.013632851\n","No BN: Loss function at epoch 48 and at batch 450  is  0.07879442\n","No BN: Loss function at epoch 48 and at batch 500  is  0.24296717\n","No BN: Loss function at epoch 48 and at batch 550  is  0.04467088\n","No BN: Loss function at epoch 48 and at batch 600  is  0.13148962\n","No BN: Loss function at epoch 48 and at batch 650  is  0.056050327\n","No BN: Loss function at epoch 48 and at batch 700  is  0.051804416\n","No BN: Loss function at epoch 48 and at batch 750  is  0.16500266\n","No BN: Loss function at epoch 48 and at batch 800  is  0.11206864\n","No BN: Loss function at epoch 48 and at batch 850  is  0.06539849\n","No BN: Loss function at epoch 48 and at batch 900  is  0.1470712\n","No BN: Loss function at epoch 48 and at batch 950  is  0.106066875\n","No BN: Loss function at epoch 49 and at batch 0  is  0.033705868\n","Testing test minibatch at training step  0  of epoch  49\n","Accuracy of training step 49000  =  0.9357\n","No BN: Loss function at epoch 49 and at batch 50  is  0.041204825\n","No BN: Loss function at epoch 49 and at batch 100  is  0.035163056\n","No BN: Loss function at epoch 49 and at batch 150  is  0.15881377\n","No BN: Loss function at epoch 49 and at batch 200  is  0.09209436\n","No BN: Loss function at epoch 49 and at batch 250  is  0.08799005\n","No BN: Loss function at epoch 49 and at batch 300  is  0.16159646\n","No BN: Loss function at epoch 49 and at batch 350  is  0.086235546\n","No BN: Loss function at epoch 49 and at batch 400  is  0.02674649\n","No BN: Loss function at epoch 49 and at batch 450  is  0.09833289\n","No BN: Loss function at epoch 49 and at batch 500  is  0.16779748\n","No BN: Loss function at epoch 49 and at batch 550  is  0.019712994\n","No BN: Loss function at epoch 49 and at batch 600  is  0.13197705\n","No BN: Loss function at epoch 49 and at batch 650  is  0.15370451\n","No BN: Loss function at epoch 49 and at batch 700  is  0.028714886\n","No BN: Loss function at epoch 49 and at batch 750  is  0.06920078\n","No BN: Loss function at epoch 49 and at batch 800  is  0.06004723\n","No BN: Loss function at epoch 49 and at batch 850  is  0.06000949\n","No BN: Loss function at epoch 49 and at batch 900  is  0.028054187\n","No BN: Loss function at epoch 49 and at batch 950  is  0.06692262\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XlCsgi0DsmLz","colab_type":"code","outputId":"ef0873ed-f278-4ec0-8465-0c361b541496","executionInfo":{"status":"ok","timestamp":1587318582187,"user_tz":-120,"elapsed":1736,"user":{"displayName":"marco sala","photoUrl":"","userId":"07284782352463012974"}},"colab":{"base_uri":"https://localhost:8080/","height":839}},"source":["plt.figure()\n","plt.plot(testAccuracyPerTrainingStep, 'b', label='With BN')\n","plt.plot(testAccuracyPerTrainingStepNoBN, '--k', label='Without BN')\n","plt.xticks([10, 20, 30, 40, 50], ('10K', '20K', '30K', '40K', '50K'))\n","plt.xlabel('Number of Training Steps')\n","plt.ylabel('Test Accuracy')\n","plt.ylim(0.7, 1)\n","plt.legend()\n","plt.grid()\n","plt.savefig('Scratch_Accuracy_LR0-1_init1.png', dpi=200)\n","plt.show()\n","\n","plt.figure()\n","plt.plot(sigmoidActivation15Percentile, label=r'$15^{th}$ Percentile')\n","plt.plot(sigmoidActivation50Percentile, label=r'$50^{th}$ Percentile')\n","plt.plot(sigmoidActivation85Percentile, label=r'$85^{th}$ Percentile')\n","plt.xticks([200, 400, 600, 800, 1000], ('10K', '20K', '30K', '40K', '50K'))\n","plt.xlabel('Number of Training Steps')\n","plt.ylabel(\"Activation of the last layer's Sigmoid\")\n","plt.title(\"WITH BN\")\n","plt.legend(loc='best')\n","plt.grid()\n","plt.savefig('Scratch_ActivationsBN_LR0-1_init1.png', dpi=200)\n","plt.show()\n","\n","plt.figure()\n","plt.plot(sigmoidActivation15PercentileNoBN, label=r'$15^{th}$ Percentile')\n","plt.plot(sigmoidActivation50PercentileNoBN, label=r'$50^{th}$ Percentile')\n","plt.plot(sigmoidActivation85PercentileNoBN, label=r'$85^{th}$ Percentile')\n","plt.xticks([200, 400, 600, 800, 1000], ('10K', '20K', '30K', '40K', '50K'))\n","plt.xlabel('Number of Training Steps')\n","plt.ylabel(\"Activation of the last layer's Sigmoid\")\n","plt.title(\"NO BN\")\n","plt.legend(loc='best')\n","plt.grid()\n","plt.savefig('Scratch_ActivationsNoBN_LR0-1_init1.png', dpi=200)\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYkAAAEKCAYAAADn+anLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXhV1fXw8e/KREKYCYMSJkFAFAlDEQEVUJFWgdZSBVuHKsVWxIpaX9SqyE8tKs5irUMFB0QFUQREURMUQRkqg4AgMwkOQJgChJBkvX/sk3Az3HCBnNwM6/M858k989pXPOuevc/ZW1QVY4wxpjgR4Q7AGGNM+WVJwhhjTFCWJIwxxgRlScIYY0xQliSMMcYEZUnCGGNMUL4lCRH5r4j8IiLfBVkvIvKMiKwXkRUi0jlg3bUi8oM3XetXjMYYY0rm553ERKB/Cet/DZzuTcOBfwOISD3gfuAcoBtwv4jU9TFOY4wxQfiWJFT1CyC9hE0GAa+p8zVQR0ROAS4B5qpquqruBuZScrIxxhjjk6gwnrsJsC1gPtVbFmx5ESIyHHcXQlxcXJemTZv6E2kllpubS0RE1WuasnJXLVbu4NatW7dTVRsEWx/OJHHSVPVF4EWArl276pIlS8IcUcWTkpJC7969wx1GmbNyVy1W7uBEZEtJ68OZWtOAwJ/+id6yYMuNMcaUsXAmiRnANd5TTt2Bvar6I/Ax0E9E6noN1v28ZcYYY8qYb9VNIvIW0BtIEJFU3BNL0QCq+gIwG/gNsB44CPzZW5cuIv8HLPYONVZVS2oAN8YY4xPfkoSqDj3GegVGBFn3X+C/fsRljDEmdFWvud8YY0zILEkYY4wJypKEMcaYoCxJGGOMCcqShDHGmKAsSRhjjAnKkoQxxpigLEkYY4wJypKEMcaYoCxJGGOMCcqShDHGmKAsSRhjjAnKkoQxxpigLEkYY4wJqkIPX2qMMaUpNxd++gnS0iA6GmrUODpVrw5VcJhsSxLGmIrl4EHYuxcOHSo4ZWZCVBTUrl1wio4+ut+OHQWnn36CzZth0yY3bd4Mhw8HP3d8vDtHcWrUgCZNik41a8Lu3ZCeXnDatw9EIDLSTVFRR//Wrg316kHduu5v3ueDB13MhaeWLeHVV0v7m3YsSRhjyq29e+Hbb2HpUjf973+wbh2ohn6MuDhQPY/MzOLX16sHLVrAWWfBgAHugpuYCDk5kJFRdMrJKXoMVXfRT0uDtWvh889d7IVFRh696Neq5fbLyXFTdvbRv3v3ukSSmxu8XDVrQqNG0LixSyB+sSRhjCkiM9P90t671/2yjY6GmJijU2QkbN9+9Bd43q/wvF/igdvmTbm5xV90MzOL3z47G7ZsORpTYiJ06QJXXQUNG7qLf+AUGwtHjriY9+51F+28z1u2bKdz56Y0aECBqWFDd7H2w4EDLmlkZBxNDDVruruHUOTmwv79Be9Cqld3SaFRI3dXUxYsSRhTQR0+7C7O69cXnDZudBeivAtT4LRtWzM++6xoVc3+/QWrYTIyji+WmBj3a7xFC3fxyso6OmVkuL8i7iKZmFiwrr9aNXdxD9wnK8v9yv7LX1xi6NzZXdBPVErKBnr3bnriBzgB8fHQps2J7x8RcbTKrEWLUgvruFmSMKaUHTkC33/vfqE2bXrsxs6MDLd9WlrRC2VWlruI//xz0Xro9PSCx6ldG1q3hqQkd0FOT3f7rVnjPrvqj9MQKforvEYN98v69NMhIeHoL+26dV0VSOGYsrPdL9qWLd3UuHHVbNStCixJGHMSVN2v98WLYdEiN337Lfn133Fx7sLbpg20beumI0dg9eqjU2CVSjBxcXDKKe5i3K4d9O7tPp92mksMrVpB/folV2VkZ8Pnn8/j4osvCLnKwxhLEsYUkpvrfn0vXOimr792jZFw9EmUvCk729U9g7uQd+kCf/ub+3vggNtv7VpYtgymTz/a6Bkb6xJGjx4wbBi0bw/NmrnlhevmY2Nd1cXJXtijoiAmRi1BmONiScJUKZmZrtpl8+bqzJtX9JHItWvhm29coye4evzu3WHgQFedkvckSt4k4p6K6dbNXeiDPR4Jrppm40a3TcuWLskYU95ZkjCVzvr1MGsWzJ0LP/5Y8CmXrKy8rboV2S+vgXDoUDj3XJcc2rQ5+V/weWJiXFWRMRWJJQlT4R0+DF9+6RLDrFnwww9ueZs2rq6+TZuiL1j9/PNqzj+/fX4DbUKCu4gbYwqyJGHKpZwcVzWzcuXRacsWlxACn7LJey7+8GH3KGWfPnDLLfCb37hG3WBSUn6hd+/2ZVcgYyooSxIm7HJz3Vu0eQ3F//ufe+rn0CG3XsTdEbRq5RqHq1Ur2LAbHw8XXAB9+7qXjYwxpcfXJCEi/YGngUjgZVUdV2h9c+C/QAMgHfiTqqZ663KAld6mW1V1oJ+xmrKTlQVffeWqiBYudA3Fu3e7dXXquCeDbrwROnRwU/v2Zfd2qTGmIN+ShIhEAhOAi4FUYLGIzFDV1QGbjQdeU9VJItIX+BdwtbfukKom+RWfKVs//ggffXS0QXn/fneHcOaZ8Pvfu4bic891j4XaS1nGlB9+3kl0A9ar6kYAEZkCDAICk0R74DbvczLwvo/xmDKUleXuED75BGbPdlVI4LpkGDoULr3UVRHVrh3eOI0xJfMzSTQBtgXMpwLnFNpmOXA5rkrqd0BNEamvqruAWBFZAmQD41TVEkg5pupeQJs7103z5rnuJiIi3B3Cww+7xNChQ+k9UmqM8Z/o8fS5ezwHFhkM9FfVYd781cA5qnpzwDanAs8BLYEvgN8DZ6nqHhFpoqppInIa8DlwoapuKHSO4cBwgEaNGnWZMmWKL2WpzDIyMqhRo8Zx73fwYCTr1tVkzZqafP99LVavrsXOndUASEw8SOfOu+nadTedOu2hRo3s0g77pJ1ouSs6K3fVEkq5+/Tps1RVuwZb7+edRBoQ2O1iorcsn6pux91JICI1gN+r6h5vXZr3d6OIpACdgA2F9n8ReBGga9eu2rt3bz/KUamlpKQQyveWm+vaE957z/VPtGbN0T79W7WCiy92TxddfDE0b14dqI67mSyfQi13ZWPlrlpKo9x+JonFwOki0hKXHIYAVwVuICIJQLqq5gJ34Z50QkTqAgdV9bC3TU/gUR9jNUEcOACTJsFTT7mX1BIS3JvIV17puqL41a9cx3LGmMrJtyShqtkicjPwMe4R2P+q6ioRGQssUdUZQG/gXyKiuOqmEd7uZwD/EZFcIALXJrG6yEmMb9LS4Lnn4D//cY+ndusGU6bA5ZcfHQ7SGFP5+fqehKrOBmYXWnZfwOepwNRi9lsAdPAzNlO8HTvg7rth4kRXxfS738Ftt7nGZ2twNqbqsTeuDeC6wXj5ZbjrLvcOw9/+BqNGud5KjTFVlyUJw9KlLiksXuwGs5kwwb3lbIwxliSqsN274cknT+fDD934wW++6V50s2olY0weSxJViKrrOO/TT90LbykpcOjQqYwcCWPH2tvPxpiiLElUcllZMG0azJnjksP27W756afDNddA585LGTYs6Hs0xphyYPPmzXz55ZekpaUxcuRI4uPjefvtt3n99dfZt28fycnJRPo01KEliUoqOxtee83dIWzZ4t5vuPBC97LbRRdB8+Zuu5SUjPAGakwY5ebmsnv3bnbs2JE/NW7cmB49egAwYcIERISYmJj8qW3btnTq1AlVZd68efnLVZWsrCyaNGlCixYtyMzMZNasWRw8eJD09HR2795Neno6AwYM4OKLL2b37t2MGjWK1q1b07p1a1q1akXr1q2pW7cuAEuWLOHpp5/miy++YOvWrfkxDxkyhPj4ePbs2cP27dupXbs2hw8fprpf/eSraqWYunTpokY1O1v1jTdUW7dWBdVf/Ur1o49Uc3KK3z45OblM4ysvrNxVS16509PTddWqVaqqeuTIEa1Vq5YCBaarrroqf7/o6Ogi62+++WZVVc3MzCyyDtC77rpLVVV37NhRZF2dOnX06aefVlXV1atXa2JiYpFtXn31VVVVnTNnjjZo0EAHDx6szz77rC5fvlwPHDigubm5x13ukuDeWwt6bbU7iUpC1VUr3X+/a3fo2BE++AAGDLCGaFP+qCoiwrx585g2bRqNGzemSZMm+VPr1q2Jjo5mx44drFixgrVr17Ju3TrWrl3L+vXrWbduHSLCbbfdxquvvkpOTg45OTlUr16dU089lWXLliEivPHGG6xbt45Vq1Zx6623smLFCjp37sySJUuIiori0UcfJTMzkwYNGpCQkECDBg1o0uRodzI///wzR44cISsri6ysLA4fPkxtr/EuKiqK5OTk/OV5dxyneUMi1qlTh+XLlxMXF0e9evWoU6dOgSqhM844g23btnHo0CE2btzI+vXrWb9+Pd27dwfgoosu4ueff0bC/D+wJYlK4MgRuP56eOMNaNcO3nnHjdFg4zKYk5WZmcmXX35ZoLolJiaGU089lfr165Odnc3u3bvzl0dHR3Po0CGio6OJjY1l586dJCcnk56ezsaNG1m+fDnLli3j/fffp3v37vz0009MnDiR/fv3Fzjv2rVradOmDc888wwPPvggAPHx8bRp04YuXbrkJ5lu3bqRnZ1NZGQkkZGRHDhwgKysrPwL65w5c5g8eTIxMTH06tWLBx54gD59+uSf58Ybbyyx/HlVP8WJjIwssV+kqKgozj777GN9xcTFxXHmmWdy5plnFjl+uVDSbUZFmqpqddOBA6qXXuqqlsaOddVNx6OqVz9URocPH9adO3fmz//www86f/58nTt3rk6YMEF37NgRtMpiw4YN+uSTT+qHH36oqqpbtmwptkrlqaeeUlXVVatWFbv+tddeU1XV+fPn5y+Ljo7WpKQkve6663T58uWqqvlxHDhwQH/44QdNSUnRN998Uw8dOqSqqt9//71++umnum3btuOqZgmUnZ2tn3766QntW9FZdVMVt2ePq0766it44QU35KepPNT7tQzw7rvvcu6555KYmFjstvv27WPmzJlMmzaNjz76iOrVq7Nz504A7rzzTqZPn56/7YgRI2jXrh1r1qwB4M0332TlypXMnDmTVatWAe4X9mWXXUbDhg2ZP39+fnVL3pT3C7lRo0Y899xzBapjqlevTufOnQFISkpixYoV1KtXjwYNGhATE1Mg7rzyVa9ePb8BN1Dbtm1p27btSX2PeXcZ5sRYkqigfvoJLrnEddk9ZQpccUW4IzKlYdOmTbz//vtMnz6dpKQknnnmGTZv3swV3n/gNm3a0KdPH/r27ctFF11EvXr1eP755xk1ahRZWVmccsop/PnPf6Zjx475x7z77ru58cYbiYuL46uvviIuLo7c3Nz89ePHj2flypVccMEF/OUvf2HAgAH59eqxsbH07NkzaLz169dnxIgRQdfHx8fToYN1w1aRWZKogDZudI+y/vyzG+Ph4ovDHZE5lszMTFJTU9m6dSs7duxg7969AAwfPhyARx99lMmTJ7N8+XIAOnTokP+rulmzZnz77bd8/vnnJCcnM3nyZP7zn/8wefJkhg4dSlJSEjfddBODBw/m3HPPJaJQY1TXrkffg8nNzS1Sj75o0SKysrKIj4/3q/imArMkUcGsWOHuILKy4LPP4JzCA8KaMpGTk8Py5cvzq1VmzpxJSkpK/lM22dnZ7Nu3jzfeeAOA66+/nrfeeqvAMerXr5+fJDZv3kzt2rUZP348v/3tb2nVqlX+dhERESQlJZGUlMRtt91GdnY2S5cuza+G6dGjR/5z/SciOjqaaOv/3QRhSaIC+fhj+MMfoFYt+OILKPQwhPFZRkYGn3zyCTNmzGDWrFns3LmTLVu20KxZMxYsWMC///3v/PrvyMhIGjZsSGZmJrGxsQwbNoz+/fvTrFkzGjZsSO3atfMfpQR4/vnnQ44jKiqKc+zXgSkjliQqiBdfhJtucolh1iwI0n5pTtCGDRsYMWIEqampxMbGEhcXR1xcHKNGjeLXv/41c+bMYdCgQWRlZVG3bl1+85vfMGDAAOp7w/I9/PDDPPzww0GP37dv37IqijGlypJEOZeb68Z4ePRR6N/fvQNRs2a4oyrfsrKymDNnDtOnT+ess87i9ttvB+CRRx5BRIiPjyclJYU777yTwYMHc+edd1KvXj22b99OmzZtyMzMJDMzk/3793PkyBEAOnXqxM0338zAgQPp2bMnUVH2v46pGuxfejl26BBcey28+y789a/w7LNQVa5Nqprf503Dhg2pVq1afv83zZo1K7YOfdGiRUyaNIm3336bXbt2Ua9ePerVq5e//sEHHyQjw/VVFRMTQ/fu3WncuDHgXppasWJF0HgaNWrE448/XsqlNKb8qyKXnIpnxw4YNAgWLoTHHoPbb6/83WssWrSIe+65h++++4709HSysrIA+PrrrznnnHOYPn06w4YNIzIykhYtWuQ/V3/vvffmX8RnzJjBoEGDuPrqq+nXr1+BZLJ3714OHTpERkYGy5cvp1+/fuEqqjEVhiWJcmjfPjdC3MaN7i5i8OBwR+SPNWvWMH36dM4//3x69epFdHQ0qampXHbZZSQkJOTfCTT3uqzt27cvr776an4fN+vXr+frr79mzJgxADz22GO89NJL1KpVq9jzRUREEB8fT3x8fJGXuowxxbMkUc7k5sLVV8Pate5ppgsvDHdEpUdVWb58OVOnTmXatGl8//33AIwdO5ZevXqRlJSU/xZwcVq2bEnLQoNuu14FnGbNmvkTuDFVmCWJcmbsWJgxA55+unIkCFUlNTWVpk2boqpceuml/PTTT/Tp04eRI0cyaNCg/F43T6S3y3D3kGlMZWdJohyZPh0eeACuuw5Gjgx3NMXLzs4mIiKiyFu9eXbt2sXixYv53//+x9KlS/nmm2/Izc0lNTWViIgIpk6dSuvWrWnQoEEZR26MORGWJMqJVavccKLdusG//12+Gqm///57EhMTqVGjBq+++io33ngjdevWpW7duvntBi+//DKJiYk8/PDDPPHEEwC0bt2aXr168etf/5qcnBwiIiI499xzw1waY8zxsCRRDqSnuyeZatRwdxOxseGOCH755RfeeustXn/9dZYuXcqkSZO45ppr6NSpE//85z8LDMeYnp6e/xTRsGHDuOyyy+jUqRN16tQJcymMMSfLkkSYZWfD0KGwbRukpMCpp4Y3noyMDIYOHcpHH31ETk4OnTp14oknnuCSSy4BXGdxgR3GFXbGGWdwxhlnlFW4xhifWZIIs9Gj4ZNP4OWXIVw1MZs3b+bbb7/ld7/7HTVq1EBV+cc//sGf/vSnIqNlGWOqFksSYaIK994Ljz8OI0bADTeU9fmVWbNmMXbsWJYsWUJ8fDy//PILcXFxzJw5s2yDMcaUW76Ogiwi/UVkrYisF5HRxaxvLiKficgKEUkRkcSAddeKyA/edK2fcZa13Fz4+9/hoYdg2DD3uGtZ2rp1K5dddhkDBgxg8+bN3HfffaxatYq4uLiyDcQYU+75dichIpHABOBiIBVYLCIzVHV1wGbjgddUdZKI9AX+BVwtIvWA+4GuuPFxl3r77vYr3rKSk+MSw8SJcNttMH582T/JlJGRwcKFC3niiSc4++yzubAyvJBhjPGFn3cS3YD1qrpRVbOAKcCgQtu0Bz73PicHrL8EmKuq6V5imAv09zHWMpGV5RqpJ05070OUZYJYunQp999/PwDt27dn27ZtjBo1ysb+NcaUyM82iSbAtoD5VKDwSCnLgcuBp4HfATVFpH6QfZsUPoGIDAeGg+ulMyUlpbRiL3WZmRGMGXMm33xTn5tuWs/556cyb57/501LS2P69OlMnz6dOnXqFHk0NSMjo1x/b36xclctVu6ToKq+TMBg4OWA+auB5wptcyrwHvAtLlGkAnWAO4B/Bmx3L3BHSefr0qWLllcZGarnn68qovrSS2VzztWrV2unTp0UUBHRv/71r7p79+4i2yUnJ5dNQOWMlbtqsXIHByzREq6tft5JpAFNA+YTvWX5VHU77k4CEakB/F5V94hIGtC70L4pPsbqqzvugC+/hMmTYcgQf86xZcsWpk6dyqmnnsrQoUNJTEykZs2aPPHEEwwePJimTZse+yDGGFPIMZOEiESqas4JHHsxcLqItMQlhyHAVYWOnQCkq2oucBfwX2/Vx8DDIlLXm+/nra9wZs+GF15wiaK0E8T69euZNm0aU6dOZcmSJQBce+21DB06lJo1azKvLOqzjDGVWigN1z+IyGMi0v54Dqyq2cDNuAv+GuAdVV0lImNFZKC3WW9grYisAxoBD3n7pgP/h0s0i4Gx3rIKZedOuP566NABHnywdI6ZnZ2d/3nEiBGMHj2aiIgIHnnkEdavX8/EiRNL50TGGENoDdcdcXcBL4tIBO7X/hRV3XesHVV1NjC70LL7Aj5PBaYG2fe/HL2zqHBUYfhw2L3bvVFdrdrJH3PevHkMGzaMDz/8kHbt2jF+/Hhq1aqVPyiPMcaUtmPeSajqflV9SVV7AP8P9/7CjyIySURa+x5hBTVpkuus76GH4OyzT+5YqspTTz3FhRdeSFRUVP4YCh06dLAEYYzx1TGThIhEishAEZkOPAU8DpwGfEihuwTjbNoEt9wCF1wAo0ad3LEOHjzIn/70J0aNGsXAgQP55ptvaNu2bekEaowxxxBKddMPuBfdHlPVBQHLp4rI+f6EVXHl5LhxIUTc3cTJvqs2fvx43nrrLR566KH89gdjjCkroSSJs1U1o7gVqnpLKcdT4Y0fD/Pnw2uvQWnUBN15551ccMEFXHDBBSd/MGOMOU6h/CydICL5r+iKSF0RqbANyn5ascL17PqHP8Cf/nTix/nxxx/p168fq1evJjY21hKEMSZsQkkSZ6vqnrwZdX0pdfIvpIrr8cchLu7khx+94447mDdvXv5ob8YYEy6hJImIgJfa8HpotXEoCjlwAKZNc3cR9euf+HGSk5OZPHkyo0eP5vTTTy+9AI0x5gSEcrF/HFgoIu8CguuT6SFfo6qA3n/fJYqrrz7xY2RlZXHTTTdx2mmnMXp0keE3jDGmzB0zSajqayKyFOjjLbpcC44JYYA33oBmzeC88078GC+99BLff/89s2bNsgGAjDHlQkjVRl53GjuAWAARaaaqW32NrAL56Sf3VvXo0XAyT6jecMMN1K9fn9/85jelF5wxxpyEUF6mGygiPwCbgHnAZuAjn+OqUN56yw1JejJVTYcPHyY2NpYhfnUTa4wxJyCU373/B3QH1qlqS+BC4Gtfo6pgXn8dunaFdu1ObP9Zs2bRtm1b1q5dW7qBGWPMSQolSRxR1V24p5wiVDUZN/a0AVatgm+/PfG7iEOHDjFy5Eji4uJo2bJl6QZnjDEnKZQ2iT3egEBfAG+KyC/AAX/Dqjhef911vXGitUTjxo1j06ZNfP7558TExJRucMYYc5JCuZMYBBwERgFzgA3AAD+Dqihyc+HNN6F/f2jY8Pj3X7JkCePGjeOqq66iT58+x97BGGPKWIl3EiISCcxU1T5ALjCpTKKqIFJSIDXV9dd0Il555RUaN27M008/XapxGWNMaSkxSahqjojkikhtVd1bVkFVFK+/DrVqwcCBx962OBMmTCAtLY2EhITSDcwYY0pJKG0SGcBKEZlLQFtEVe8B9uBBmDoVrrjC9dd0PCZNmkTfvn1p2rQpTZs29SdAY4wpBaG0SbwH3ItruF4aMFVpH3wAGRnH/1TTJ598wp///GfGjRvnT2DGGFOKQumWw9ohivH669C0KZx/HMMubd26lauuuor27dvz6KOP+hecMcaUkmMmCRHZBGjh5ap6mi8RVQA//+y64fjHP0LvhiMrK4srrriCrKwspk2bRnx8vL9BGmNMKQilTSLwxblY4A9APX/CqRjeessNU3o8VU2PPPII33zzDe+++66NUW2MqTBCqW7aVWjRU16vsPf5E1L5l5wMbdtC+/ah73PrrbfSsmVLBg8e7F9gxhhTykKpbuocMBuBu7Oo0oMOpaZCqD1oZGdno6rUrFmTP53MmKbGGBMGodSoPx4w/QvoDFzhZ1DlXVoaJCaGtu3zzz9Px44d2blzp79BGWOMD0KpbrL+IgIcOQK//AJNmhx72127djFmzBi6du1K/ZMZ09QYY8IklPEkHhaROgHzdUXkQX/DKr9+/BFUQ0sSDzzwAHv37uWJJ55ARPwPzhhjSlko1U2/VtU9eTOquhsIaeg0EekvImtFZL2IFBm0WUSaiUiyiHwrIitE5Dfe8hYickhElnnTC6EWyG+pqe7vsZLE6tWref7557nxxhs566yz/A/MGGN8EEoDdKSIVFPVwwAiEgdUO9ZOXueAE4CLgVRgsYjMKDQ+9j+Bd1T13yLSHpgNtPDWbVDVpNCLUjbS0tzfYyWJ559/nho1avDAAw/4H5QxxvgklDuJN4HPROQGEbkBmEtovcF2A9ar6kZVzQKm4LodD6RALe9zbWB7aGGHT6hJ4umnn+bLL7+kQYMG/gdljDE+EdUiL1MX3UikP3CRNztXVT8OYZ/BQH9VHebNXw2co6o3B2xzCvAJUBeIBy5S1aUi0gJYBawD9gH/VNUviznHcGA4QKNGjbpMmTLlmGU5WS+8cBrvvZfIxx9/QXHNDNnZ2WRmZlKjRg3fYykNGRkZFSbW0mTlrlqs3MH16dNnqaoGH21UVUucgJZAbMB8HNAihP0GAy8HzF8NPFdom9uA273P5wKrcXc31YD63vIuwDagVknn69Kli5aFoUNVTzst+Pqnn35aExISdOvWrWUSz8lKTk4OdwhhYeWuWqzcwQFLtIRrayjVTe/iBhzKk+MtO5Y0ILAf7ERvWaAbgHcAVHUhrtuPBFU9rN6b3qq6FDcaXpsQzum7tLTgVU15j7x26tSJxFBfpDDGmHIslCQRpa5NAQDvcyiDMS8GTheRliISAwwBZhTaZitwIYCInIFLEjtEpIHX8I2InAacDmwM4Zy+KylJTJgwgT179tgjr8aYSiOUJLFDRPLHXhORQcAxXx9W1WzgZuBjYA3uKaZVIjI24Hi3A38RkeXAW8B13u3P+cAKEVkGTAX+qqrpx1MwP6i6RyxoGxYAABxDSURBVGCLSxKqypQpUzj//PPtkVdjTKURyiOwfwXeFJHnAMG1D4TU/6mqzsY91hq47L6Az6uBnsXsNw2YFso5ylJ6Ohw+XHySWLNmDWvWrGHkyJFlH5gxxvgklG45NgDdRaSGN58hIr/CtRNUKSU9/nrGGWfw7bff0qxZs7INyhhjfHQ8vbk2A4aKyBBgLwXHmagS8pJEcW3SIkJSUrl7988YY05KiW0SXvcYd4nICuB14G/AxVrSM7WVWLA7iRUrVnD99dezdevWsg/KGGN8FDRJiMhCYBbubuP3qtoF2K+qm8sotnInL0mcckrB5ZMnT+a1116jevXqZR+UMcb4qKQ7iZ+BmkAjIK9viWO/nl2JpaZCw4YQE/AAsKry9ttvc9FFF5GQkBC+4IwxxgdBk4Sq/hboACwFxojIJqCuiHQrq+DKm+LekViyZAmbN2/myiuvDE9QxhjjoxIbrlV1L/Aq8KqINMSNSPekiDRT1aYl7VsZpaVB4YeX3n77baKjo/ntb38bnqCMMcZHobxMB4Cq/qKqz6lqT6CXjzGVW8UNW1qvXj2uueYa6tatG56gjDHGR8fzCGw+Vd1S2oGUd5mZsGtX0eqmu+++OzwBGWNMGQj5TqKq2+6NdBGYJDZt2kROTk54AjLGmDIQyhjXRbrNKG5ZZVf4HYnc3Fx69erFDTfcEL6gjDHGZ6HcSTwb4rJKrfDY1vPnz2f79u1ccskl4QvKGGN8FrRNQkTOBXoADUTktoBVtYBIvwMrbwrfSbzzzjvExcUxYMCA8AVljDE+K6nhOgao4W1TM2D5Ptyoc1VKWhpUrw61a0NOTg5Tp07l0ksvrZJDIhpjqo6gSUJV5wHzRGRi3tNMIhIB1FDVfWUVYHmR9/irCHzxxRf8/PPPXHHFFeEOyxhjfBVKm8S/RKSWiMQD3wGrReQfPsdV7gS+bd2rVy8++ugjLr300vAGZYwxPgslSbT37hx+C3wEtCTEQYcqk8AkER0dTf/+/a1DP2NMpRdKkogWkWhckpihqkeoYh395ea69yTyksSzzz7L/PnzwxuUMcaUgVCSxH+AzUA88IWINMc1XlcZO3bAkSMuSeTk5HDbbbcxe/bsY+9ojDEVXCjDlz4DPBOwaIuI9PEvpPIn8PHXH3/8kezsbJo3bx7eoIwxpgyE8sZ1IxF5RUQ+8ubbA9f6Hlk5Ejhs6ZYtrtsqSxLGmKoglOqmicDHwKne/DrgVr8CKo8C7yQsSRhjqpKShi/Nq4pKUNV3gFwAVc0GqlSvdmlpEBEBjRodTRLNCg8sYYwxlVBJdxKLvL8HRKQ+3hNNItId2Ot3YOVJWho0bgxRUXDnnXeSmppKfHx8uMMyxhjfldRwLd7f24AZQCsR+Qo33nWV6pYj8B2JyMhImhQeVMIYYyqpkpJEYMd+04HZuMRxGLgIWOFzbOVGaiq0aeM+jxkzhg4dOvD73/8+vEEZY0wZKKm6KRLXwV9N3DsSUd6y6hTs8K/Sy7uTUFXGjx/Pl19+Ge6QjDGmTJR0J/Gjqo49mYOLSH/gaVxyeVlVxxVa3wyYBNTxthmtqrO9dXcBN+AayW9R1Y9PJpYTdeAA7N3rHn9NT0/nwIED9mSTMabKCKVN4oSISCQwAbgYSAUWi8gMVV0dsNk/gXdU9d/e+xezgRbe5yHAmbhHbz8VkTaqWuZPVdnjr8aYqqyk6qYLT/LY3YD1qrpRVbOAKcCgQtsobhAjgNqAN5I0g4ApqnpYVTcB673jlbnAJLF161bAkoQxpuooaTyJ9JM8dhNgW8B8KnBOoW3GAJ+IyEhcu8dFAft+XWjfIo8UichwYDhAo0aNSElJOcmQi/r000bAGaSmfsPKlV8RERFBamoq+/fvL/VzhUNGRoYv31t5Z+WuWqzcJ+6YfTf5bCgwUVUf94ZLfV1Ezgp1Z1V9EXgRoGvXrtq7d+9SD/BrL1Vdfvk5XHPNOfzrX/8iMjISkZOqjSs3UlJS8ON7K++s3FWLlfvE+Zkk0oCmAfOJ3rJANwD9AVR1oYjEAgkh7lsm0tKgVi3IG6U0KircedUYY8pOKH03najFwOki0lJEYnAN0TMKbbMVr+1DRM4AYoEd3nZDRKSaiLQETufoG+BlKm/YUoBbb72V5557LhxhGGNMWPiWJLw+nm7GdQ64BvcU0yoRGSsiA73Nbgf+IiLLgbeA69RZBbwDrAbmACPC8WQTFHzbevLkyaxcuTIcYRhjTFj4WnfivfMwu9Cy+wI+rwZ6Btn3IeAhP+MLRVoatG8PBw8eZMeOHfZkkzGmSvGzuqnCy8mBn34q+Pir9f5qjKlKLEmU4OefXaKwF+mMMVWVJYkSpKa6v02aQGZmJomJiZYkjDFViiWJEgQOWzpo0CC2bdtm1U3GmCrFkkQJArvkMMaYqsiSRAnS0iA6Gho0gOuvv5677ror3CEZY0yZsiRRgrQ0OOUUN771Z599RmpeI4UxxlQRliRKkPciXXZ2NmlpadZobYypcixJlGD7dpcktm/fTk5OjiUJY0yVY0miBAcOuI797B0JY0xVZUmiBDk5EBkJIkKPHj047bTTwh2SMcaUKev3ugTZ2RAVBb169eKrr74KdzjGGFPm7E6iBHl3EsYYU1VZkihBXpK44oor+OMf/xjucIwxpsxZkihBXpJYsWIFhw8fDnc4xhhT5ixJlCAnByIilK1bt9qTTcaYKsmSRAmys+HIkZ0cOnTIkoQxpkqyJFGCnBzIyHDvSFjvr8aYqsiSRAlyciAmJpYrr7ySM844I9zhGGNMmbP3JILIzXV/TznlLF54YUp4gzHGmDCxO4kgcnLcX5Hs8AZijDFhZEkiiGwvN7z99h/o2bNneIMxxpgwsSQRRN6dxJ49W6hTp054gzHGmDCxJBFEYJKwJ5uMMVWVJYkgXJLI4ODBdHtHwhhTZVmSCMK1Sdg4EsaYqs2SRBDuTqIGF110O506dQp3OMYYExa+JgkR6S8ia0VkvYiMLmb9kyKyzJvWiciegHU5Aetm+BlncVySaM4VV4ynXbt2ZX16Y4wpF3x7mU5EIoEJwMVAKrBYRGao6uq8bVR1VMD2I4HAn+yHVDXJr/iOxSWJnWRnVweqhysMY4wJKz/fuO4GrFfVjQAiMgUYBKwOsv1Q4H4f4zkuLkn8nfvvX8jf/rYx3OEYUykdOXKE1NRUMjMzfT1P7dq1WbNmja/nKI8Cyx0bG0tiYiLR0dHHdQw/k0QTYFvAfCpwTnEbikhzoCXwecDiWBFZAmQD41T1fb8CLU5ew3VCgjVaG+OX1NRUatasSYsWLRAR386zf/9+atas6dvxy6u8cqsqu3btIjU1lZYtWx7XMcpL301DgKmqmhOwrLmqponIacDnIrJSVTcE7iQiw4HhAI0aNSIlJaXUAtqypTqwncjIM0v1uOVNRkZGpS5fMFbu8qF27drUr1+fjIwMX8+Tk5PD/v37fT1HeRRY7piYGPbs2XPc//39TBJpQNOA+URvWXGGACMCF6hqmvd3o4ik4NorNhTa5kXgRYCuXbtq7969SyNuAL77DuAIDRo0pDSPW96kpKRU6vIFY+UuH9asWUOtWrV8P09Vv5PIExsbe9xPa/r5dNNi4HQRaSkiMbhEUOQpJRFpB9QFFgYsqysi1bzPCUBPgrdl+MK1SWQTGRlZlqc1xphyxbckoarZwM3Ax8Aa4B1VXSUiY0VkYMCmQ4ApqqoBy84AlojIciAZ1yYRhiRxH716DS7L0xpjytCoUaN46qmn8ucvueQShg0blj9/++2388QTTzBjxgzGjRsHwPvvv8/q1UcvR71792bJkiUlnmfz5s3ExcWRlJREx44d6dGjB2vXrgXc3Z2I8OGHH+Zvf9lll5WbakFf35NQ1dmq2kZVW6nqQ96y+1R1RsA2Y1R1dKH9FqhqB1Xt6P19xc84i+Marv9G1679yvrUxpgy0rNnTxYsWABAbm4uO3fuZNWqVfnrFyxYQI8ePRg4cCCjR7vLVOEkEapWrVqxbNkyli9fzrXXXsvDDz+cvy4xMZGHHnroJEvjj/LScF3uuDuJ9WRk1AESwhyNMZXfrbfCsmWle8ykJAi4USiiR48ejBrlXtdatWoVZ511Fj/++CO7d++mevXqrFmzhs6dOzNx4kSWLFnCVVddxYwZM5g3bx4PPvgg06ZNA+Ddd9/lpptuYs+ePbzyyiucd955Jca1b98+6tatmz/fsWNHjhw5wty5c7n44otPvuClyJJEEC5JJPHuuzdy5ZWPhzscY4wPTj31VKKioti6dSsLFizg3HPPJS0tjYULF1K7dm06dOhATExM/vZ5dxWXXXYZgwcfrYrOzs5m0aJFzJ49mwceeIBPP/20yLk2bNhAUlIS+/fv5+DBg3zzzTcF1t9zzz3ce++9liQqCpckcqzh2pgyUtIvfj/16NGDBQsWsGDBAm677TbS0tJYsGABtWvXDnnAscsvvxyALl26sHnz5mK3yatuAnj77bcZPnw4c+bMyV9//vnnAzB//vyTKE3psw7+gnBtEjlER1seNaYyy2uXWLlyJWeddRbdu3dn4cKF+e0RoahWrRoAkZGRZGcfe8jjgQMH8sUXXxRZfs899/Dggw8eXwF8ZkkiiLxHYKOi7E7CmMqsR48ezJw5k3r16hEZGUm9evXYs2cPCxcuLDZJ1KxZ86RfzJs/fz6tWrUqsrxfv37s3r2bFStWnNTxS5MliSCysxVQSxLGVHIdOnRg586ddO/evcCy2rVrk5BQ9KGVIUOG8Nhjj9GpUyc2bNhQZH0weW0SHTt25O677+bll18udrt77rmHbdu2FbsuHKwuJQh3J/EC553XJdyhGGN8FBkZyb59+wosmzhxYoH56667juuuuw5w1VOBj8AGvs+QkJBQbJtEixYtOHToULHn7927d4G34AcOHEjB18bCy5JEELm5AtzI2WeHOxJjjAkfq24K4vDhHGApe/b8Eu5QjDEmbCxJBHHw4AGgK7Nnvx7uUIwxJmwsSQRx5IjrtdwegTXGVGWWJII4csQ962xPNxljqjJLEkEcvZOwJGGMqbosSQRhScKYyq+sugoPVWDPsIW1aNGCDh06kJSURIcOHfjggw/y14kIt99+e/78+PHjGTNmTKnEZEkiiNjYusCb9OrVN9yhGGN8UpZdhYeipCQBkJyczLJly5g6dSq33HJL/vJq1arx3nvvsXPnzlKPyZJEEJGR1YGraN26dbhDMabKyHuxLHB6/vnnATh48GCx6/NefNu5c2eRdcfSo0cPFi50g2LmdRVes2ZNdu/ezeHDhwt0FX7zzTezYMECZsyYwT/+8Q+SkpLy37h+99136datG23atOHLL78EIDMzkz//+c906NCBTp06kZycDJB/rDx5AwyNHj2aQ4cOkZSUxB//+McS4y7c1XhUVBTDhw/nySefDO2LPg726E4Qhw4dBBaRnt6exo0bhjscY4wP/OwqfMKECYgIK1eu5Pvvv6dfv36sW7cuaCzjxo3jueeey+8ptjh9+vRBVdm4cSPvvPNOgXUjRozg7LPP5s477zyJb6QoSxJB7NixFejDggVv0b79kHCHY0yVUNKQndWrVy9xfUJCwgkN+elXV+Hz589n5MiRALRr147mzZuXmCRCkZycTEJCAhs2bODCCy+kd+/e1KhRA4BatWpxzTXX8MwzzxAXF3dS5wlk1U1B5D0Caw3XxlRuZd1VeFRUFLm5ufnzmZmZxx1zq1ataNSoUZG2kVtvvZVXXnmFAwcOHPcxg7EkEUR2tnu6KSbGbraMqcz86ir8vPPO48033wRg3bp1bN26lbZt29KiRQuWLVtGbm4u27ZtY9GiRfn7REdHc+TIkWMe+5dffmHTpk00b968wPJ69epxxRVX8MorrxzzGKGyJBFE3q8Bu5MwpnLzq6vwm266idzcXDp06MCVV17JxIkTqVatGj179qRly5a0b9+eW265hc6dO+fvM3z4cM4+++ygDdd9+vQhKSmJPn36MG7cOBo1alRkm9tvv710n3JS1UoxdenSRUvTjTd+o4B+8MHMUj1ueZOcnBzuEMLCyl0+rF69ukzOs2/fvjI5T3lTuNzFfd/AEi3h2mp3EkHUrn06MINu3bqGOxRjjAkbq3APIiamLiIDaNw43JEYY0z42J1EEPv370RkJrt27Qp3KMZUalqORmGrzE70e7YkEcRPPy0nN3eAb6/fG2MgNjaWXbt2WaLwmaqya9cuYmNjj3tfq24KIu/ppshIe7rJGL8kJiaSmprKjh07fD1PZmbmCV0gK7rAcsfGxpKYmHjcx7AkEUReL7CWJIzxT3R0NC1btvT9PCkpKXTq1Mn385Q3pVFuX6ubRKS/iKwVkfUiMrqY9U+KyDJvWiciewLWXSsiP3jTtX7GWZycHEsSxhjj252EiEQCE4CLgVRgsYjMUNX8Sn5VHRWw/Uigk/e5HnA/0BVQYKm3726/4i0sL0lERdnNljGm6vLzTqIbsF5VN6pqFjAFGFTC9kOBt7zPlwBzVTXdSwxzgf4+xlpEgwY9qVv3c+sq3BhTpfn5M7kJsC1gPhU4p7gNRaQ50BL4vIR9mxSz33BguDebISJrTzLmImrWLO0jljsJQOmPVFL+WbmrFit3cM1LWlle6lKGAFNVNed4dlLVF4EX/QmpahCRJapa5V4rt3JXLVbuE+dndVMa0DRgPtFbVpwhHK1qOt59jTHG+MTPJLEYOF1EWopIDC4RzCi8kYi0A+oCCwMWfwz0E5G6IlIX6OctM8YYU4Z8q25S1WwRuRl3cY8E/quqq0RkLK7XwbyEMQSYogGvXKpquoj8Hy7RAIxV1XS/Yq3iqmp1nZW7arFynyCx1+GNMcYEY303GWOMCcqShDHGmKAsSVRiIvJfEflFRL4LWFZPROZ63Z3M9R4MQESuE5HnvM8RIjLJ21/CFf+JEpGmIpIsIqtFZJWI/N1bXqnLLiKxIrJIRJZ75X7AW95SRL7xusd523uQBBEZIyJ3BOw7V0TGhLEIJ0VEIkXkWxGZ6c1X+nKLyGYRWel1bbTEW1aq/84tSVRuEyn6pvpo4DNVPR34zJvP5/2DeQGIBoZpxWy0ygZuV9X2QHdghIi0p/KX/TDQV1U7AklAfxHpDjwCPKmqrYHdwA2BO3kXz2nAUlUdU7Yhl6q/A2sC5qtKufuoalLA+xCl+u/ckkQlpqpfAIWfChsETPI+TwJ+W2j9M0B94BpVzfU3Qn+o6o+q+j/v837chaMJlbzs3pDFGd5stDcp0BeY6i0vXO4o4G3gB1Ut0glnRSEiicClwMvevFAFyh1Eqf47tyRR9TRS1R+9zz8BjQLWXQV0BoaoanaZR+YDEWmB6zjyG6pA2b0ql2XAL7g+zzYAewLKVLiLmzuBLFW9tWwjLXVP4cqSd9GrT9UotwKfiMhSr5siKOV/55YkqjDvNjPwVvN/uH5cuoUnotIlIjVw1Qm3quq+wHWVteyqmqOqSbheCroB7Y6xy3ygh4i08T04n4jIZcAvqrr0OHar8OX29FLVzsCvcdWq5weuLI1/55Ykqp6fReQUAO/vLwHrvgeuAN4WkTPDEVxpEZFoXIJ4U1Xf8xZXibIDqOoeIBk4F6gjInkvzhbu4uYL4Fbgo7zvpgLqCQwUkc243qb7Ak9T+cuNqqZ5f38BpuMu/qX679ySRNUzA8gbxOla4IPAlaq6APgbMFNEmpVxbKXCq49+BVijqk8ErKrUZReRBiJSx/schxvLZQ0uWQz2Niuu3NOA8cCcvP0rElW9S1UTVbUFrgeHz1X1j1TycotIvIjUzPuM677oO0r533l56QXW+EBE3gJ6AwkikoobyGkc8I6I3ABswf2qKEBVPxSRBNz/POep6q4yDLs09ASuBlZ69fMAd1P5y34KMEncgF8RwDuqOlNEVgNTRORB4FtcAi1AVf8tIo2AGSLST1UzyzRyf/w/Kne5GwHTvSdYo4DJqjpHRBZTiv/OrVsOY4wxQVl1kzHGmKAsSRhjjAnKkoQxxpigLEkYY4wJypKEMcaYoCxJmDIlIioijwfM31FaPXCKyEQRGXzsLU/6PH8QkTUikhywrIPXE+cyEUkXkU3e509DPOZAESmxDyEROVVEppa0TahEpJGIzBTXY+xqEZntLW8hIleVxjlM5WBJwpS1w8Dl3jPa5UbAm7mhuAH4i6r2yVugqiu9njiTcC8z/cObvyiUc6jqDFUdV9JJVXW7qpZWEhwLzFXVjl5vuXkJqgWufx9jAEsSpuxl48bdHVV4ReE7ARHJ8P72FpF5IvKBiGwUkXEi8kdxYyesFJFWAYe5SESWiMg6r0+fvE7vHhORxSKyQkRuDDjulyIyA1hdTDxDveN/JyKPeMvuA3oBr4jIY8cqrIikiMhT4vr6/7uIDBA3xsG3IvKp9yJX4b7+J4rIMyKywCvvYG95C/HGBvG2f09E5ogbN+DRgHPe4JV/kYi8lHfcQk7BdXoHgKqu8D6OA87z7oJGHeO7+0JEZonIWhF5QdwYBZFe/N95312R/86mYrE3rk04TABWBF7YQtAROAPX9flG4GVV7SZuQKGRuH54wP0S7ga0ApJFpDVwDbBXVX8lItWAr0TkE2/7zsBZqrop8GQicipuPIIuuLEIPhGR36rqWBHpC9yhqktCjD0mr69/cQPAdFdVFZFhuN5Iby9mn1Nwyagd7s6kuGqmJFwPt4eBtSLyLJAD3OuVaz/wObC8mH0n4PrvuRn4FHhVVbfj7ijuUNW8BDuc4N9dN6A97q3eOcDlwCagiaqe5e1f4bq7MAVZkjBlTlX3ichrwC3AoRB3W5zX/bGIbADyLlQrgT4B273j9ZH/g4hsxF1k+wFnB9yl1AZOB7KARYUThOdXQIqq7vDO+SZwPvB+iPEGejvgcyLu4nwKEIO7qBbnfa8cq/PuNorxmaru9eJbjevdMwGYp6rp3vJ3gSI9narqxyJyGm5Qql8D34rIWcWc41jf3UbvPG/hktpnwGlewprF0f9OpoKy6iYTLk/h6vbjA5Zl4/2bFJEI3EU0z+GAz7kB87kU/LFTuJ8ZBQQYmddmoKotVTXv4nXgpEoRmsBzPAs8p6odgBuB2CD7BJY32PCSgdvkcJw/+lQ1XVUnq+rVwGJcEiyspO+uyHetqrtxd30pwF/xBgEyFZclCRMW3i/ddyg4pORmXPUOwEDcyGrH6w9e3Xgr4DRgLfAx8Ddx3YcjIm3E9ZpZkkXABSKSIK7DvKHAvBOIp7DaHO2y+tqSNjxBi3Fx1/Uayn9f3EYi0ldEqnufa+Kq57biqqhqBmxa0nfXTdw40hHAlcB874GECK+H1X/iqr1MBWbVTSacHgduDph/CfhARJbj6rhP5Ff+VtwFvhbwV1XNFJGXcW0V/xMRAXZQdEjHAlT1R3GPpCbjfk3PUtUPStonRGOAd0VkN669oGUpHDOfqqaJyMO47yAdN37A3mI27QI8JyJ5d28vq+piLxnkeP8NJuLGZWhB8d/dYuA5oDXue5oOdABe9RIHwF2lWT5T9qwXWGMqGRGpoaoZ3p3EdOC/qjq9lM/Rm4AGblN5WXWTMZXPGHHjaHyHaxg/kcZ2YwC7kzDGGFMCu5MwxhgTlCUJY4wxQVmSMMYYE5QlCWOMMUFZkjDGGBPU/wfMqMISZFlrVgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}